diff --git a/libs/luajit/LuaJIT-src/Makefile b/libs/luajit/LuaJIT-src/Makefile
index 0f93308..45b3b2d 100644
--- a/libs/luajit/LuaJIT-src/Makefile
+++ b/libs/luajit/LuaJIT-src/Makefile
@@ -88,7 +88,7 @@ FILES_INC= lua.h lualib.h lauxlib.h luaconf.h lua.hpp luajit.h
 FILES_JITLIB= bc.lua bcsave.lua dump.lua p.lua v.lua zone.lua \
 	      dis_x86.lua dis_x64.lua dis_arm.lua dis_arm64.lua \
 	      dis_arm64be.lua dis_ppc.lua dis_mips.lua dis_mipsel.lua \
-	      dis_mips64.lua dis_mips64el.lua vmdef.lua
+	      dis_mips64.lua dis_mips64el.lua dis_loongarch64.lua vmdef.lua
 
 ifeq (,$(findstring Windows,$(OS)))
   HOST_SYS:= $(shell uname -s)
diff --git a/libs/luajit/LuaJIT-src/doc/ext_jit.html b/libs/luajit/LuaJIT-src/doc/ext_jit.html
index e4088bc..492f537 100644
--- a/libs/luajit/LuaJIT-src/doc/ext_jit.html
+++ b/libs/luajit/LuaJIT-src/doc/ext_jit.html
@@ -153,7 +153,7 @@ Contains the target OS name:
 <h3 id="jit_arch"><tt>jit.arch</tt></h3>
 <p>
 Contains the target architecture name:
-"x86", "x64", "arm", "arm64", "ppc", "mips" or "mips64".
+"x86", "x64", "arm", "arm64", "ppc", "loongarch64", "mips" or "mips64".
 </p>
 
 <h2 id="jit_opt"><tt>jit.opt.*</tt> &mdash; JIT compiler optimization control</h2>
diff --git a/libs/luajit/LuaJIT-src/doc/install.html b/libs/luajit/LuaJIT-src/doc/install.html
index c491c60..fc8559d 100644
--- a/libs/luajit/LuaJIT-src/doc/install.html
+++ b/libs/luajit/LuaJIT-src/doc/install.html
@@ -154,6 +154,13 @@ operating systems, CPUs and compilers:
 <td class="compatos compatno">&nbsp;</td>
 <td class="compatos compatno">&nbsp;</td>
 </tr>
+<tr class="odd">
+<td class="compatcpu"><a href="#cross2">LoongArch64</a></td>
+<td class="compatos">GCC 4.3+</td>
+<td class="compatos">GCC 4.3+</td>
+<td class="compatos compatno">&nbsp;</td>
+<td class="compatos compatno">&nbsp;</td>
+</tr>
 </table>
 
 <h2>Configuring LuaJIT</h2>
@@ -426,6 +433,9 @@ make HOST_CC="gcc -m32" CROSS=mipsel-linux-
 make CROSS=mips-linux- TARGET_CFLAGS="-mips64r2 -mabi=64"
 # MIPS64 little-endian
 make CROSS=mipsel-linux- TARGET_CFLAGS="-mips64r2 -mabi=64"
+
+# LOONGARCH64
+make CROSS=loongarch64-linux-
 </pre>
 <p>
 You can cross-compile for <b id="android">Android</b> using the <a href="https://developer.android.com/ndk/index.html">Android NDK</a>.
diff --git a/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.h b/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.h
new file mode 100644
index 0000000..e6c9e3e
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.h
@@ -0,0 +1,451 @@
+/*
+** DynASM LoongArch encoding engine.
+** Copyright (C) 2005-2021 Mike Pall. All rights reserved.
+** Copyright (C) 2021 Loongson Technology. All rights reserved.
+** Released under the MIT license. See dynasm.lua for full copyright notice.
+*/
+
+#include <stddef.h>
+#include <stdarg.h>
+#include <string.h>
+#include <stdlib.h>
+
+#define DASM_ARCH		"loongarch64"
+
+#ifndef DASM_EXTERN
+#define DASM_EXTERN(a,b,c,d)	0
+#endif
+
+/* Action definitions. */
+enum {
+  DASM_STOP, DASM_SECTION, DASM_ESC, DASM_REL_EXT,
+  /* The following actions need a buffer position. */
+  DASM_ALIGN, DASM_REL_LG, DASM_LABEL_LG,
+  /* The following actions also have an argument. */
+  DASM_REL_PC, DASM_LABEL_PC, DASM_IMM, DASM_IMM2,
+  DASM__MAX
+};
+
+/* Maximum number of section buffer positions for a single dasm_put() call. */
+#define DASM_MAXSECPOS		25
+
+/* DynASM encoder status codes. Action list offset or number are or'ed in. */
+#define DASM_S_OK		0x00000000
+#define DASM_S_NOMEM		0x01000000
+#define DASM_S_PHASE		0x02000000
+#define DASM_S_MATCH_SEC	0x03000000
+#define DASM_S_RANGE_I		0x11000000
+#define DASM_S_RANGE_SEC	0x12000000
+#define DASM_S_RANGE_LG		0x13000000
+#define DASM_S_RANGE_PC		0x14000000
+#define DASM_S_RANGE_REL	0x15000000
+#define DASM_S_UNDEF_LG		0x21000000
+#define DASM_S_UNDEF_PC		0x22000000
+
+/* Macros to convert positions (8 bit section + 24 bit index). */
+#define DASM_POS2IDX(pos)	((pos)&0x00ffffff)
+#define DASM_POS2BIAS(pos)	((pos)&0xff000000)
+#define DASM_SEC2POS(sec)	((sec)<<24)
+#define DASM_POS2SEC(pos)	((pos)>>24)
+#define DASM_POS2PTR(D, pos)	(D->sections[DASM_POS2SEC(pos)].rbuf + (pos))
+
+/* Action list type. */
+typedef const unsigned int *dasm_ActList;
+
+/* Per-section structure. */
+typedef struct dasm_Section {
+  int *rbuf;		/* Biased buffer pointer (negative section bias). */
+  int *buf;		/* True buffer pointer. */
+  size_t bsize;		/* Buffer size in bytes. */
+  int pos;		/* Biased buffer position. */
+  int epos;		/* End of biased buffer position - max single put. */
+  int ofs;		/* Byte offset into section. */
+} dasm_Section;
+
+/* Core structure holding the DynASM encoding state. */
+struct dasm_State {
+  size_t psize;			/* Allocated size of this structure. */
+  dasm_ActList actionlist;	/* Current actionlist pointer. */
+  int *lglabels;		/* Local/global chain/pos ptrs. */
+  size_t lgsize;
+  int *pclabels;		/* PC label chains/pos ptrs. */
+  size_t pcsize;
+  void **globals;		/* Array of globals (bias -10). */
+  dasm_Section *section;	/* Pointer to active section. */
+  size_t codesize;		/* Total size of all code sections. */
+  int maxsection;		/* 0 <= sectionidx < maxsection. */
+  int status;			/* Status code. */
+  dasm_Section sections[1];	/* All sections. Alloc-extended. */
+};
+
+/* The size of the core structure depends on the max. number of sections. */
+#define DASM_PSZ(ms)	(sizeof(dasm_State)+(ms-1)*sizeof(dasm_Section))
+
+
+/* Initialize DynASM state. */
+void dasm_init(Dst_DECL, int maxsection)
+{
+  dasm_State *D;
+  size_t psz = 0;
+  int i;
+  Dst_REF = NULL;
+  DASM_M_GROW(Dst, struct dasm_State, Dst_REF, psz, DASM_PSZ(maxsection));
+  D = Dst_REF;
+  D->psize = psz;
+  D->lglabels = NULL;
+  D->lgsize = 0;
+  D->pclabels = NULL;
+  D->pcsize = 0;
+  D->globals = NULL;
+  D->maxsection = maxsection;
+  for (i = 0; i < maxsection; i++) {
+    D->sections[i].buf = NULL;  /* Need this for pass3. */
+    D->sections[i].rbuf = D->sections[i].buf - DASM_SEC2POS(i);
+    D->sections[i].bsize = 0;
+    D->sections[i].epos = 0;  /* Wrong, but is recalculated after resize. */
+  }
+}
+
+/* Free DynASM state. */
+void dasm_free(Dst_DECL)
+{
+  dasm_State *D = Dst_REF;
+  int i;
+  for (i = 0; i < D->maxsection; i++)
+    if (D->sections[i].buf)
+      DASM_M_FREE(Dst, D->sections[i].buf, D->sections[i].bsize);
+  if (D->pclabels) DASM_M_FREE(Dst, D->pclabels, D->pcsize);
+  if (D->lglabels) DASM_M_FREE(Dst, D->lglabels, D->lgsize);
+  DASM_M_FREE(Dst, D, D->psize);
+}
+
+/* Setup global label array. Must be called before dasm_setup(). */
+void dasm_setupglobal(Dst_DECL, void **gl, unsigned int maxgl)
+{
+  dasm_State *D = Dst_REF;
+  D->globals = gl - 10;  /* Negative bias to compensate for locals. */
+  DASM_M_GROW(Dst, int, D->lglabels, D->lgsize, (10+maxgl)*sizeof(int));
+}
+
+/* Grow PC label array. Can be called after dasm_setup(), too. */
+void dasm_growpc(Dst_DECL, unsigned int maxpc)
+{
+  dasm_State *D = Dst_REF;
+  size_t osz = D->pcsize;
+  DASM_M_GROW(Dst, int, D->pclabels, D->pcsize, maxpc*sizeof(int));
+  memset((void *)(((unsigned char *)D->pclabels)+osz), 0, D->pcsize-osz);
+}
+
+/* Setup encoder. */
+void dasm_setup(Dst_DECL, const void *actionlist)
+{
+  dasm_State *D = Dst_REF;
+  int i;
+  D->actionlist = (dasm_ActList)actionlist;
+  D->status = DASM_S_OK;
+  D->section = &D->sections[0];
+  memset((void *)D->lglabels, 0, D->lgsize);
+  if (D->pclabels) memset((void *)D->pclabels, 0, D->pcsize);
+  for (i = 0; i < D->maxsection; i++) {
+    D->sections[i].pos = DASM_SEC2POS(i);
+    D->sections[i].ofs = 0;
+  }
+}
+
+
+#ifdef DASM_CHECKS
+#define CK(x, st) \
+  do { if (!(x)) { \
+    D->status = DASM_S_##st|(p-D->actionlist-1); return; } } while (0)
+#define CKPL(kind, st) \
+  do { if ((size_t)((char *)pl-(char *)D->kind##labels) >= D->kind##size) { \
+    D->status = DASM_S_RANGE_##st|(p-D->actionlist-1); return; } } while (0)
+#else
+#define CK(x, st)	((void)0)
+#define CKPL(kind, st)	((void)0)
+#endif
+
+static int dasm_imm2(unsigned int n)
+{
+  if ((n >> 21) == 0)
+    return n;
+    //return ((n>>16)&0x1f) | ((n&0xffff)>>10);
+  else if ((n >> 26) == 0)
+    return n;
+    //return ((n>>16)&0x3ff) | ((n&0xffff)>>10);
+  else
+    return -1;
+}
+
+/* Pass 1: Store actions and args, link branches/labels, estimate offsets. */
+void dasm_put(Dst_DECL, int start, ...)
+{
+  va_list ap;
+  dasm_State *D = Dst_REF;
+  dasm_ActList p = D->actionlist + start;
+  dasm_Section *sec = D->section;
+  int pos = sec->pos, ofs = sec->ofs;
+  int *b;
+
+  if (pos >= sec->epos) {
+    DASM_M_GROW(Dst, int, sec->buf, sec->bsize,
+      sec->bsize + 2*DASM_MAXSECPOS*sizeof(int));
+    sec->rbuf = sec->buf - DASM_POS2BIAS(pos);
+    sec->epos = (int)sec->bsize/sizeof(int) - DASM_MAXSECPOS+DASM_POS2BIAS(pos);
+  }
+
+  b = sec->rbuf;
+  b[pos++] = start;
+
+  va_start(ap, start);
+  while (1) {
+    unsigned int ins = *p++;
+    unsigned int action = (ins >> 16) - 0xff00;
+    if (action >= DASM__MAX) {
+      ofs += 4;
+    } else {
+      int *pl, n = action >= DASM_REL_PC ? va_arg(ap, int) : 0;
+      switch (action) {
+      case DASM_STOP: goto stop;
+      case DASM_SECTION:
+	n = (ins & 255); CK(n < D->maxsection, RANGE_SEC);
+	D->section = &D->sections[n]; goto stop;
+      case DASM_ESC: p++; ofs += 4; break;
+      case DASM_REL_EXT: break;
+      case DASM_ALIGN: ofs += (ins & 255); b[pos++] = ofs; break;
+      case DASM_REL_LG:
+	n = (ins & 2047) - 10; pl = D->lglabels + n;
+	/* Bkwd rel or global. */
+	if (n >= 0) { CK(n>=10||*pl<0, RANGE_LG); CKPL(lg, LG); goto putrel; }
+	pl += 10; n = *pl;
+	if (n < 0) n = 0;  /* Start new chain for fwd rel if label exists. */
+	goto linkrel;
+      case DASM_REL_PC:
+	pl = D->pclabels + n; CKPL(pc, PC);
+      putrel:
+	n = *pl;
+	if (n < 0) {  /* Label exists. Get label pos and store it. */
+	  b[pos] = -n;
+	} else {
+      linkrel:
+	  b[pos] = n;  /* Else link to rel chain, anchored at label. */
+	  *pl = pos;
+	}
+	pos++;
+	break;
+      case DASM_LABEL_LG:
+	pl = D->lglabels + (ins & 2047) - 10; CKPL(lg, LG); goto putlabel;
+      case DASM_LABEL_PC:
+	pl = D->pclabels + n; CKPL(pc, PC);
+      putlabel:
+	n = *pl;  /* n > 0: Collapse rel chain and replace with label pos. */
+	while (n > 0) { int *pb = DASM_POS2PTR(D, n); n = *pb; *pb = pos;
+	}
+	*pl = -pos;  /* Label exists now. */
+	b[pos++] = ofs;  /* Store pass1 offset estimate. */
+	break;
+      case DASM_IMM:
+#ifdef DASM_CHECKS
+	CK((n & ((1<<((ins>>10)&31))-1)) == 0, RANGE_I);
+#endif
+	n >>= ((ins>>10)&31);
+#ifdef DASM_CHECKS
+	if (ins & 0x8000)
+	  CK(((n + (1<<(((ins>>5)&31)-1)))>>((ins>>5)&31)) == 0, RANGE_I);
+	else
+	  CK((n>>((ins>>5)&31)) == 0, RANGE_I);
+#endif
+	b[pos++] = n;
+	break;
+      case DASM_IMM2:
+        CK(dasm_imm2((unsigned int)n) != -1, RANGE_I);
+        b[pos++] = n;
+        break;
+      }
+    }
+  }
+stop:
+  va_end(ap);
+  sec->pos = pos;
+  sec->ofs = ofs;
+}
+#undef CK
+
+/* Pass 2: Link sections, shrink aligns, fix label offsets. */
+int dasm_link(Dst_DECL, size_t *szp)
+{
+  dasm_State *D = Dst_REF;
+  int secnum;
+  int ofs = 0;
+
+#ifdef DASM_CHECKS
+  *szp = 0;
+  if (D->status != DASM_S_OK) return D->status;
+  {
+    int pc;
+    for (pc = 0; pc*sizeof(int) < D->pcsize; pc++)
+      if (D->pclabels[pc] > 0) return DASM_S_UNDEF_PC|pc;
+  }
+#endif
+
+  { /* Handle globals not defined in this translation unit. */
+    int idx;
+    for (idx = 10; idx*sizeof(int) < D->lgsize; idx++) {
+      int n = D->lglabels[idx];
+      /* Undefined label: Collapse rel chain and replace with marker (< 0). */
+      while (n > 0) { int *pb = DASM_POS2PTR(D, n); n = *pb; *pb = -idx; }
+    }
+  }
+
+  /* Combine all code sections. No support for data sections (yet). */
+  for (secnum = 0; secnum < D->maxsection; secnum++) {
+    dasm_Section *sec = D->sections + secnum;
+    int *b = sec->rbuf;
+    int pos = DASM_SEC2POS(secnum);
+    int lastpos = sec->pos;
+
+    while (pos != lastpos) {
+      dasm_ActList p = D->actionlist + b[pos++];
+      while (1) {
+	unsigned int ins = *p++;
+	unsigned int action = (ins >> 16) - 0xff00;
+	switch (action) {
+	case DASM_STOP: case DASM_SECTION: goto stop;
+	case DASM_ESC: p++; break;
+	case DASM_REL_EXT: break;
+	case DASM_ALIGN: ofs -= (b[pos++] + ofs) & (ins & 255); break;
+	case DASM_REL_LG: case DASM_REL_PC: pos++; break;
+	case DASM_LABEL_LG: case DASM_LABEL_PC: b[pos++] += ofs; break;
+	case DASM_IMM: case DASM_IMM2: pos++; break;
+	}
+      }
+      stop: (void)0;
+    }
+    ofs += sec->ofs;  /* Next section starts right after current section. */
+  }
+
+  D->codesize = ofs;  /* Total size of all code sections */
+  *szp = ofs;
+  return DASM_S_OK;
+}
+
+#ifdef DASM_CHECKS
+#define CK(x, st) \
+  do { if (!(x)) return DASM_S_##st|(p-D->actionlist-1); } while (0)
+#else
+#define CK(x, st)	((void)0)
+#endif
+
+/* Pass 3: Encode sections. */
+int dasm_encode(Dst_DECL, void *buffer)
+{
+  dasm_State *D = Dst_REF;
+  char *base = (char *)buffer;
+  unsigned int *cp = (unsigned int *)buffer;
+  int secnum;
+
+  /* Encode all code sections. No support for data sections (yet). */
+  for (secnum = 0; secnum < D->maxsection; secnum++) {
+    dasm_Section *sec = D->sections + secnum;
+    int *b = sec->buf;
+    int *endb = sec->rbuf + sec->pos;
+
+    while (b != endb) {
+      dasm_ActList p = D->actionlist + *b++;
+      while (1) {
+	unsigned int ins = *p++;
+	unsigned int action = (ins >> 16) - 0xff00;
+	int n = (action >= DASM_ALIGN && action < DASM__MAX) ? *b++ : 0;
+	switch (action) {
+	case DASM_STOP: case DASM_SECTION: goto stop;
+	case DASM_ESC: *cp++ = *p++; break;
+	case DASM_REL_EXT:
+	  n = DASM_EXTERN(Dst, (unsigned char *)cp, (ins & 2047), 1);
+	  goto patchrel;
+	case DASM_ALIGN:
+	  ins &= 255; while ((((char *)cp - base) & ins)) *cp++ = 0x60000000;
+	  break;
+	case DASM_REL_LG:
+	  if (n < 0) {
+	    n = (int)((ptrdiff_t)D->globals[-n] - (ptrdiff_t)cp + 4);
+	    goto patchrel;
+	  }
+	  /* fallthrough */
+	case DASM_REL_PC:
+	  CK(n >= 0, UNDEF_PC);
+	  n = *DASM_POS2PTR(D, n);
+	  if (ins & 2048)
+	    n = (n + (int)(size_t)base) & 0x0fffffff;
+	  else
+	    n = n - (int)((char *)cp - base) + 4;
+	patchrel: {
+          unsigned int e = 16 + ((ins >> 12) & 15);
+          CK((n & 3) == 0 &&
+             ((n + ((ins & 2048) ? 0 : (1<<(e+1)))) >> (e+2)) == 0, RANGE_REL);
+          if (!(ins & 0xf800)) { /* BEQ, BNE, BLT, BGE, BLTU, BGEU */
+            cp[-1] |= (((n >> 2) & 0xffff) << 10);
+          } else if ((ins & 0x5000)) { /* BEQZ, BNEZ, BCEQZ, BCNEZ */
+            cp[-1] |= (((n >> 2) & 0xffff) << 10) | (((n >> 2) & 0x1f0000) >> 16);
+          } else if ((ins & 0xa000)) { /* B, BL */
+            cp[-1] |= (((n >> 2) & 0xffff) << 10) | (((n >> 2) & 0x3ff0000) >> 16);
+          }
+        }
+	  break;
+	case DASM_LABEL_LG:
+	  ins &= 2047; if (ins >= 20) D->globals[ins-10] = (void *)(base + n);
+	  break;
+	case DASM_LABEL_PC: break;
+	case DASM_IMM2: {
+	  //cp[-1] |= ((n>>3) & 4); n &= 0x1f;
+          unsigned int imm2n = dasm_imm2((unsigned int)n);
+          cp[-1] |= ((imm2n&0x3ff0000) | ((imm2n&0xffff))>>10);
+          }
+          break;
+	  /* fallthrough */
+	case DASM_IMM:
+	  cp[-1] |= (n & ((1<<((ins>>5)&31))-1)) << (ins&31);
+	  break;
+	default: *cp++ = ins; break;
+	}
+      }
+      stop: (void)0;
+    }
+  }
+
+  if (base + D->codesize != (char *)cp)  /* Check for phase errors. */
+    return DASM_S_PHASE;
+  return DASM_S_OK;
+}
+#undef CK
+
+/* Get PC label offset. */
+int dasm_getpclabel(Dst_DECL, unsigned int pc)
+{
+  dasm_State *D = Dst_REF;
+  if (pc*sizeof(int) < D->pcsize) {
+    int pos = D->pclabels[pc];
+    if (pos < 0) return *DASM_POS2PTR(D, -pos);
+    if (pos > 0) return -1;  /* Undefined. */
+  }
+  return -2;  /* Unused or out of range. */
+}
+
+#ifdef DASM_CHECKS
+/* Optional sanity checker to call between isolated encoding steps. */
+int dasm_checkstep(Dst_DECL, int secmatch)
+{
+  dasm_State *D = Dst_REF;
+  if (D->status == DASM_S_OK) {
+    int i;
+    for (i = 1; i <= 9; i++) {
+      if (D->lglabels[i] > 0) { D->status = DASM_S_UNDEF_LG|i; break; }
+      D->lglabels[i] = 0;
+    }
+  }
+  if (D->status == DASM_S_OK && secmatch >= 0 &&
+      D->section != &D->sections[secmatch])
+    D->status = DASM_S_MATCH_SEC|(D->section-D->sections);
+  return D->status;
+}
+#endif
+
diff --git a/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.lua b/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.lua
new file mode 100644
index 0000000..6542763
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/dynasm/dasm_loongarch64.lua
@@ -0,0 +1,977 @@
+------------------------------------------------------------------------------
+-- DynASM LoongArch module.
+--
+-- Copyright (C) 2005-2021 Mike Pall. All rights reserved.
+-- Copyright (C) 2021 Loongson Technology. All rights reserved.
+-- See dynasm.lua for full copyright notice.
+------------------------------------------------------------------------------
+
+-- Module information:
+local _info = {
+  arch =	"loongarch64",
+  description =	"DynASM LoongArch64 module",
+  version =	"1.4.0",
+  vernum =	 10400,
+  release =	"2021-05-20",
+  author =	"Mike Pall",
+  license =	"MIT",
+}
+
+-- Exported glue functions for the arch-specific module.
+local _M = { _info = _info }
+
+-- Cache library functions.
+local type, tonumber, pairs, ipairs = type, tonumber, pairs, ipairs
+local assert, setmetatable = assert, setmetatable
+local _s = string
+local sub, format, byte, char = _s.sub, _s.format, _s.byte, _s.char
+local match, gmatch = _s.match, _s.gmatch
+local concat, sort = table.concat, table.sort
+local bit = bit or require("bit")
+local band, shl, shr, sar = bit.band, bit.lshift, bit.rshift, bit.arshift
+local tohex = bit.tohex
+
+-- Inherited tables and callbacks.
+local g_opt, g_arch
+local wline, werror, wfatal, wwarn
+
+-- Action name list.
+-- CHECK: Keep this in sync with the C code!
+local action_names = {
+  "STOP", "SECTION", "ESC", "REL_EXT",
+  "ALIGN", "REL_LG", "LABEL_LG",
+  "REL_PC", "LABEL_PC", "IMM", "IMM2",
+}
+
+-- Maximum number of section buffer positions for dasm_put().
+-- CHECK: Keep this in sync with the C code!
+local maxsecpos = 25 -- Keep this low, to avoid excessively long C lines.
+
+-- Action name -> action number.
+local map_action = {}
+for n,name in ipairs(action_names) do
+  map_action[name] = n-1
+end
+
+-- Action list buffer.
+local actlist = {}
+
+-- Argument list for next dasm_put(). Start with offset 0 into action list.
+local actargs = { 0 }
+
+-- Current number of section buffer positions for dasm_put().
+local secpos = 1
+
+------------------------------------------------------------------------------
+
+-- Dump action names and numbers.
+local function dumpactions(out)
+  out:write("DynASM encoding engine action codes:\n")
+  for n,name in ipairs(action_names) do
+    local num = map_action[name]
+    out:write(format("  %-10s %02X  %d\n", name, num, num))
+  end
+  out:write("\n")
+end
+
+-- Write action list buffer as a huge static C array.
+local function writeactions(out, name)
+  local nn = #actlist
+  if nn == 0 then nn = 1; actlist[0] = map_action.STOP end
+  out:write("static const unsigned int ", name, "[", nn, "] = {\n")
+  for i = 1,nn-1 do
+    assert(out:write("0x", tohex(actlist[i]), ",\n"))
+  end
+  assert(out:write("0x", tohex(actlist[nn]), "\n};\n\n"))
+end
+
+------------------------------------------------------------------------------
+
+-- Add word to action list.
+local function wputxw(n)
+  assert(n >= 0 and n <= 0xffffffff and n % 1 == 0, "word out of range")
+  actlist[#actlist+1] = n
+end
+
+-- Add action to list with optional arg. Advance buffer pos, too.
+local function waction(action, val, a, num)
+  local w = assert(map_action[action], "bad action name `"..action.."'")
+  wputxw(0xff000000 + w * 0x10000 + (val or 0))
+  if a then actargs[#actargs+1] = a end
+  if a or num then secpos = secpos + (num or 1) end
+end
+
+-- Flush action list (intervening C code or buffer pos overflow).
+local function wflush(term)
+  if #actlist == actargs[1] then return end -- Nothing to flush.
+  if not term then waction("STOP") end -- Terminate action list.
+  wline(format("dasm_put(Dst, %s);", concat(actargs, ", ")), true)
+  actargs = { #actlist } -- Actionlist offset is 1st arg to next dasm_put().
+  secpos = 1 -- The actionlist offset occupies a buffer position, too.
+end
+
+-- Put escaped word.
+local function wputw(n)
+  if n >= 0xff000000 then waction("ESC") end
+  wputxw(n)
+end
+
+-- Reserve position for word.
+local function wpos()
+  local pos = #actlist+1
+  actlist[pos] = ""
+  return pos
+end
+
+-- Store word to reserved position.
+local function wputpos(pos, n)
+  assert(n >= 0 and n <= 0xffffffff and n % 1 == 0, "word out of range")
+  actlist[pos] = n
+end
+
+------------------------------------------------------------------------------
+
+-- Global label name -> global label number. With auto assignment on 1st use.
+local next_global = 20
+local map_global = setmetatable({}, { __index = function(t, name)
+  if not match(name, "^[%a_][%w_]*$") then werror("bad global label") end
+  local n = next_global
+  if n > 2047 then werror("too many global labels") end
+  next_global = n + 1
+  t[name] = n
+  return n
+end})
+
+-- Dump global labels.
+local function dumpglobals(out, lvl)
+  local t = {}
+  for name, n in pairs(map_global) do t[n] = name end
+  out:write("Global labels:\n")
+  for i=20,next_global-1 do
+    out:write(format("  %s\n", t[i]))
+  end
+  out:write("\n")
+end
+
+-- Write global label enum.
+local function writeglobals(out, prefix)
+  local t = {}
+  for name, n in pairs(map_global) do t[n] = name end
+  out:write("enum {\n")
+  for i=20,next_global-1 do
+    out:write("  ", prefix, t[i], ",\n")
+  end
+  out:write("  ", prefix, "_MAX\n};\n")
+end
+
+-- Write global label names.
+local function writeglobalnames(out, name)
+  local t = {}
+  for name, n in pairs(map_global) do t[n] = name end
+  out:write("static const char *const ", name, "[] = {\n")
+  for i=20,next_global-1 do
+    out:write("  \"", t[i], "\",\n")
+  end
+  out:write("  (const char *)0\n};\n")
+end
+
+------------------------------------------------------------------------------
+
+-- Extern label name -> extern label number. With auto assignment on 1st use.
+local next_extern = 0
+local map_extern_ = {}
+local map_extern = setmetatable({}, { __index = function(t, name)
+  -- No restrictions on the name for now.
+  local n = next_extern
+  if n > 2047 then werror("too many extern labels") end
+  next_extern = n + 1
+  t[name] = n
+  map_extern_[n] = name
+  return n
+end})
+
+-- Dump extern labels.
+local function dumpexterns(out, lvl)
+  out:write("Extern labels:\n")
+  for i=0,next_extern-1 do
+    out:write(format("  %s\n", map_extern_[i]))
+  end
+  out:write("\n")
+end
+
+-- Write extern label names.
+local function writeexternnames(out, name)
+  out:write("static const char *const ", name, "[] = {\n")
+  for i=0,next_extern-1 do
+    out:write("  \"", map_extern_[i], "\",\n")
+  end
+  out:write("  (const char *)0\n};\n")
+end
+
+------------------------------------------------------------------------------
+
+-- Arch-specific maps.
+local map_archdef = { sp="r3", ra="r1" } -- Ext. register name -> int. name.
+
+local map_type = {}		-- Type name -> { ctype, reg }
+local ctypenum = 0		-- Type number (for Dt... macros).
+
+-- Reverse defines for registers.
+function _M.revdef(s)
+  if s == "r3" then return "sp"
+  elseif s == "r1" then return "ra" end
+  return s
+end
+
+------------------------------------------------------------------------------
+
+-- Template strings for LoongArch instructions.
+local map_op = {
+  ["clo.w_2"] =		"00001000DJ",
+  ["clz.w_2"] =		"00001400DJ",
+  ["cto.w_2"] =		"00001800DJ",
+  ["ctz.w_2"] =		"00001c00DJ",
+  ["clo.d_2"] =		"00002000DJ",
+  ["clz.d_2"] =		"00002400DJ",
+  ["cto.d_2"] =		"00002800DJ",
+  ["ctz.d_2"] =		"00002c00DJ",
+  ["revb.2h_2"] =	"00003000DJ",
+  ["revb.4h_2"] =	"00003400DJ",
+  ["revb.2w_2"] =	"00003800DJ",
+  ["revb.d_2"] = 	"00003c00DJ",
+  ["revh.2w_2"] =	"00004000DJ",
+  ["revh.d_2"] =	"00004400DJ",
+  ["bitrev.4b_2"] =	"00004800DJ",
+  ["bitrev.8b_2"] =	"00004c00DJ",
+  ["bitrev.w_2"] =	"00005000DJ",
+  ["bitrev.d_2"] =	"00005400DJ",
+  ["ext.w.h_2"] =	"00005800DJ",
+  ["ext.w.b_2"] =	"00005c00DJ",
+
+  ["add.w_3"] =		"00100000DJK",
+  ["add.d_3"] =		"00108000DJK",
+  ["sub.w_3"] =		"00110000DJK",
+  ["sub.d_3"] =		"00118000DJK",
+  slt_3 = 		"00120000DJK",
+  sltu_3 =		"00128000DJK",
+  maskeqz_3 = 		"00130000DJK",
+  masknez_3 =		"00138000DJK",
+
+  nor_3 =		"00140000DJK",
+  and_3 = 		"00148000DJK",
+  or_3 = 		"00150000DJK",
+  xor_3 = 		"00158000DJK",
+  orn_3 =		"00160000DJK",
+  andn_3 = 		"00168000DJK",
+  ["sll.w_3"] =		"00170000DJK",
+  ["srl.w_3"] =		"00178000DJK",
+  ["sra.w_3"] = 	"00180000DJK",
+  ["sll.d_3"] =		"00188000DJK",
+  ["srl.d_3"] =		"00190000DJK",
+  ["sra.d_3"] =		"00198000DJK",
+  ["rotr.w_3"] =	"001b0000DJK",
+  ["rotr.d_3"] =	"001b8000DJK",
+  ["mul.w_3"] =		"001c0000DJK",
+  ["mulh.w_3"] = 	"001c8000DJK",
+  ["mulh.wu_3"] =	"001d0000DJK",
+  ["mul.d_3"] =		"001d8000DJK",
+  ["mulh.d_3"] =	"001e0000DJK",
+  ["mulh.du_3"] =	"001e8000DJK",
+  ["mulw.d.w_3"] =	"001f0000DJK",
+  ["mulw.d.wu_3"] =	"001f8000DJK",
+
+  ["fabs.h_2"] =	"01140000FG",
+  ["fabs.s_2"] = 	"01140400FG",
+  ["fabs.d_2"] =	"01140800FG",
+  ["fneg.h_2"] =	"01141000FG",
+  ["fneg.s_2"] =	"01141400FG",
+  ["fneg.d_2"] =	"01141800FG",
+  ["flogb.h_2"] =	"01142000FG",
+  ["flogb.s_2"] =	"01142400FG",
+  ["flogb.d_2"] =	"01142800FG",
+  ["fclass.h_2"] =	"01143000FG",
+  ["fclass.s_2"] =	"01143400FG",
+  ["fclass.d_2"] =	"01143800FG",
+  ["fsqrt.h_2"] =	"01144000FG",
+  ["fsqrt.s_2"] =	"01144400FG",
+  ["fsqrt.d_2"] =	"01144800FG",
+  ["frecip.h_2"] = 	"01145000FG",
+  ["frecip.s_2"] =	"01145400FG",
+  ["frecip.d_2"] =	"01145800FG",
+  ["frsqrt.h_2"] =	"01146000FG",
+  ["frsqrt.s_2"] =	"01146400FG",
+  ["frsqrt.d_2"] =	"01146800FG",
+  ["frecipe.h_2"] =	"01147000FG",
+  ["frecipe.s_2"] =	"01147400FG",
+  ["frecipe.d_2"] =	"01147800FG",
+  ["frsqrte.h_2"] =	"01148000FG",
+  ["frsqrte.s_2"] =	"01148400FG",
+  ["frsqrte.d_2"] =	"01148800FG",
+
+  ["fmov.h_2"] =	"01149000FG",
+  ["fmov.s_2"] =	"01149400FG",
+  ["fmov.d_2"] =	"01149800FG",
+  ["movgr2fr.h_2"] =	"0114a000FJ",
+  ["movgr2fr.w_2"] =	"0114a400FJ",
+  ["movgr2fr.d_2"] =	"0114a800FJ",
+  ["movgr2frh.w_2"] =	"0114ac00FJ",
+  ["movfr2gr.h_2"] =	"0114b000DG",
+  ["movfr2gr.s_2"] =	"0114b400DG",
+  ["movfr2gr.d_2"] =	"0114b800DG",
+  ["movfrh2gr.s_2"] =	"0114bc00DG",
+  movgr2fcsr_2 =	"0114c000SG",
+  movfcsr2gr_2 =	"0114c800FR",
+  movfr2cf_2 =		"0114d000EG",
+  movcf2fr_2 =		"0114d400FA",
+  movgr2cf_2 =		"0114d800EG",
+  movcf2gr_2 =		"0114dc00DA",
+  ["fcvt.ld.d_2"] =	"0114e000FG",
+  ["fcvt.ud.d_2"] =	"0114e400FG",
+  ["fcvt.s.d_2"] = 	"01191800FG",
+  ["fcvt.d.s_2"] =	"01192400FG",
+  ["ftintrm.w.s_2"] =	"011a0400FG",
+  ["ftintrm.w.d_2"] =	"011a0800FG",
+  ["ftintrm.l.s_2"] =	"011a2400FG",
+  ["ftintrm.l.d_2"] =	"011a2800FG",
+  ["ftintrp.w.s_2"] =	"011a4400FG",
+  ["ftintrp.w.d_2"] =	"011a4800FG",
+  ["ftintrp.l.s_2"] =	"011a6400FG",
+  ["ftintrp.l.d_2"] =	"011a6800FG",
+  ["ftintrz.w.s_2"] =	"011a8400FG",
+  ["ftintrz.w.d_2"] =	"011a8800FG",
+  ["ftintrz.l.s_2"] =	"011aa400FG",
+  ["ftintrz.l.d_2"] =	"011aa800FG",
+  ["ftintrne.w.s_2"] =	"011ac400FG",
+  ["ftintrne.w.d_2"] =	"011ac800FG",
+  ["ftintrne.l.s_2"] =	"011ae400FG",
+  ["ftintrne.l.d_2"] =	"011ae800FG",
+  ["ftint.w.s_2"] =	"011b0400FG",
+  ["ftint.w.d_2"] =	"011b0800FG",
+  ["ftint.l.s_2"] =	"011b2400FG",
+  ["ftint.l.d_2"] =	"011b2800FG",
+  ["ffint.s.w_2"] =	"011d1000FG",
+  ["ffint.s.l_2"] =	"011d1800FG",
+  ["ffint.d.w_2"] =	"011d2000FG",
+  ["ffint.d.l_2"] =	"011d2800FG",
+  ["frint.s_2"] =	"011e4400FG",
+  ["frint.d_2"] =	"011e4800FG",
+
+  ["fadd.h_3"] =	"01000000FGH",
+  ["fadd.s_3"] =	"01008000FGH",
+  ["fadd.d_3"] =	"01010000FGH",
+  ["fsub.h_3"] =	"01020000FGH",
+  ["fsub.s_3"] =	"01028000FGH",
+  ["fsub.d_3"] =	"01030000FGH",
+  ["fmul.h_3"] =	"01040000FGH",
+  ["fmul.s_3"] =	"01048000FGH",
+  ["fmul.d_3"] =	"01050000FGH",
+  ["fdiv.h_3"] =	"01060000FGH",
+  ["fdiv.s_3"] =	"01068000FGH",
+  ["fdiv.d_3"] =	"01070000FGH",
+  ["fmax.h_3"] =	"01080000FGH",
+  ["fmax.s_3"] =	"01088000FGH",
+  ["fmax.d_3"] =	"01090000FGH",
+  ["fmin.h_3"] = 	"010a0000FGH",
+  ["fmin.s_3"] =	"010a8000FGH",
+  ["fmin.d_3"] =	"010b0000FGH",
+  ["fmaxa.h_3"] =	"010c0000FGH",
+  ["fmaxa.s_3"] =	"010c8000FGH",
+  ["fmaxa.d_3"] =	"010d0000FGH",
+  ["fmina.h_3"] =	"010e0000FGH",
+  ["fmina.s_3"] =	"010e8000FGH",
+  ["fmina.d_3"] =	"010f0000FGH",
+  ["fscaleb.h_3"] =	"01100000FGH",
+  ["fscaleb.s_3"] =	"01108000FGH",
+  ["fscaleb.d_3"] =	"01110000FGH",
+  ["fcopysign.h_3"] =	"01120000FGH",
+  ["fcopysign.s_3"] =	"01128000FGH",
+  ["fcopysign.d_3"] =	"01130000FGH",
+
+  ["alsl.w_4"] =	"00040000DJKQ",
+  ["alsl.wu_4"] =	"00060000DJKQ",
+  ["alsl.d_4"] =	"002c0000DJKQ",
+  ["bytepick.w_4"] =	"00080000DJKQ",
+  ["bytepick.d_4"] =	"000c0000DJKB",
+
+  ["div.w_3"] = 	"00200000DJK",
+  ["mod.w_3"] =		"00208000DJK",
+  ["div.wu_3"] =	"00210000DJK",
+  ["mod.wu_3"] =	"00218000DJK",
+  ["div.d_3"] =		"00220000DJK",
+  ["mod.d_3"] =		"00228000DJK",
+  ["div.du_3"] =	"00230000DJK",
+  ["mod.du_3"] =	"00238000DJK",
+  ["crc.w.b.w_3"] =	"00240000DJK",
+  ["crc.w.h.w_3"] =	"00248000DJK",
+  ["crc.w.w.w_3"] =	"00250000DJK",
+  ["crc.w.d.w_3"] =	"00258000DJK",
+  ["crcc.w.b.w_3"] =	"00260000DJK",
+  ["crcc.w.h.w_3"] =	"00268000DJK",
+  ["crcc.w.w.w_3"] =	"00270000DJK",
+  ["crcc.w.d.w_3"] =	"00278000DJK",
+
+  break_1 =		"002a0000C",
+  syscall_1 =		"002b0000C",
+
+  ["slli.w_3"] =	"00408000DJU",
+  ["slli.d_3"] =	"00410000DJV",
+  ["srli.w_3"] =	"00448000DJU",
+  ["srli.d_3"] =	"00450000DJV",
+  ["srai.w_3"] =	"00488000DJU",
+  ["srai.d_3"] =	"00490000DJV",
+  ["rotri.w_3"] =	"004c8000DJU",
+  ["rotri.d_3"] =	"004d0000DJV",
+
+  ["bstrins.w_4"] =	"00600000DJMU",
+  ["bstrpick.w_4"] =	"00608000DJMU",
+  ["bstrins.d_4"] = 	"00800000DJNV",
+  ["bstrpick.d_4"] =	"00c00000DJNV",
+  slti_3 =		"02000000DJX",
+  sltui_3 =		"02400000DJX",
+  ["addi.w_3"] =	"02800000DJX",
+  ["addi.d_3"] =	"02c00000DJX",
+  ["lu52i.d_3"] =	"03000000DJX",
+  andi_3 =		"03400000DJT",
+  ori_3 =		"03800000DJT",
+  xori_3 = 		"03c00000DJT",
+  ["lu12i.w_2"] =	"14000000DZ",
+  ["lu32i.d_2"] =	"16000000DZ",
+  pcaddi_2 =		"18000000DZ",
+  pcalau12i_2 = 	"1a000000DZ",
+  pcaddu12i_2 =		"1c000000DZ",
+  pcaddu18i_2 = 	"1e000000DZ",
+
+  ["ldx.b_3"] =		"38000000DJK",
+  ["ldx.h_3"] =		"38040000DJK",
+  ["ldx.w_3"] =		"38080000DJK",
+  ["ldx.d_3"] =		"380c0000DJK",
+  ["stx.b_3"] =		"38100000DJK",
+  ["stx.h_3"] =		"38140000DJK",
+  ["stx.w_3"] =		"38180000DJK",
+  ["stx.d_3"] =		"381c0000DJK",
+  ["ldx.bu_3"] =	"38200000DJK",
+  ["ldx.hu_3"] =	"38240000DJK",
+  ["ldx.wu_3"] =	"38280000DJK",
+  ["fldx.s_3"] =	"38300000FJK",
+  ["fldx.d_3"] =	"38340000FJK",
+  ["fstx.s_3"] =	"38380000FJK",
+  ["fstx.d_3"] =	"383c0000FJK",
+  ["fldgt.s_3"] =	"38740000FJK",
+  ["fldgt.d_3"] =	"38748000FJK",
+  ["fldle.s_3"] =	"38750000FJK",
+  ["fldle.d_3"] =	"38758000FJK",
+  ["fstgt.s_3"] =	"38760000FJK",
+  ["fstgt.d_3"] =	"38768000FJK",
+  ["fstle.s_3"] =	"38770000FJK",
+  ["fstle.d_3"] =	"38778000FJK",
+  ["ldgt.b_3"] =	"38780000DJK",
+  ["ldgt.h_3"] =	"38788000DJK",
+  ["ldgt.w_3"] =	"38790000DJK",
+  ["ldgt.d_3"] =	"38798000DJK",
+  ["ldle.b_3"] =	"387a0000DJK",
+  ["ldle.h_3"] =	"387a8000DJK",
+  ["ldle.w_3"] =	"387b0000DJK",
+  ["ldle.d_3"] =	"387b8000DJK",
+  ["stgt.b_3"] =	"387c0000DJK",
+  ["stgt.h_3"] =	"387c8000DJK",
+  ["stgt.w_3"] =	"387d0000DJK",
+  ["stgt.d_3"] =	"387d8000DJK",
+  ["stle.b_3"] =	"387e0000DJK",
+  ["stle.h_3"] =	"387e8000DJK",
+  ["stle.w_3"] =	"387f0000DJK",
+  ["stle.d_3"] =	"387f8000DJK",
+
+  ["ll.w_3"] =		"20000000DJW",
+  ["sc.w_3"] =		"21000000DJW",
+  ["ll.d_3"] =		"22000000DJW",
+  ["sc.d_3"] =		"23000000DJW",
+  ["ldptr.w_3"] =	"24000000DJW",
+  ["stptr.w_3"] =	"25000000DJW",
+  ["ldptr.d_3"] =	"26000000DJW",
+  ["stptr.d_3"] =	"27000000DJW",
+
+  ["ld.b_3"] =		"28000000DJX",
+  ["ld.h_3"] =		"28400000DJX",
+  ["ld.w_2"] =		"28800000Do",
+  ["ld.d_2"] =		"28c00000Do",
+  ["st.b_2"] =		"29000000Do",
+  ["st.h_2"] =		"29400000Do",
+  ["st.w_2"] =		"29800000Do",
+  ["st.d_2"] =		"29c00000Do",
+  ["ld.bu_2"] =		"2a000000Do",
+  ["ld.hu_2"] =		"2a400000Do",
+  ["ld.wu_3"] =		"2a800000DJX",
+  ["ldx.d_3"] =		"380c0000DJK",
+  ["stx.d_3"] =		"381c0000DJK",
+  ["fld.s_2"] =		"2b000000Fo",
+  ["fst.s_2"] =		"2b400000Fo",
+  ["fld.d_2"] =		"2b800000Fo",
+  ["fst.d_2"] =		"2bc00000Fo",
+
+  ["fcmp.caf.s_3"] =	"0c100000EGH",
+  ["fcmp.saf.s_3"] =	"0c108000EGH",
+  ["fcmp.clt.s_3"] =	"0c110000EGH",
+  ["fcmp.slt.s_3"] =	"0c118000EGH",
+  ["fcmp.ceq.s_3"] =	"0c120000EGH",
+  ["fcmp.seq.s_3"] =	"0c128000EGH",
+  ["fcmp.cle.s_3"] =	"0c130000EGH",
+  ["fcmp.sle.s_3"] =	"0c138000EGH",
+  ["fcmp.cun.s_3"] =	"0c140000EGH",
+  ["fcmp.sun.s_3"] =	"0c148000EGH",
+  ["fcmp.cult.s_3"] =	"0c150000EGH",		--TODO
+  ["fcmp.sult.s_3"] =	"0c158000EGH",
+  ["fcmp.cueq.s_3"] =	"0c160000EGH",
+  ["fcmp.sueq.s_3"] =	"0c168000EGH",
+  ["fcmp.cule.s_3"] =	"0c170000EGH",
+  ["fcmp.sule.s_3"] =	"0c178000EGH",
+  ["fcmp.cne.s_3"] =	"0c180000EGH",
+  ["fcmp.sne.s_3"] =	"0c188000EGH",
+  ["fcmp.cor.s_3"] =	"0c1a0000EGH",
+  ["fcmp.sor.s_3"] =	"0c1a8000EGH",
+  ["fcmp.cune.s_3"] =	"0c1c0000EGH",
+  ["fcmp.sune.s_3"] =	"0c1c8000EGH",
+  ["fcmp.caf.d_3"] =	"0c200000EGH",
+  ["fcmp.saf.d_3"] =	"0c208000EGH",
+  ["fcmp.clt.d_3"] =	"0c210000EGH",
+  ["fcmp.slt.d_3"] =	"0c218000EGH",
+  ["fcmp.ceq.d_3"] =	"0c220000EGH",
+  ["fcmp.seq.d_3"] =	"0c228000EGH",
+  ["fcmp.cle.d_3"] =	"0c230000EGH",
+  ["fcmp.sle.d_3"] =	"0c238000EGH",
+  ["fcmp.cun.d_3"] =	"0c240000EGH",
+  ["fcmp.sun.d_3"] =	"0c248000EGH",
+  ["fcmp.cult.d_3"] =	"0c250000EGH",		--TODO
+  ["fcmp.sult.d_3"] =	"0c258000EGH",
+  ["fcmp.cueq.d_3"] =	"0c260000EGH",
+  ["fcmp.sueq.d_3"] =	"0c268000EGH",
+  ["fcmp.cule.d_3"] =	"0c270000EGH",
+  ["fcmp.sule.d_3"] =	"0c278000EGH",
+  ["fcmp.cne.d_3"] =	"0c280000EGH",
+  ["fcmp.sne.d_3"] =	"0c288000EGH",
+  ["fcmp.cor.d_3"] =	"0c2a0000EGH",
+  ["fcmp.sor.d_3"] =	"0c2a8000EGH",
+  ["fcmp.cune.d_3"] =	"0c2c0000EGH",
+  ["fcmp.sune.d_3"] =	"0c2c8000EGH",
+
+  fsel_4 =		"0d000000FGHI",
+
+  ["addu16i.d_3"] = 	"10000000DJY",
+  beqz_2 =		"40000000JL",
+  bnez_2 = 		"44000000JL",
+  bceqz_2 = 		"48000000AL",
+  bcnez_2 = 		"48000100AL",
+  jirl_3 =		"4c000000DJa",
+  b_1 =			"50000000P",
+  bl_1 =		"54000000P",
+  beq_3 =		"58000000JDO",
+  bne_3 = 		"5c000000JDO",
+  blt_3 = 		"60000000JDO",
+  bge_3 = 		"64000000JDO",
+  bltu_3 = 		"68000000JDO",
+  bgeu_3 = 		"6c000000JDO",
+}
+
+------------------------------------------------------------------------------
+
+local function parse_gpr(expr)
+  local tname, ovreg = match(expr, "^([%w_]+):(r[1-3]?[0-9])$")
+  local tp = map_type[tname or expr]
+  if tp then
+    local reg = ovreg or tp.reg
+    if not reg then
+      werror("type `"..(tname or expr).."' needs a register override")
+    end
+    expr = reg
+  end
+  local r = match(expr, "^r([1-3]?[0-9])$")
+  if r then
+    r = tonumber(r)
+    if r <= 31 then return r, tp end
+  end
+  werror("bad register name `"..expr.."'")
+end
+
+local function parse_fpr(expr)
+  local r = match(expr, "^f([1-3]?[0-9])$")
+  if r then
+    r = tonumber(r)
+    if r <= 31 then return r end
+  end
+  werror("bad register name `"..expr.."'")
+end
+
+local function parse_fcsr(expr)
+  local r = match(expr, "^fcsr([0-3])$")
+  if r then
+    r = tonumber(r)
+    return r
+  end
+  werror("bad register name `"..expr.."'")
+end
+
+local function parse_fcc(expr)
+  local r = match(expr, "^fcc([0-7])$")
+  if r then
+    r = tonumber(r)
+    return r
+  end
+  werror("bad register name `"..expr.."'")
+end
+
+local function parse_imm(imm, bits, shift, scale, signed, action)
+  local n = tonumber(imm)
+  if n then
+    local m = sar(n, scale)
+    if shl(m, scale) == n then
+      if signed then
+	local s = sar(m, bits-1)
+	if s == 0 then return shl(m, shift)
+	elseif s == -1 then return shl(m + shl(1, bits), shift) end
+      else
+	if sar(m, bits) == 0 then return shl(m, shift) end
+      end
+    end
+    werror("out of range immediate1 `"..imm.."'")
+  elseif match(imm, "^[rf]([1-3]?[0-9])$") or
+	 match(imm, "^([%w_]+):([rf][1-3]?[0-9])$") then
+    werror("expected immediate operand, got register")
+  else
+    waction(action or "IMM",
+	    (signed and 32768 or 0)+shl(scale, 10)+shl(bits, 5)+shift, imm)
+    return 0
+  end
+end
+
+local function parse_imm21or26(imm, i)
+  local n = tonumber(imm)
+  if n then
+    -- signed
+    local m = sar(n, 0)
+    if shl(m, 0) == n then
+      local s = sar(m, i-1)
+      if s == 0 then
+        return shl(sub(m, 1, 16), 10) + shl(sub(m, 17, i), 0)
+      elseif s == -1 then
+        return shl(sub(m, 1, 16), 10) + shl(sub(m, 17, i), 0)	--TODO
+      end
+    end
+    werror("out of range immediate2 `"..imm.."'")
+  else
+    waction("IMM2", 0, imm)	--TODO
+    return 0
+  end
+end
+
+local function parse_disp(disp)
+  local imm, reg = match(disp, "^(.*)%(([%w_:]+)%)$")
+  if imm then
+    local r = shl(parse_gpr(reg), 5)
+    local extname = match(imm, "^extern%s+(%S+)$")
+    if extname then
+      waction("REL_EXT", map_extern[extname], nil, 1)
+      return r
+    else
+      return r + parse_imm(imm, 12, 10, 0, true)
+    end
+  end
+  local reg, tailr = match(disp, "^([%w_:]+)%s*(.*)$")
+  if reg and tailr ~= "" then
+    local r, tp = parse_gpr(reg)
+    if tp then
+      waction("IMM", 32768+12*32+10, format(tp.ctypefmt, tailr))
+      return shl(r, 5)
+    end
+  end
+  werror("bad displacement `"..disp.."'")
+end
+
+local function parse_label(label, def)
+  local prefix = sub(label, 1, 2)
+  -- =>label (pc label reference)
+  if prefix == "=>" then
+    return "PC", 0, sub(label, 3)
+  end
+  -- ->name (global label reference)
+  if prefix == "->" then
+    return "LG", map_global[sub(label, 3)]
+  end
+  if def then
+    -- [1-9] (local label definition)
+    if match(label, "^[1-9]$") then
+      return "LG", 10+tonumber(label)
+    end
+  else
+    -- [<>][1-9] (local label reference)
+    local dir, lnum = match(label, "^([<>])([1-9])$")
+    if dir then -- Fwd: 1-9, Bkwd: 11-19.
+      return "LG", lnum + (dir == ">" and 0 or 10)
+    end
+    -- extern label (extern label reference)
+    local extname = match(label, "^extern%s+(%S+)$")
+    if extname then
+      return "EXT", map_extern[extname]
+    end
+  end
+  werror("bad label `"..label.."'")
+end
+
+local function branch_type(op)
+  if shr(op, 26) == 0x16 or shr(op, 26) == 0x17 or shr(op, 26) == 0x18 or
+     shr(op, 26) == 0x19 or shr(op, 26) == 0x1a or shr(op, 26) == 0x1b then
+    return 0 -- BEQ, BNE, BLT, BGE, BLTU, BGEU
+  elseif shr(op, 26) == 0x10 or shr(op, 26) == 0x11 or shr(op, 26) == 0x12 then
+    return 0x5000 -- BEQZ, BNEZ, BCEQZ, BCNEZ
+  elseif band(op, 0xf8000000) == 0x50000000 then return 0xa000 --B, BL
+  else
+    assert(false, "unknown branch type")
+  end
+end
+
+------------------------------------------------------------------------------
+
+-- Handle opcodes defined with template strings.
+map_op[".template__"] = function(params, template, nparams)
+  if not params then return sub(template, 9) end
+  local op = tonumber(sub(template, 1, 8), 16)
+  local n = 1
+
+  -- Limit number of section buffer positions used by a single dasm_put().
+  -- A single opcode needs a maximum of 2 positions (ins/ext).
+  if secpos+2 > maxsecpos then wflush() end
+  local pos = wpos()
+
+  -- Process each character.
+  for p in gmatch(sub(template, 9), ".") do
+    if p == "D" then
+      op = op + shl(parse_gpr(params[n]), 0); n = n + 1
+    elseif p == "J" then
+      op = op + shl(parse_gpr(params[n]), 5); n = n + 1
+    elseif p == "K" then
+      op = op + shl(parse_gpr(params[n]), 10); n = n + 1
+    elseif p == "F" then
+      op = op + shl(parse_fpr(params[n]), 0); n = n + 1
+    elseif p == "G" then
+      op = op + shl(parse_fpr(params[n]), 5); n = n + 1
+    elseif p == "H" then
+      op = op + shl(parse_fpr(params[n]), 10); n = n + 1
+    elseif p == "I" then
+      op = op + shl(parse_fcc(params[n]), 15); n = n + 1
+    elseif p == "A" then
+      op = op + shl(parse_fcc(params[n]), 5); n = n + 1
+    elseif p == "E" then
+      op = op + shl(parse_fcc(params[n]), 0); n = n + 1
+    elseif op == "S" then
+      op = op + shl(parse_fcsr(params[n]), 0); n = n + 1
+    elseif op == "R" then
+      op = op + shl(parse_fcsr(params[n]), 5); n = n + 1
+    elseif p == "U" then
+      op = op + parse_imm(params[n], 5, 10, 0, false); n = n + 1
+    elseif p == "V" then
+      op = op + parse_imm(params[n], 6, 10, 0, false); n = n + 1
+    elseif p == "W" then
+      op = op + parse_imm(params[n], 14, 10, 0, true); n = n + 1
+    elseif p == "X" then
+      op = op + parse_imm(params[n], 12, 10, 0, true); n = n + 1
+    elseif p == "o" then
+      op = op + parse_disp(params[n]); n = n + 1
+    elseif p == "Y" then
+      op = op + parse_imm(params[n], 16, 10, 0, true); n = n + 1
+    elseif p == "Z" then
+      op = op + parse_imm(params[n], 20, 5, 0, true); n = n + 1
+    elseif p == "T" then
+      op = op + parse_imm(params[n], 12, 10, 0, false); n = n + 1
+    elseif p == "C" then
+      op = op + parse_imm(params[n], 15, 0, 0, false); n = n + 1
+    elseif p == "Q" then
+      op = op + parse_imm(params[n], 2, 15, 0, false); n = n + 1
+    elseif p == "B" then
+      op = op + parse_imm(params[n], 3, 15, 0, false); n = n + 1
+    elseif p == "M" then
+      op = op + parse_imm(params[n], 5, 16, 0, false); n = n + 1
+    elseif p == "N" then
+      op = op + parse_imm(params[n], 6, 16, 0, false); n = n + 1
+--    elseif p == "O" then
+--      op = op + parse_imm(params[n], 16, 10, 0, true); n = n + 1
+--    elseif p == "L" then
+--      op = op + parse_imm21or26(params[n], 21); n = n + 1
+--    elseif p == "P" then
+--      op = op + parse_imm21or26(params[n], 26); n = n + 1
+    elseif p == "O" or p == "L" or p == "P" then
+      local mode, m, s = parse_label(params[n], false)
+      local v = branch_type(op)
+      waction("REL_"..mode, m+v, s, 1)
+      n = n + 1
+    elseif p == "a" then
+      op = op + parse_imm(params[n], 16, 10, 0, true); n = n + 1
+    else
+      assert(false)
+    end
+  end
+  wputpos(pos, op)
+end
+
+------------------------------------------------------------------------------
+
+-- Pseudo-opcode to mark the position where the action list is to be emitted.
+map_op[".actionlist_1"] = function(params)
+  if not params then return "cvar" end
+  local name = params[1] -- No syntax check. You get to keep the pieces.
+  wline(function(out) writeactions(out, name) end)
+end
+
+-- Pseudo-opcode to mark the position where the global enum is to be emitted.
+map_op[".globals_1"] = function(params)
+  if not params then return "prefix" end
+  local prefix = params[1] -- No syntax check. You get to keep the pieces.
+  wline(function(out) writeglobals(out, prefix) end)
+end
+
+-- Pseudo-opcode to mark the position where the global names are to be emitted.
+map_op[".globalnames_1"] = function(params)
+  if not params then return "cvar" end
+  local name = params[1] -- No syntax check. You get to keep the pieces.
+  wline(function(out) writeglobalnames(out, name) end)
+end
+
+-- Pseudo-opcode to mark the position where the extern names are to be emitted.
+map_op[".externnames_1"] = function(params)
+  if not params then return "cvar" end
+  local name = params[1] -- No syntax check. You get to keep the pieces.
+  wline(function(out) writeexternnames(out, name) end)
+end
+
+------------------------------------------------------------------------------
+
+-- Label pseudo-opcode (converted from trailing colon form).
+map_op[".label_1"] = function(params)
+  if not params then return "[1-9] | ->global | =>pcexpr" end
+  if secpos+1 > maxsecpos then wflush() end
+  local mode, n, s = parse_label(params[1], true)
+  if mode == "EXT" then werror("bad label definition") end
+  waction("LABEL_"..mode, n, s, 1)
+end
+
+------------------------------------------------------------------------------
+
+-- Pseudo-opcodes for data storage.
+map_op[".long_*"] = function(params)
+  if not params then return "imm..." end
+  for _,p in ipairs(params) do
+    local n = tonumber(p)
+    if not n then werror("bad immediate `"..p.."'") end
+    if n < 0 then n = n + 2^32 end
+    wputw(n)
+    if secpos+2 > maxsecpos then wflush() end
+  end
+end
+
+-- Alignment pseudo-opcode.
+map_op[".align_1"] = function(params)
+  if not params then return "numpow2" end
+  if secpos+1 > maxsecpos then wflush() end
+  local align = tonumber(params[1])
+  if align then
+    local x = align
+    -- Must be a power of 2 in the range (2 ... 256).
+    for i=1,8 do
+      x = x / 2
+      if x == 1 then
+	waction("ALIGN", align-1, nil, 1) -- Action byte is 2**n-1.
+	return
+      end
+    end
+  end
+  werror("bad alignment")
+end
+
+------------------------------------------------------------------------------
+
+-- Pseudo-opcode for (primitive) type definitions (map to C types).
+map_op[".type_3"] = function(params, nparams)
+  if not params then
+    return nparams == 2 and "name, ctype" or "name, ctype, reg"
+  end
+  local name, ctype, reg = params[1], params[2], params[3]
+  if not match(name, "^[%a_][%w_]*$") then
+    werror("bad type name `"..name.."'")
+  end
+  local tp = map_type[name]
+  if tp then
+    werror("duplicate type `"..name.."'")
+  end
+  -- Add #type to defines. A bit unclean to put it in map_archdef.
+  map_archdef["#"..name] = "sizeof("..ctype..")"
+  -- Add new type and emit shortcut define.
+  local num = ctypenum + 1
+  map_type[name] = {
+    ctype = ctype,
+    ctypefmt = format("Dt%X(%%s)", num),
+    reg = reg,
+  }
+  wline(format("#define Dt%X(_V) (int)(ptrdiff_t)&(((%s *)0)_V)", num, ctype))
+  ctypenum = num
+end
+map_op[".type_2"] = map_op[".type_3"]
+
+-- Dump type definitions.
+local function dumptypes(out, lvl)
+  local t = {}
+  for name in pairs(map_type) do t[#t+1] = name end
+  sort(t)
+  out:write("Type definitions:\n")
+  for _,name in ipairs(t) do
+    local tp = map_type[name]
+    local reg = tp.reg or ""
+    out:write(format("  %-20s %-20s %s\n", name, tp.ctype, reg))
+  end
+  out:write("\n")
+end
+
+------------------------------------------------------------------------------
+
+-- Set the current section.
+function _M.section(num)
+  waction("SECTION", num)
+  wflush(true) -- SECTION is a terminal action.
+end
+
+------------------------------------------------------------------------------
+
+-- Dump architecture description.
+function _M.dumparch(out)
+  out:write(format("DynASM %s version %s, released %s\n\n",
+    _info.arch, _info.version, _info.release))
+  dumpactions(out)
+end
+
+-- Dump all user defined elements.
+function _M.dumpdef(out, lvl)
+  dumptypes(out, lvl)
+  dumpglobals(out, lvl)
+  dumpexterns(out, lvl)
+end
+
+------------------------------------------------------------------------------
+
+-- Pass callbacks from/to the DynASM core.
+function _M.passcb(wl, we, wf, ww)
+  wline, werror, wfatal, wwarn = wl, we, wf, ww
+  return wflush
+end
+
+-- Setup the arch-specific module.
+function _M.setup(arch, opt)
+  g_arch, g_opt = arch, opt
+end
+
+-- Merge the core maps and the arch-specific maps.
+function _M.mergemaps(map_coreop, map_def)
+  setmetatable(map_op, { __index = map_coreop })
+  setmetatable(map_def, { __index = map_archdef })
+  return map_op, map_def
+end
+
+return _M
+
+------------------------------------------------------------------------------
+
diff --git a/libs/luajit/LuaJIT-src/src/Makefile b/libs/luajit/LuaJIT-src/src/Makefile
index 34c5e97..cb3fc00 100644
--- a/libs/luajit/LuaJIT-src/src/Makefile
+++ b/libs/luajit/LuaJIT-src/src/Makefile
@@ -36,7 +36,7 @@ CC= $(DEFAULT_CC)
 # to slow down the C part by not omitting it. Debugging, tracebacks and
 # unwinding are not affected -- the assembler part has frame unwind
 # information and GCC emits it where needed (x64) or with -g (see CCDEBUG).
-CCOPT= -O2 -fomit-frame-pointer
+CCOPT= -O0 -fomit-frame-pointer
 # Use this if you want to generate a smaller binary (but it's slower):
 #CCOPT= -Os -fomit-frame-pointer
 # Note: it's no longer recommended to use -O3 with GCC 4.x.
@@ -53,6 +53,7 @@ CCOPT_arm=
 CCOPT_arm64=
 CCOPT_ppc=
 CCOPT_mips=
+CCOPT_loongarch64=
 #
 CCDEBUG=
 # Uncomment the next line to generate debug information:
@@ -241,6 +242,10 @@ else
 ifneq (,$(findstring LJ_TARGET_ARM ,$(TARGET_TESTARCH)))
   TARGET_LJARCH= arm
 else
+ifneq (,$(findstring LJ_TARGET_LOONGARCH64 ,$(TARGET_TESTARCH)))
+  TARGET_ARCH= -DLJ_ARCH_ENDIAN=LUAJIT_LE
+  TARGET_LJARCH= loongarch64
+else
 ifneq (,$(findstring LJ_TARGET_ARM64 ,$(TARGET_TESTARCH)))
   ifneq (,$(findstring __AARCH64EB__ ,$(TARGET_TESTARCH)))
     TARGET_ARCH= -D__AARCH64EB__=1
@@ -272,6 +277,7 @@ endif
 endif
 endif
 endif
+endif
 
 ifneq (,$(findstring LJ_TARGET_PS3 1,$(TARGET_TESTARCH)))
   TARGET_SYS= PS3
diff --git a/libs/luajit/LuaJIT-src/src/host/buildvm.c b/libs/luajit/LuaJIT-src/src/host/buildvm.c
index 98a7a57..8e96cb4 100644
--- a/libs/luajit/LuaJIT-src/src/host/buildvm.c
+++ b/libs/luajit/LuaJIT-src/src/host/buildvm.c
@@ -65,6 +65,8 @@ static int collect_reloc(BuildCtx *ctx, uint8_t *addr, int idx, int type);
 #include "../dynasm/dasm_ppc.h"
 #elif LJ_TARGET_MIPS
 #include "../dynasm/dasm_mips.h"
+#elif LJ_TARGET_LOONGARCH64
+#include "../dynasm/dasm_loongarch64.h"
 #else
 #error "No support for this architecture (yet)"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/host/buildvm_asm.c b/libs/luajit/LuaJIT-src/src/host/buildvm_asm.c
index ffd1490..bc9ab7f 100644
--- a/libs/luajit/LuaJIT-src/src/host/buildvm_asm.c
+++ b/libs/luajit/LuaJIT-src/src/host/buildvm_asm.c
@@ -164,6 +164,15 @@ static void emit_asm_wordreloc(BuildCtx *ctx, uint8_t *p, int n,
 	  "Error: unsupported opcode %08x for %s symbol relocation.\n",
 	  ins, sym);
   exit(1);
+#elif LJ_TARGET_LOONGARCH64
+  if ((ins >> 26) == 21) {
+    fprintf(ctx->fp, "\tbl %s\n", sym);
+  } else {
+    fprintf(stderr,
+            "Error: unsupported opcode %08x for %s symbol relocation.\n",
+            ins, sym);
+    exit(1);
+  }
 #else
 #error "missing relocation support for this architecture"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/jit/bcsave.lua b/libs/luajit/LuaJIT-src/src/jit/bcsave.lua
index c17c88e..79bae42 100644
--- a/libs/luajit/LuaJIT-src/src/jit/bcsave.lua
+++ b/libs/luajit/LuaJIT-src/src/jit/bcsave.lua
@@ -64,7 +64,7 @@ local map_type = {
 
 local map_arch = {
   x86 = true, x64 = true, arm = true, arm64 = true, arm64be = true,
-  ppc = true, mips = true, mipsel = true,
+  ppc = true, mips = true, mipsel = true, loongarch64 = true,
 }
 
 local map_os = {
diff --git a/libs/luajit/LuaJIT-src/src/jit/dis_loongarch64.lua b/libs/luajit/LuaJIT-src/src/jit/dis_loongarch64.lua
new file mode 100644
index 0000000..3e67efc
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/src/jit/dis_loongarch64.lua
@@ -0,0 +1,649 @@
+----------------------------------------------------------------------------
+-- LuaJIT LoongArch disassembler module.
+--
+-- Copyright (C) 2005-2021 Mike Pall. All rights reserved.
+-- Copyright (C) 2021 Loongson Technology. All rights reserved.
+-- Released under the MIT/X license. See Copyright Notice in luajit.h
+----------------------------------------------------------------------------
+-- This is a helper module used by the LuaJIT machine code dumper module.
+--
+-- It disassembles most LoongArch instructions.
+-- NYI: SIMD instructions.
+------------------------------------------------------------------------------
+
+local type = type
+local byte, format = string.byte, string.format
+local match, gmatch = string.match, string.gmatch
+local concat = table.concat
+local bit = require("bit")
+local band, bor, tohex = bit.band, bit.bor, bit.tohex
+local lshift, rshift, arshift = bit.lshift, bit.rshift, bit.arshift
+
+------------------------------------------------------------------------------
+-- Opcode maps
+------------------------------------------------------------------------------
+
+local map_18_0 = {      -- 18-20:0, 10-17
+  shift = 10, mask = 255,
+  [4] = "clo.wDJ",
+  [5] = "clz.wDJ",
+  [6] = "cto.wDJ",
+  [7] = "ctz.wDJ",
+  [8] = "clo.dDJ",
+  [9] = "clz.dDJ",
+  [10] = "cto.dDJ",
+  [11] = "ctz.dDJ",
+  [12] = "revb.2hDJ",
+  [13] = "revb.4hDJ",
+  [14] = "revb.2wDJ",
+  [15] = "revb.dDJ",
+  [16] = "revh.2wDJ",
+  [17] = "revh.dDJ",
+  [18] = "bitrev.4bDJ",
+  [19] = "bitrev.8bDJ",
+  [20] = "bitrev.wDJ",
+  [21] = "bitrev.dDJ",
+  [22] = "ext.w.hDJ",
+  [23] = "ext.w.bDJ",
+}
+
+local map_18_4 = {	-- 18-20:4, 15-17
+  shift = 15, mask = 7,
+  [0] = "add.wDJK",
+  [1] = "add.dDJK",
+  [2] = "sub.wDJK",
+  [3] = "sub.dDJK",
+  [4] = "sltDJK",
+  [5] = "sltuDJK",
+  [6] = "maskeqzDJK",
+  [7] = "masknezDJK",
+}
+
+local map_18_5 = {	-- 18-20:5, 15-17
+  shift = 15, mask = 7,
+  [0] = "norDJK",
+  [1] = "andDJK",
+  [2] = "orDJK",
+  [3] = "xorDJK",
+  [4] = "ornDJK",
+  [5] = "andnDJK",
+  [6] = "sll.wDJK",
+  [7] = "srl.wDJK",
+}
+
+local map_18_6 = {	-- 18-20:6, 15-17
+  shift = 15, mask = 7,
+  [0] = "sra.wDJK",
+  [1] = "sll.dDJK",
+  [2] = "srl.dDJK",
+  [3] = "sra.dDJK",
+  [6] = "rotr.wDJK",
+  [7] = "rotr.dDJK",
+}
+
+local map_18_7 = {	-- 18-20:7, 15-17
+  shift = 15, mask = 7,
+  [0] = "mul.wDJK",
+  [1] = "mulh.wDJK",
+  [2] = "mulh.wuDJK",
+  [3] = "mul.dDJK",
+  [4] = "mulh.dDJK",
+  [5] = "mulh.duDJK",
+  [6] = "mulw.d.wDJK",
+  [7] = "mulw.d.wuDJK",
+}
+
+local map_farith2 = {
+  shift = 10, mask = 31,
+  [0] = "fabs.hFG",
+  [1] = "fabs.sFG",
+  [2] = "fabs.dFG",
+  [4] = "fneg.hFG",
+  [5] = "fneg.sFG",
+  [6] = "fneg.dFG",
+  [8] = "flogb.hFG",
+  [9] = "flogb.sFG",
+  [10] = "flogb.dFG",
+  [12] = "fclass.hFG",
+  [13] = "fclass.sFG",
+  [14] = "fclass.dFG",
+  [16] = "fsqrt.hFG",
+  [17] = "fsqrt.sFG",
+  [18] = "fsqrt.dFG",
+  [20] = "frecip.hFG",
+  [21] = "frecip.sFG",
+  [22] = "frecip.dFG",
+  [24] = "frsqrt.hFG",
+  [25] = "frsqrt.sFG",
+  [26] = "frsqrt.dFG",
+  [28] = "frecipe.hFG",
+  [29] = "frecipe.sFG",
+  [30] = "frecipe.dFG",
+  [32] = "frsqrte.hFG",
+  [33] = "frsqrte.sFG",
+  [34] = "frsqrte.dFG",
+}
+
+local map_fmov = {
+  shift = 10, mask = 31,
+  [4] = "fmov.hFG",
+  [5] = "fmov.sFG",
+  [6] = "fmov.dFG",
+  [8] = "movgr2fr.hFJ",
+  [9] = "movgr2fr.wFJ",
+  [10] = "movgr2fr.dFJ",
+  [11] = "movgr2frh.wFJ",
+  [12] = "movfr2gr.hDG",
+  [13] = "movfr2gr.sDG",
+  [14] = "movfr2gr.dDG",
+  [15] = "movfrh2gr.sDG",
+  [16] = "movgr2fcsrSJ",
+  [18] = "movfcsr2grDR",
+  [20] = { shift = 3, mask = 3, [0] = "movfr2cfEG", },
+  [21] = { shift = 8, mask = 3, [0] = "movcf2frFA", },
+  [22] = { shift = 3, mask = 3, [0] = "movgr2cfEJ", },
+  [23] = { shift = 8, mask = 3, [0] = "movcf2grDA", },
+  [24] = "fcvt.ld.dFG",
+  [25] = "fcvt.ud.dFG",
+}
+
+local map_fconvert = { -- 15-20: 110010
+  shift = 10, mask = 31,
+  [6] = "fcvt.s.dFG",	[9] = "fcvt.d.sFG",
+}
+
+local map_fconvert1 = { -- 15-20: 110100
+  shift = 10, mask = 31,
+  [1] = "ftintrm.w.sFG",
+  [2] = "ftintrm.w.dFG",
+  [9] = "ftintrm.l.sFG",
+  [10] = "ftintrm.l.dFG",
+  [17] = "ftintrp.w.sFG",
+  [18] = "ftintrp.w.dFG",
+  [25] = "ftintrp.l.sFG",
+  [26] = "ftintrp.l.dFG",
+}
+
+local map_fconvert2 = { -- 15-20: 110101
+  shift = 10, mask = 31,
+  [1] = "ftintrz.w.sFG",
+  [2] = "ftintrz.w.dFG",
+  [9] = "ftintrz.l.sFG",
+  [10] = "ftintrz.l.dFG",
+  [17] = "ftintrne.w.sFG",
+  [18] = "ftintrne.w.dFG",
+  [25] = "ftintrne.l.sFG",
+  [26] = "ftintrne.l.dFG",
+}
+
+local map_fconvert3 = { -- 15-20: 110110
+  shift = 10, mask = 31,
+  [1] = "ftint.w.sFG",
+  [2] = "ftint.w.dFG",
+  [9] = "ftint.l.sFG",
+  [10] = "ftint.l.dFG",
+}
+
+local map_fconvert4 = { -- 15-20: 111010
+  shift = 10, mask = 31,
+  [4] = "ffint.s.wFG",
+  [6] =  "ffint.s.lFG",
+  [8] = "ffint.d.wFG",
+  [10] = "ffint.d.lFG",
+}
+
+local map_fconvert5 = { -- 15-20: 111100
+  shift = 10, mask = 31,
+  [17] = "frint.sFG",
+  [18] = "frint.dFG",
+}
+
+local map_farith = {	-- 22-25:4, 15-21
+  shift = 15, mask = 127,
+  [0] = "fadd.hFGH",
+  [1] = "fadd.sFGH",
+  [2] = "fadd.dFGH",
+  [4] = "fsub.hFGH",
+  [5] = "fsub.sFGH",
+  [6] = "fsub.dFGH",
+  [8] = "fmul.hFGH",
+  [9] = "fmul.sFGH",
+  [10] = "fmul.dFGH",
+  [12] = "fdiv.hFGH",
+  [13] = "fdiv.sFGH",
+  [14] = "fdiv.dFGH",
+  [16] = "fmax.hFGH",
+  [17] = "fmax.sFGH",
+  [18] = "fmax.dFGH",
+  [20] = "fmin.hFGH",
+  [21] = "fmin.sFGH",
+  [22] = "fmin.dFGH",
+  [24] = "fmaxa.hFGH",
+  [25] = "fmaxa.sFGH",
+  [26] = "fmaxa.dFGH",
+  [28] = "fmina.hFGH",
+  [29] = "fmina.sFGH",
+  [30] = "fmina.dFGH",
+  [32] = "fscaleb.hFGH",
+  [33] = "fscaleb.sFGH",
+  [34] = "fscaleb.dFGH",
+  [36] = "fcopysign.hFGH",
+  [37] = "fcopysign.sFGH",
+  [38] = "fcopysign.dFGH",
+  [40] = map_farith2, [41] = map_fmov,
+  [50] = map_fconvert, [52] = map_fconvert1,
+  [53] = map_fconvert2, [54] = map_fconvert3,
+  [58] = map_fconvert4, [60] = map_fconvert5,
+}
+
+local map_21_0 = {	--21st:0, 18-20
+  shift = 18, mask = 7,
+  [0] = map_18_0,
+  [1] = { shift = 17, mask = 1, [0] = "alsl.wDJKQ", "alsl.wuDJKQ", },
+  [2] = {shift = 17, mask = 1, [0] = "bytepick.wDJKQ", },
+  [3] = "bytepick.dDJKB",
+  [4] = map_18_4,
+  [5] = map_18_5,
+  [6] = map_18_6,
+  [7] = map_18_7,
+}
+
+local map_21_1 = {      --21st:1, 22nd:0, 15-20
+  shift = 21, mask = 1,
+  [1] = {
+    shift = 18, mask = 7,
+    [0] = {
+      shift = 15, mask = 7,
+      [0] = "div.wDJK",
+      [1] = "mod.wDJK",
+      [2] = "div.wuDJK",
+      [3] = "mod.wuDJK",
+      [4] = "div.dDJK",
+      [5] = "mod.dDJK",
+      [6] = "div.duDJK",
+      [7] = "mod.duDJK",
+    },
+    [1] = {
+      shift = 18, mask = 7,
+      [0] = "crc.w.b.wDJK",
+      [1] = "crc.w.h.wDJK",
+      [2] = "crc.w.w.wDJK",
+      [3] = "crc.w.d.wDJK",
+      [4] = "crcc.w.b.wDJK",
+      [5] = "crcc.w.h.wDJK",
+      [6] = "crcc.w.w.wDJK",
+      [7] = "crcc.w.d.wDJK",
+    },
+    [2] = {
+      shift = 15, mask = 7,
+      [4] = breakC, [6] = syscallC,
+    },
+    [3] = { shift = 17, mask = 1, [0] = "alsl.dDJKQ", },
+  },
+}
+
+local map_22_0 = {
+  shift = 21, mask = 1,
+  [0] = map_21_0,
+  [1] = map_21_1,
+}
+
+local map_shift = {	-- 22nd:1, 21st:0
+  shift = 16, mask = 31,
+  [0] = { shift = 15, mask = 1, [1] = "slli.wDJU", },
+  [1] = "slli.dDJV",
+  [4] = { shift = 15, mask = 1, [1] = "srli.wDJU", },
+  [5] = "srli.dDJV",
+  [8] = { shift = 15, mask = 1, [1] = "srai.wDJU", },
+  [9] = "srai.dDJV",
+  [12] = { shift = 15, mask = 1, [1] = "rotri.wDJU", },
+  [13] = "rotri.dDJV",
+}
+
+local map_22_1 = {        -- 22nd:1
+  shift = 21, mask = 1,
+  [0] = map_shift,
+  [1] = { shift = 15, mask = 1, [0] = "bstrins.wDJMU", [1] = "bstrpick.wDJMU", },
+}
+
+local map_26_0 = {
+  shift = 22, mask = 15,
+  [0] = map_22_0,
+  [1] = map_22_1,
+  [2] = "bstrins.dDJNV",
+  [3] = "bstrpick.dDJNV",
+  [4] = map_farith,
+  [8] = "sltiDJX",
+  [9] = "sltuiDJX",
+  [10] = "addi.wDJX",
+  [11] = "addi.dDJX",
+  [12] = "lu52i.dDJX",
+  [13] = "andiDJT",
+  [14] = "oriDJT",
+  [15] = "xoriDJT",
+}
+
+local map_long_i_5 = { -- Long immediate fixed-point arithmetic.
+  shift = 25, mask = 1,
+  [0] = "lu12i.wDZ",
+  [1] = "lu32i.dDZ",
+}
+
+local map_long_i_6 = {
+  shift = 25, mask = 1,
+  [0] = "pcaddiDZ",
+  [1] = "pcalau12iDZ",
+}
+
+local map_long_i_7 = {
+  shift = 25, mask = 1,
+  [0] = "pcaddu12iDZ",
+  [1] = "pcaddu18iDZ",
+}
+
+local map_ldst0_14 = {
+  shift = 15, mask = 2047,
+  [0] = "ldx.bDJK", [8] = "ldx.hDJK", [16] = "ldx.wDJK",
+  [24] = "ldx.dDJK", [32] = "stx.bDJK", [40] = "stx.hDJK",
+  [48] = "stx.wDJK", [56] = "stx.dDJK", [64] = "ldx.buDJK",
+  [72] = "ldx.huDJK", [80] = "ldx.wuDJK", [96] = "fldx.sFJK",
+  [104] = "fldx.dFJK", [112] = "fstx.sFJK", [120] = "fstx.dFJK",
+  [232] = "fldgt.sFJK", [233] = "fldgt.dFJK", [234] = "fldle.sFJK",
+  [235] = "fldle.dFJK", [236] = "fstgt.sFJK", [237] = "fstgt.dFJK",
+  [238] = "fstle.sFJK", [239] = "fstle.dFJK", [240] = "ldgt.bDJK",
+  [241] = "ldgt.hDJK", [242] = "ldgt.wDJK", [243] = "ldgt.dDJK",
+  [244] = "ldle.bDJK", [245] = "ldle.hDJK", [246] = "ldle.wDJK",
+  [247] = "ldle.dDJK", [248] = "stgt.bDJK", [249] = "stgt.hDJK",
+  [250] = "stgt.wDJK", [251] = "stgt.dDJK", [252] = "stle.bDJK",
+  [253] = "stle.hDJK", [254] = "stle.wDJK", [255] = "stle.dDJK",
+}
+
+local map_ldst1_8 = {
+  shift = 24, mask = 3,
+  [0] = "ll.wDJW",
+  [1] = "sc.wDJW",
+  [2] = "ll.dDJW",
+  [3] = "sc.dDJW",
+}
+
+local map_ldst1_9 = {
+  shift = 24, mask = 3,
+  [0] = "ldptr.wDJW",
+  [1] = "stptr.wDJW",
+  [2] = "ldptr.dDJW",
+  [3] = "stptr.dDJW",
+}
+
+local map_ldst1_10 = {
+  shift = 22, mask = 15,
+  [0] = "ld.bDJX",
+  [1] = "ld.hDJX",
+  [2] = "ld.wDo",
+  [3] = "ld.dDo",
+  [4] = "st.bDo",
+  [5] = "st.hDo",
+  [6] = "st.wDo",
+  [7] = "st.dDo",
+  [8] = "ld.buDo",
+  [9] = "ld.huDo",
+  [10] = "ld.wuDJX",
+  [12] = "fld.sFo",
+  [13] = "fst.sFo",
+  [14] = "fld.dFo",
+  [15] = "fst.dFo",
+}
+
+local map_fcmp0 = {
+  shift = 15, mask = 31,
+  [0] = "fcmp.caf.sEGH",
+  [1] = "fcmp.saf.sEGH",
+  [2] = "fcmp.clt.sEGH",
+  [3] = "fcmp.slt.sEGH",
+  [4] = "fcmp.ceq.sEGH",
+  [5] = "fcmp.seq.sEGH",
+  [6] = "fcmp.cle.sEGH",
+  [7] = "fcmp.sle.sEGH",
+  [8] = "fcmp.cun.sEGH",
+  [9] = "fcmp.sun.sEGH",
+  [10] = "fcmp.cult.sEGH",
+  [11] ="fcmp.sult.sEGH",
+  [12] = "fcmp.cueq.sEGH",
+  [13] = "fcmp.sueq.sEGH",
+  [14] = "fcmp.cule.sEGH",
+  [15] = "fcmp.sule.sEGH",
+  [16] = "fcmp.cne.sEGH",
+  [17] = "fcmp.sne.sEGH",
+  [20] = "fcmp.cor.sEGH",
+  [21] = "fcmp.sor.sEGH",
+  [24] = "fcmp.cune.sEGH",
+  [25] = "fcmp.sune.sEGH",
+}
+
+local map_fcmp1 = {
+  shift = 15, mask = 31,
+  [0] = "fcmp.caf.dEGH",
+  [1] = "fcmp.saf.dEGH",
+  [2] = "fcmp.clt.dEGH",
+  [3] = "fcmp.slt.dEGH",
+  [4] = "fcmp.ceq.dEGH",
+  [5] = "fcmp.seq.dEGH",
+  [6] = "fcmp.cle.dEGH",
+  [7] = "fcmp.sle.dEGH",
+  [8] = "fcmp.cun.dEGH",
+  [9] = "fcmp.sun.dEGH",
+  [10] = "fcmp.cult.dEGH",
+  [11] = "fcmp.sult.dEGH",
+  [12] = "fcmp.cueq.dEGH",
+  [13] = "fcmp.sueq.dEGH",
+  [14] = "fcmp.cule.dEGH",
+  [15] = "fcmp.sule.dEGH",
+  [16] = "fcmp.cne.dEGH",
+  [17] = "fcmp.sne.dEGH",
+  [20] = "fcmp.cor.dEGH",
+  [21] = "fcmp.sor.dEGH",
+  [24] = "fcmp.cune.dEGH",
+  [25] = "fcmp.sune.dEGH",
+}
+
+local map_fcmp = {
+  shift = 20, mask = 63,
+  [1] = { shift = 3, mask = 3, [0] = map_fcmp0, },
+  [2] = { shift = 3, mask = 3, [0] = map_fcmp1, },
+  [16] = { shift = 18, mask = 3, [0] = "fselFGHI", },
+}
+
+local map_init = {
+  shift = 26, mask = 63,
+  [0] = map_26_0,
+  [3] = map_fcmp,
+  [4] = "addu16i.dDJY",
+  [5] = map_long_i_5,
+  [6] = map_long_i_6,
+  [7] = map_long_i_7,
+  [8] = map_ldst1_8,
+  [9] = map_ldst1_9,
+  [10] = map_ldst1_10,
+  [14] = map_ldst0_14,
+  [16] = "beqzJL",
+  [17] = "bnezJL",
+  [18] = { shift = 8, mask = 3, [0] = "bceqzAL", "bcnezAL", },
+  [19] = "jirlDJa",
+  [20] = "bP",
+  [21] = "blP",
+  [22] = "beqJDO",
+  [23] = "bneJDO",
+  [24] = "bltJDO",
+  [25] = "bgeJDO",
+  [26] = "bltuJDO",
+  [27] = "bgeuJDO",
+}
+
+------------------------------------------------------------------------------
+
+local map_gpr = {
+  [0] = "r0", "ra", "r2", "sp", "r4", "r5", "r6", "r7",
+  "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15",
+  "r16", "r17", "r18", "r19", "r20", "r21", "r22", "r23",
+  "r24", "r25", "r26", "r27", "r28", "r29", "r30", "r31",
+}
+
+------------------------------------------------------------------------------
+
+-- Output a nicely formatted line with an opcode and operands.
+local function putop(ctx, text, operands)
+  local pos = ctx.pos
+  local extra = ""
+  if ctx.rel then
+    local sym = ctx.symtab[ctx.rel]
+    if sym then extra = "\t->"..sym end
+  end
+  if ctx.hexdump > 0 then
+    ctx.out(format("%08x  %s  %-7s %s%s\n",
+	    ctx.addr+pos, tohex(ctx.op), text, concat(operands, ", "), extra))
+  else
+    ctx.out(format("%08x  %-7s %s%s\n",
+	    ctx.addr+pos, text, concat(operands, ", "), extra))
+  end
+  ctx.pos = pos + 4
+end
+
+-- Fallback for unknown opcodes.
+local function unknown(ctx)
+  return putop(ctx, ".long", { "0x"..tohex(ctx.op) })
+end
+
+local function get_le(ctx)
+  local pos = ctx.pos
+  local b0, b1, b2, b3 = byte(ctx.code, pos+1, pos+4)
+  return bor(lshift(b3, 24), lshift(b2, 16), lshift(b1, 8), b0)
+end
+
+-- Disassemble a single instruction.
+local function disass_ins(ctx)
+  local op = ctx:get()
+  local operands = {}
+  local last = nil
+  ctx.op = op
+  ctx.rel = nil
+
+  local opat = ctx.map_pri[rshift(op, 26)]
+  while type(opat) ~= "string" do
+    if not opat then return unknown(ctx) end
+    opat = opat[band(rshift(op, opat.shift), opat.mask)]
+  end
+  local name, pat = match(opat, "^([a-z0-9_.]*)(.*)")
+  local altname, pat2 = match(pat, "|([a-z0-9_.|]*)(.*)")
+  if altname then pat = pat2 end
+
+  for p in gmatch(pat, ".") do
+    local x = nil
+    if p == "D" then
+      x = map_gpr[band(rshift(op, 0), 31)]
+    elseif p == "J" then
+      x = map_gpr[band(rshift(op, 5), 31)]
+    elseif p == "K" then
+      x = map_gpr[band(rshift(op, 10), 31)]
+    elseif p == "F" then
+      x = "f"..band(rshift(op, 0), 31)
+    elseif p == "G" then
+      x = "f"..band(rshift(op, 5), 31)
+    elseif p == "H" then
+      x = "f"..band(rshift(op, 10), 31)
+    elseif p == "S" then
+      x = "fcsr"..band(rshift(op, 0), 31)
+    elseif p == "R" then
+      x = "fcsr"..band(rshift(op, 5), 31)
+    elseif p == "E" then
+      x = "fcc"..band(rshift(op, 0), 7)
+    elseif p == "A" then
+      x = "fcc"..band(rshift(op, 5), 7)
+    elseif p == "I" then
+      x = "fcc"..band(rshift(op, 15), 7)
+    elseif p == "Q" then	--TODO sa2
+      x = band(rshift(op, 15), 3)
+    elseif p == "B" then	--TODO sa3
+      x = band(rshift(op, 15), 7)
+    elseif p == "M" then	--TODO msbw
+      x = band(rshift(op, 16), 31)
+    elseif p == "N" then	--TODO msbd
+      x = band(rshift(op, 16), 63)
+    elseif p == "U" then	-- ui5
+      x = band(rshift(op, 10), 31)
+    elseif p == "V" then	-- ui6
+      x = band(rshift(op, 10), 63)
+    elseif p == "T" then	-- ui12
+      x = band(rshift(op, 10), 4095)
+    elseif p == "W" then	-- si14
+      x = band(rshift(op, 10), 16383)
+    elseif p == "X" then	-- si12
+      x = band(rshift(op, 10), 4095)
+    elseif p == "o" then
+      local disp = band((rshift(op, 10)), 0xfff)
+      operands[#operands] = format("%s, %d", last, disp)
+    elseif p == "Y" then	-- si16
+      x = band(rshift(op, 10), 65535)
+    elseif p == "Z" then	-- si20
+      x = band(rshift(op, 10), 1048575)
+    elseif p == "C" then	-- code
+      x = band(rshift(op, 0), 32767)
+    elseif p == "O" then	-- offs[15:0]
+      x = band(rshift(op, 10), 65535)
+    elseif p == "L" then	-- offs[15:0] + offs[20:16]
+      x = lshift(band(op, 31), 16) + band(rshift(op, 10), 65535)
+    elseif p == "P" then	-- offs[15:0] + offs[25:16]
+      x = lshift(band(op, 1023), 16) + band(rshift(op, 10), 65535)
+    elseif p == "a" then
+      x = band(rshift(op, 10), 65535)
+    else
+      assert(false)
+    end
+    if x then operands[#operands+1] = x; last = x end
+  end
+
+  return putop(ctx, name, operands)
+end
+
+------------------------------------------------------------------------------
+
+-- Disassemble a block of code.
+local function disass_block(ctx, ofs, len)
+  if not ofs then ofs = 0 end
+  local stop = len and ofs+len or #ctx.code
+  stop = stop - stop % 4
+  ctx.pos = ofs - ofs % 4
+  ctx.rel = nil
+  while ctx.pos < stop do disass_ins(ctx) end
+end
+
+-- Extended API: create a disassembler context. Then call ctx:disass(ofs, len).
+local function create(code, addr, out)
+  local ctx = {}
+  ctx.code = code
+  ctx.addr = addr or 0
+  ctx.out = out or io.write
+  ctx.symtab = {}
+  ctx.disass = disass_block
+  ctx.hexdump = 8
+  ctx.get = get_le
+  ctx.map_pri = map_init
+  return ctx
+end
+
+-- Simple API: disassemble code (a string) at address and output via out.
+local function disass(code, addr, out)
+  create(code, addr, out):disass()
+end
+
+-- Return register name for RID.
+local function regname(r)
+  if r < 32 then return map_gpr[r] end
+  return "f"..(r-32)
+end
+
+-- Public module functions.
+return {
+  create = create,
+  disass = disass,
+  regname = regname
+}
+
diff --git a/libs/luajit/LuaJIT-src/src/lib_jit.c b/libs/luajit/LuaJIT-src/src/lib_jit.c
index 22ca0a1..09be9eb 100644
--- a/libs/luajit/LuaJIT-src/src/lib_jit.c
+++ b/libs/luajit/LuaJIT-src/src/lib_jit.c
@@ -732,6 +732,10 @@ static uint32_t jit_cpudetect(lua_State *L)
   }
 #endif
 #endif
+
+#elif LJ_TARGET_LOONGARCH64
+  flags |= JIT_F_GS464V;
+
 #else
 #error "Missing CPU detection for this architecture"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_arch.h b/libs/luajit/LuaJIT-src/src/lj_arch.h
index e8ad844..6bdaaaf 100644
--- a/libs/luajit/LuaJIT-src/src/lj_arch.h
+++ b/libs/luajit/LuaJIT-src/src/lj_arch.h
@@ -29,6 +29,8 @@
 #define LUAJIT_ARCH_mips32	6
 #define LUAJIT_ARCH_MIPS64	7
 #define LUAJIT_ARCH_mips64	7
+#define LUAJIT_ARCH_LOONGARCH64	9
+#define LUAJIT_ARCH_loongarch64	9
 
 /* Target OS. */
 #define LUAJIT_OS_OTHER		0
@@ -55,6 +57,8 @@
 #define LUAJIT_TARGET	LUAJIT_ARCH_MIPS64
 #elif defined(__mips__) || defined(__mips) || defined(__MIPS__) || defined(__MIPS)
 #define LUAJIT_TARGET	LUAJIT_ARCH_MIPS32
+#elif defined(__loongarch64__) || defined(__loongarch64) || defined(__LOONGARCH64__) || defined(__LOONGARCH64)
+#define LUAJIT_TARGET	LUAJIT_ARCH_LOONGARCH64
 #else
 #error "No support for this architecture (yet)"
 #endif
@@ -358,6 +362,40 @@
 #define LJ_ARCH_VERSION		10
 #endif
 
+#elif LUAJIT_TARGET == LUAJIT_ARCH_LOONGARCH64
+#define LJ_ARCH_NAME		"loongarch64"
+#define LJ_ARCH_BITS		64
+#define LJ_ARCH_ENDIAN		LUAJIT_LE
+#define LJ_TARGET_LOONGARCH64	1
+#define LJ_TARGET_GC64		1
+#define LJ_TARGET_EHRETREG	4
+#define LJ_TARGET_EHRAREG	30
+#define LJ_TARGET_JUMPRANGE	27	/* 2*2^27 = 256MB-aligned region */
+#define LJ_TARGET_MASKSHIFT	1
+#define LJ_TARGET_MASKROT	1
+#define LJ_TARGET_UNIFYROT	2	/* Want only IR_BROR. */
+#define LJ_ARCH_NUMMODE		LJ_NUMMODE_DUAL
+
+#if !defined(LJ_ARCH_HASFPU)
+#ifdef __loongarch_soft_float
+#define LJ_ARCH_HASFPU		0
+#else
+#define LJ_ARCH_HASFPU		1
+#endif
+#endif
+
+#if !defined(LJ_ABI_SOFTFP)
+#ifdef __loongarch_soft_float
+#define LJ_ABI_SOFTFP		1
+#else
+#define LJ_ABI_SOFTFP		0
+#endif
+#endif
+
+#if LJ_ABI_SOFTFP || !LJ_ARCH_HASFPU
+#define LJ_ARCH_NOJIT		1
+#endif
+
 #else
 #error "No target architecture defined"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_asm.c b/libs/luajit/LuaJIT-src/src/lj_asm.c
index c2cf5a9..72932f8 100644
--- a/libs/luajit/LuaJIT-src/src/lj_asm.c
+++ b/libs/luajit/LuaJIT-src/src/lj_asm.c
@@ -177,6 +177,8 @@ IRFLDEF(FLOFS)
 #include "lj_emit_ppc.h"
 #elif LJ_TARGET_MIPS
 #include "lj_emit_mips.h"
+#elif LJ_TARGET_LOONGARCH64
+#include "lj_emit_loongarch64.h"
 #else
 #error "Missing instruction emitter for target CPU"
 #endif
@@ -1597,6 +1599,8 @@ static void asm_loop(ASMState *as)
 #include "lj_asm_ppc.h"
 #elif LJ_TARGET_MIPS
 #include "lj_asm_mips.h"
+#elif LJ_TARGET_LOONGARCH64
+#include "lj_asm_loongarch64.h"
 #else
 #error "Missing assembler for target CPU"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_asm_loongarch64.h b/libs/luajit/LuaJIT-src/src/lj_asm_loongarch64.h
new file mode 100644
index 0000000..28847cb
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/src/lj_asm_loongarch64.h
@@ -0,0 +1,2272 @@
+/*
+** LoongArch IR assembler (SSA IR -> machine code).
+** Copyright (C) 2005-2021 Mike Pall. See Copyright Notice in luajit.h
+** Copyright (C) 2021 Loongson Technology. All rights reserved.
+*/
+
+/* -- Register allocator extensions --------------------------------------- */
+
+/* Allocate a register with a hint. */
+static Reg ra_hintalloc(ASMState *as, IRRef ref, Reg hint, RegSet allow)
+{
+  Reg r = IR(ref)->r;
+  if (ra_noreg(r)) {
+    if (!ra_hashint(r) && !iscrossref(as, ref))
+      ra_sethint(IR(ref)->r, hint);  /* Propagate register hint. */
+    r = ra_allocref(as, ref, allow);
+  }
+  ra_noweak(as, r);
+  return r;
+}
+
+/* Allocate two source registers for three-operand instructions. */
+static Reg ra_alloc2(ASMState *as, IRIns *ir, RegSet allow)
+{
+  IRIns *irl = IR(ir->op1), *irr = IR(ir->op2);
+  Reg left = irl->r, right = irr->r;
+  if (ra_hasreg(left)) {
+    ra_noweak(as, left);
+    if (ra_noreg(right))
+      right = ra_allocref(as, ir->op2, rset_exclude(allow, left));
+    else
+      ra_noweak(as, right);
+  } else if (ra_hasreg(right)) {
+    ra_noweak(as, right);
+    left = ra_allocref(as, ir->op1, rset_exclude(allow, right));
+  } else if (ra_hashint(right)) {
+    right = ra_allocref(as, ir->op2, allow);
+    left = ra_allocref(as, ir->op1, rset_exclude(allow, right));
+  } else {
+    left = ra_allocref(as, ir->op1, allow);
+    right = ra_allocref(as, ir->op2, rset_exclude(allow, left));
+  }
+  return left | (right << 8);
+}
+
+/* -- Guard handling ------------------------------------------------------ */
+
+/* Setup exit stub after the end of each trace. */
+static void asm_exitstub_setup(ASMState *as)
+{
+  MCode *mxp = as->mctop;
+  if (as->mcp == mxp)
+    --as->mcp;
+  /* st.w TMP, sp, 0; li TMP, traceno; b ->vm_exit_handler;*/
+  *--mxp = LAI_JIRL | RID_R0 | LAF_J(RID_R20) | 0<<10;
+//  *--mxp = LAI_B | LAF_I((uintptr_t)(void *)lj_vm_exit_handler & 0xffff) | (((uintptr_t)(void *)lj_vm_exit_handler >> 16) & 0x3ff);
+  emit_dj32i(as, RID_TMP, RID_ZERO, as->T->traceno);
+  *--mxp = *as->mcp;
+  *--mxp = LAI_LU52I_D | RID_R20 | LAF_J(RID_R20) | ((((uintptr_t)(void *)lj_vm_exit_handler)>>52)&0xfff)<<10;
+  *--mxp = LAI_LU32I_D | RID_R20 | ((((uintptr_t)(void *)lj_vm_exit_handler)>>32)&0xfffff)<<5;
+  *--mxp = LAI_ORI | RID_R20| LAF_J(RID_R20) | (((uintptr_t)(void *)lj_vm_exit_handler)&0xfff) << 10;
+  *--mxp = LAI_LU12I_W | RID_R20 | ((((uintptr_t)(void *)lj_vm_exit_handler)&0xfffff000)>>12)<<5;
+  *--mxp = LAI_ST_W|LAF_D(RID_TMP)|LAF_J(RID_SP)|0;
+  as->mctop = mxp;
+}
+
+/* Keep this in-sync with exitstub_trace_addr(). */
+#define asm_exitstub_addr(as)	((as)->mctop)
+
+/* Emit conditional branch to exit for guard. */
+static void asm_guard(ASMState *as, LAIns lai, Reg rj, Reg rd)
+{
+  MCode *target = asm_exitstub_addr(as);
+  MCode *p = as->mcp;
+  if (LJ_UNLIKELY(p == as->invmcp)) {
+    as->invmcp = NULL;
+    as->loopinv = 1;
+    as->mcp = p;
+    lai = lai ^ ((lai>>28) == 4 ? 0x00000100u : 0x04000000u);  /* Invert cond. BEQ BNE BGE BLZ*/
+    target = p;  /* Patch target later in asm_loop_fixup. */
+  }
+  if (rj == RID_TMP) {
+    emit_branch(as, lai, RID_R20, rd, target);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+  /* move r18, r1*/
+    emit_djk(as, LAI_OR, RID_R20, rj, RID_ZERO);
+  } else {
+    emit_branch(as, lai, rj, rd, target);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+  }
+}
+
+static void asm_guard21(ASMState *as, LAIns lai, Reg rj, Reg rd)
+{
+  MCode *target = asm_exitstub_addr(as);
+  MCode *p = as->mcp;
+  if (LJ_UNLIKELY(p == as->invmcp)) {
+    as->invmcp = NULL;
+    as->loopinv = 1;
+    as->mcp = p;
+    lai = lai ^ ((lai>>28) == 4 ? 0x00000100u : 0x04000000u);  /* Invert cond. BCEQZ BCNEZ*/
+    target = p;  /* Patch target later in asm_loop_fixup. */
+  }
+  if (rj == RID_TMP) {
+    emit_branch21(as, lai, RID_R20, target);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+    /* move r18, r1*/
+    emit_djk(as, LAI_OR, RID_R20, rj, RID_ZERO);
+  } else {
+    emit_branch21(as, lai, rj, target);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+  }
+}
+
+/* -- Operand fusion ------------------------------------------------------ */
+
+/* Limit linear search to this distance. Avoids O(n^2) behavior. */
+#define CONFLICT_SEARCH_LIM	31
+
+/* Check if there's no conflicting instruction between curins and ref. */
+static int noconflict(ASMState *as, IRRef ref, IROp conflict)
+{
+  IRIns *ir = as->ir;
+  IRRef i = as->curins;
+  if (i > ref + CONFLICT_SEARCH_LIM)
+    return 0;  /* Give up, ref is too far away. */
+  while (--i > ref)
+    if (ir[i].o == conflict)
+      return 0;  /* Conflict found. */
+  return 1;  /* Ok, no conflict. */
+}
+
+/* Fuse the array base of colocated arrays. */
+static int32_t asm_fuseabase(ASMState *as, IRRef ref)
+{
+  IRIns *ir = IR(ref);
+  if (ir->o == IR_TNEW && ir->op1 <= LJ_MAX_COLOSIZE &&
+      !neverfuse(as) && noconflict(as, ref, IR_NEWREF))
+    return (int32_t)sizeof(GCtab);
+  return 0;
+}
+
+/* Fuse array/hash/upvalue reference into register+offset operand. */
+static Reg asm_fuseahuref(ASMState *as, IRRef ref, int32_t *ofsp, RegSet allow)	//TODO
+{
+  IRIns *ir = IR(ref);
+  if (ra_noreg(ir->r)) {
+    if (ir->o == IR_AREF) {
+      if (mayfuse(as, ref)) {
+	if (irref_isk(ir->op2)) {
+	  IRRef tab = IR(ir->op1)->op1;
+	  int32_t ofs = asm_fuseabase(as, tab);
+	  IRRef refa = ofs ? tab : ir->op1;
+	  ofs += 8*IR(ir->op2)->i;
+	  if (checki16(ofs)) {
+	    *ofsp = ofs;
+	    return ra_alloc1(as, refa, allow);
+	  }
+	}
+      }
+    } else if (ir->o == IR_HREFK) {
+      if (mayfuse(as, ref)) {
+	int32_t ofs = (int32_t)(IR(ir->op2)->op2 * sizeof(Node));
+	if (checki16(ofs)) {
+	  *ofsp = ofs;
+	  return ra_alloc1(as, ir->op1, allow);
+	}
+      }
+    } else if (ir->o == IR_UREFC) {
+      if (irref_isk(ir->op1)) {
+	GCfunc *fn = ir_kfunc(IR(ir->op1));
+	intptr_t ofs = (intptr_t)&gcref(fn->l.uvptr[(ir->op2 >> 8)])->uv.tv;
+	intptr_t jgl = (intptr_t)J2G(as->J);
+	if ((uintptr_t)(ofs-jgl) < 65536) {
+	  *ofsp = ofs-jgl-32768;
+	  return RID_JGL;
+	} else {
+	  *ofsp = (int16_t)ofs;
+	  return ra_allock(as, ofs-(int16_t)ofs, allow);
+	}
+      }
+    }
+  }
+  *ofsp = 0;
+  return ra_alloc1(as, ref, allow);
+}
+
+/* Fuse XLOAD/XSTORE reference into load/store operand. */
+static void asm_fusexref(ASMState *as, LAIns lai, Reg rd, IRRef ref,	//TODO
+			 RegSet allow, int32_t ofs)
+{
+  IRIns *ir = IR(ref);
+  Reg base;
+  if (ra_noreg(ir->r) && canfuse(as, ir)) {
+    if (ir->o == IR_ADD) {
+      intptr_t ofs2;
+      if (irref_isk(ir->op2) && (ofs2 = ofs + get_kval(as, ir->op2),
+				 checki16(ofs2))) {
+	ref = ir->op1;
+	ofs = (int32_t)ofs2;
+      }
+    } else if (ir->o == IR_STRREF) {
+      intptr_t ofs2 = 65536;
+      lua_assert(ofs == 0);
+      ofs = (int32_t)sizeof(GCstr);
+      if (irref_isk(ir->op2)) {
+	ofs2 = ofs + get_kval(as, ir->op2);
+	ref = ir->op1;
+      } else if (irref_isk(ir->op1)) {
+	ofs2 = ofs + get_kval(as, ir->op1);
+	ref = ir->op2;
+      }
+      if (!checki16(ofs2)) {
+	/* NYI: Fuse ADD with constant. */
+	Reg right, left = ra_alloc2(as, ir, allow);
+	right = (left >> 8); left &= 255;
+	emit_dji(as, lai, rd, RID_TMP, ofs&0xfff);
+	emit_djk(as, LAI_ADD_D, RID_TMP, left, right);
+	return;
+      }
+      ofs = ofs2;
+    }
+  }
+  base = ra_alloc1(as, ref, allow);
+  emit_dji(as, lai, rd, base, ofs&0xfff);
+}
+
+/* -- Calls --------------------------------------------------------------- */
+
+/* Generate a call to a C function. */
+static void asm_gencall(ASMState *as, const CCallInfo *ci, IRRef *args)
+{
+  uint32_t n, nargs = CCI_XNARGS(ci);
+  int32_t ofs = 0;
+#if LJ_SOFTFP
+  Reg gpr = REGARG_FIRSTGPR;
+#else
+  Reg gpr, fpr = REGARG_FIRSTFPR;
+#endif
+  if ((void *)ci->func)
+    emit_call(as, (void *)ci->func);		//TODO
+#if !LJ_SOFTFP
+  for (gpr = REGARG_FIRSTGPR; gpr <= REGARG_LASTGPR; gpr++)
+    as->cost[gpr] = REGCOST(~0u, ASMREF_L);
+  gpr = REGARG_FIRSTGPR;
+#endif
+  for (n = 0; n < nargs; n++) {  /* Setup args. */
+    IRRef ref = args[n];
+    if (ref) {
+      IRIns *ir = IR(ref);
+#if !LJ_SOFTFP
+      if (irt_isfp(ir->t) && fpr <= REGARG_LASTFPR &&
+	  !(ci->flags & CCI_VARARG)) {
+	lua_assert(rset_test(as->freeset, fpr));  /* Already evicted. */
+	ra_leftov(as, fpr, ref);
+	fpr += 1;
+      } else
+#endif
+      {
+	if (gpr <= REGARG_LASTGPR) {
+	  lua_assert(rset_test(as->freeset, gpr));  /* Already evicted. */
+#if !LJ_SOFTFP
+	  if (irt_isfp(ir->t)) {
+	    RegSet of = as->freeset;
+	    Reg r;
+	    /* Workaround to protect argument GPRs from being used for remat. */
+	    as->freeset &= ~RSET_RANGE(REGARG_FIRSTGPR, REGARG_LASTGPR+1);
+	    r = ra_alloc1(as, ref, RSET_FPR);
+	    as->freeset |= (of & RSET_RANGE(REGARG_FIRSTGPR, REGARG_LASTGPR+1));
+	    if (irt_isnum(ir->t)) {
+	      emit_dj(as, LAI_MOVFR2GR_D, gpr, r);
+	      gpr++;
+	    } else if (irt_isfloat(ir->t)) {
+	      emit_dj(as, LAI_MOVFR2GR_S, gpr, r);
+	      gpr++;
+	    }
+	  } else
+#endif
+	  {
+	    ra_leftov(as, gpr, ref);
+	    gpr++;
+	  }
+	} else {
+	  Reg r = ra_alloc1(as, ref, !LJ_SOFTFP && irt_isfp(ir->t) ? RSET_FPR : RSET_GPR);
+	  emit_spstore(as, ir, r, ofs);
+	  ofs += 8;
+	}
+      }
+    } else {
+#if !LJ_SOFTFP
+      fpr = REGARG_LASTFPR+1;
+#endif
+      if (gpr <= REGARG_LASTGPR) {
+	gpr++;
+      } else {
+	ofs += 8;
+      }
+    }
+    checkmclim(as);
+  }
+}
+
+/* Setup result reg/sp for call. Evict scratch regs. */
+static void asm_setupresult(ASMState *as, IRIns *ir, const CCallInfo *ci)
+{
+  RegSet drop = RSET_SCRATCH;
+#if !LJ_SOFTFP
+  if ((ci->flags & CCI_NOFPRCLOBBER))
+    drop &= ~RSET_FPR;
+#endif
+  if (ra_hasreg(ir->r))
+    rset_clear(drop, ir->r);  /* Dest reg handled below. */
+  ra_evictset(as, drop);  /* Evictions must be performed first. */
+  if (ra_used(ir)) {
+    lua_assert(!irt_ispri(ir->t));
+    if (!LJ_SOFTFP && irt_isfp(ir->t)) {
+      if ((ci->flags & CCI_CASTU64)) {
+	int32_t ofs = sps_scale(ir->s);
+	Reg dest = ir->r;
+	if (ra_hasreg(dest)) {
+	  ra_free(as, dest);
+	  ra_modified(as, dest);
+	  emit_dj(as, LAI_MOVGR2FR_D, dest, RID_RET);
+	}
+	if (ofs) {
+	//emit_dji(as, LAI_ST_D, RID_RET, RID_SP, ofs);		//TODO ofs&0xfff?
+	  emit_djk(as, LAI_STX_D, RID_RET, RID_SP, RID_R19);
+	  emit_d16i(as, RID_R19, ofs);
+	}
+      } else {
+	ra_destreg(as, ir, RID_FPRET);
+      }
+    } else {
+      ra_destreg(as, ir, RID_RET);
+    }
+  }
+}
+
+static void asm_callx(ASMState *as, IRIns *ir)
+{
+  IRRef args[CCI_NARGS_MAX*2];
+  CCallInfo ci;
+  IRRef func;
+  IRIns *irf;
+  ci.flags = asm_callx_flags(as, ir);
+  asm_collectargs(as, ir, &ci, args);
+  asm_setupresult(as, ir, &ci);
+  func = ir->op2; irf = IR(func);
+  if (irf->o == IR_CARG) { func = irf->op1; irf = IR(func); }
+  if (irref_isk(func)) {  /* Call to constant address. */
+    ci.func = (ASMFunction)(void *)get_kval(as, func);
+  } else {  /* Need specific register for indirect calls. */
+    Reg r = ra_alloc1(as, func, RID2RSET(RID_CFUNCADDR));
+    MCode *p = as->mcp;
+    *--p = LAI_JIRL | LAF_D(RID_RA) | LAF_J(r);
+    *--p = LAI_MOVE | LAF_D(RID_CFUNCADDR) | LAF_J(r);
+    //*--p = LAI_JIRL | LAF_D(RID_RA) | LAF_J(r);
+    as->mcp = p;
+    ci.func = (ASMFunction)(void *)0;
+  }
+  asm_gencall(as, &ci, args);
+}
+
+#if !LJ_SOFTFP
+static void asm_callround(ASMState *as, IRIns *ir, IRCallID id)
+{
+  /* The modified regs must match with the *.dasc implementation. */
+  RegSet drop = RID2RSET(RID_R12)|RID2RSET(RID_FPRET)|
+		RID2RSET(RID_F23)|RID2RSET(RID_F10)|RID2RSET(REGARG_FIRSTFPR)
+		|RID2RSET(RID_F19);
+  if (ra_hasreg(ir->r)) rset_clear(drop, ir->r);
+  ra_evictset(as, drop);
+  ra_destreg(as, ir, RID_FPRET);
+  emit_call(as, (void *)lj_ir_callinfo[id].func);
+  ra_leftov(as, REGARG_FIRSTFPR, ir->op1);
+}
+#endif
+
+/* -- Returns ------------------------------------------------------------- */
+
+/* Return to lower frame. Guard that it goes to the right spot. */
+static void asm_retf(ASMState *as, IRIns *ir)
+{
+  Reg base = ra_alloc1(as, REF_BASE, RSET_GPR);
+  void *pc = ir_kptr(IR(ir->op2));
+  int32_t delta = 1+LJ_FR2+bc_a(*((const BCIns *)pc - 1));
+  as->topslot -= (BCReg)delta;
+  if ((int32_t)as->topslot < 0) as->topslot = 0;
+  irt_setmark(IR(REF_BASE)->t);  /* Children must not coalesce with BASE reg. */
+  emit_setgl(as, base, jit_base);
+  emit_addptr(as, base, -8*delta);
+  asm_guard(as, LAI_BNE, RID_TMP,
+	    ra_allock(as, igcptr(pc), rset_exclude(RSET_GPR, base)));
+  emit_dji(as, LAI_LD_D, RID_TMP, base, -8&0xfff);
+}
+
+/* -- Buffer operations --------------------------------------------------- */
+
+#if LJ_HASBUFFER
+static void asm_bufhdr_write(ASMState *as, Reg sb)
+{
+  Reg tmp = ra_scratch(as, rset_exclude(RSET_GPR, sb));
+  IRIns irgc;
+  irgc.ot = IRT(0, IRT_PGC);  /* GC type. */
+  emit_storeofs(as, &irgc, RID_TMP, sb, offsetof(SBuf, L));
+  if ((as->flags & JIT_F_GS464V)) {
+      emit_djml(as, LJ_64? LAI_BSTRINS_D : LAI_BSTRINS_W, RID_TMP, tmp, lj_fls(SBUF_MASK_FLAG), 0);
+  } else {
+    emit_djk(as, LAI_OR, RID_TMP, RID_TMP, tmp);
+    emit_dji(as, LAI_ANDI, tmp, tmp, SBUF_MASK_FLAG);
+  }
+  emit_getgl(as, RID_TMP, cur_L);
+  emit_loadofs(as, &irgc, tmp, sb, offsetof(SBuf, L));
+}
+#endif
+
+/* -- Type conversions ---------------------------------------------------- */
+
+#if !LJ_SOFTFP
+static void asm_tointg(ASMState *as, IRIns *ir, Reg left)
+{
+  Reg tmp = ra_scratch(as, rset_exclude(RSET_FPR, left));
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  //asm_guard21(as, LAI_BCEQZ, tmp&7, (tmp&7));
+  asm_guard21(as, LAI_BCEQZ, 0, (tmp&7));
+  //emit_djk(as, LAI_FCMP_CEQ_D, tmp&7, tmp, left);
+  emit_djk(as, LAI_FCMP_CEQ_D, 0, tmp, left);
+  emit_dj(as, LAI_FFINT_D_W, tmp, tmp);
+  emit_dj(as, LAI_MOVFR2GR_S, dest, tmp);
+  emit_dj(as, LAI_FTINT_W_D, tmp, left);
+}
+
+static void asm_tobit(ASMState *as, IRIns *ir)
+{
+  RegSet allow = RSET_FPR;
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg left = ra_alloc1(as, ir->op1, allow);
+  Reg right = ra_alloc1(as, ir->op2, rset_clear(allow, left));
+  Reg tmp = ra_scratch(as, rset_clear(allow, right));
+  emit_dj(as, LAI_MOVFR2GR_S, dest, tmp);
+  emit_djk(as, LAI_FADD_D, tmp, left, right);
+}
+#elif LJ_64  /* && LJ_SOFTFP */
+static void asm_tointg(ASMState *as, IRIns *ir, Reg r)
+{
+  /* The modified regs must match with the *.dasc implementation. */
+  RegSet drop = RID2RSET(REGARG_FIRSTGPR)|RID2RSET(RID_RET)|RID2RSET(RID_RET+1)|
+		RID2RSET(RID_R12);		// r1 -> r19, r12 -> r12
+  if (ra_hasreg(ir->r)) rset_clear(drop, ir->r);
+  ra_evictset(as, drop);
+  /* Return values are in RID_RET (converted value) and RID_RET+1 (status). */
+  ra_destreg(as, ir, RID_RET);
+  asm_guard(as, LAI_BNE, RID_RET+1, RID_ZERO);
+  emit_call(as, (void *)lj_ir_callinfo[IRCALL_lj_vm_tointg].func);
+  if (r == RID_NONE)
+    ra_leftov(as, REGARG_FIRSTGPR, ir->op1);
+  else if (r != REGARG_FIRSTGPR)
+    emit_move(as, REGARG_FIRSTGPR, r);
+}
+
+static void asm_tobit(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  emit_dju(as, LAI_SLLI_W, dest, dest, 0);
+  asm_callid(as, ir, IRCALL_lj_vm_tobit);
+}
+#endif
+
+static void asm_conv(ASMState *as, IRIns *ir)
+{
+  IRType st = (IRType)(ir->op2 & IRCONV_SRCMASK);
+  int stfp = (st == IRT_NUM || st == IRT_FLOAT);
+  int st64 = (st == IRT_I64 || st == IRT_U64 || st == IRT_P64);
+  IRRef lref = ir->op1;
+  lua_assert(irt_type(ir->t) != st);
+#if !LJ_SOFTFP
+  if (irt_isfp(ir->t)) {
+    Reg dest = ra_dest(as, ir, RSET_FPR);
+    if (stfp) {  /* FP to FP conversion. */
+      emit_dj(as, st == IRT_NUM ? LAI_FCVT_S_D : LAI_FCVT_D_S,
+	      dest, ra_alloc1(as, lref, RSET_FPR));
+    } else if (st == IRT_U32) {  /* U32 to FP conversion. */
+      /* y = (x ^ 0x8000000) + 2147483648.0 */
+      Reg left = ra_alloc1(as, lref, RSET_GPR);
+      Reg tmp = ra_scratch(as, rset_exclude(RSET_FPR, dest));
+      if (irt_isfloat(ir->t))
+	emit_dj(as, LAI_FCVT_S_D, dest, dest);
+      /* Must perform arithmetic with doubles to keep the precision. */
+      emit_djk(as, LAI_FADD_D, dest, dest, tmp);
+      emit_dj(as, LAI_FFINT_D_W, dest, dest);
+      emit_lsptr(as, LAI_FLD_D, (tmp & 31),	//TODO emit_lsptr
+		 (void *)&as->J->k64[LJ_K64_2P31], RSET_GPR);
+      emit_dj(as, LAI_MOVGR2FR_W, RID_TMP, dest);
+      emit_djk(as, LAI_XOR, RID_TMP, RID_TMP, left);
+      emit_dji(as, LAI_ADDU16I_D, RID_TMP, RID_R0, 0x8000);
+#if LJ_64
+    } else if(st == IRT_U64) {  /* U64 to FP conversion. */
+      /* if (x >= 1u<<63) y = (double)(int64_t)(x&(1u<<63)-1) + pow(2.0, 63) */
+      Reg left = ra_alloc1(as, lref, RSET_GPR);
+      Reg tmp = ra_scratch(as, rset_exclude(RSET_FPR, dest));
+      MCLabel l_end = emit_label(as);
+      if (irt_isfloat(ir->t)) {
+	emit_djk(as, LAI_FADD_S, dest, dest, tmp);
+	emit_lsptr(as, LAI_FLD_S, (tmp & 31), (void *)&as->J->k32[LJ_K32_2P63],
+		   rset_exclude(RSET_GPR, left));
+	emit_branch(as, LAI_BGE, left, RID_ZERO, l_end);
+	emit_dj(as, LAI_FFINT_S_L, dest, dest);
+      } else {
+	emit_djk(as, LAI_FADD_D, dest, dest, tmp);
+	emit_lsptr(as, LAI_FLD_D, (tmp & 31), (void *)&as->J->k64[LJ_K64_2P63],
+		   rset_exclude(RSET_GPR, left));
+	emit_branch(as, LAI_BGE, left, RID_ZERO, l_end);
+	emit_dj(as, LAI_FFINT_D_L, dest, dest);
+      }
+      //emit_branch(as, LAI_BGE, left, RID_ZERO, l_end);	//TODO
+      emit_dj(as, LAI_MOVGR2FR_D, RID_TMP, dest);
+      emit_djml(as, LAI_BSTRPICK_D, RID_TMP, left, 62, 0);
+#endif
+    } else {  /* Integer to FP conversion. */
+      Reg left = ra_alloc1(as, lref, RSET_GPR);
+      LAIns lai = irt_isfloat(ir->t) ?
+	(st64 ? LAI_FFINT_S_L : LAI_FFINT_S_W) :
+	(st64 ? LAI_FFINT_D_L : LAI_FFINT_D_W);
+      emit_dj(as, lai, dest, dest);
+      emit_dj(as, st64 ? LAI_MOVGR2FR_D : LAI_MOVGR2FR_W, dest, left);
+    }
+  } else if (stfp) {  /* FP to integer conversion. */
+    if (irt_isguard(ir->t)) {
+      /* Checked conversions are only supported from number to int. */
+      lua_assert(irt_isint(ir->t) && st == IRT_NUM);
+      asm_tointg(as, ir, ra_alloc1(as, lref, RSET_FPR));
+    } else {
+      Reg dest = ra_dest(as, ir, RSET_GPR);
+      Reg left = ra_alloc1(as, lref, RSET_FPR);
+      Reg tmp = ra_scratch(as, rset_exclude(RSET_FPR, left));
+      if (irt_isu32(ir->t)) {  /* FP to U32 conversion. */
+	/* y = (int)floor(x - 2147483648.0) ^ 0x80000000 */
+	emit_djk(as, LAI_XOR, dest, dest, RID_TMP);
+	emit_dji(as, LAI_ADDU16I_D, RID_TMP, RID_R0, 0x8000);
+	emit_dj(as, LAI_MOVFR2GR_S, dest, tmp);
+	emit_dj(as, st == IRT_FLOAT ? LAI_FTINTRM_W_S : LAI_FTINTRM_W_D,
+		tmp, tmp);
+	emit_djk(as, st == IRT_FLOAT ? LAI_FSUB_S : LAI_FSUB_D,
+		 tmp, left, tmp);
+	if (st == IRT_FLOAT)
+	  emit_lsptr(as, LAI_FLD_S, (tmp & 31),
+		     (void *)&as->J->k32[LJ_K32_2P31], RSET_GPR);
+	else
+	  emit_lsptr(as, LAI_FLD_D, (tmp & 31),
+		     (void *)&as->J->k64[LJ_K64_2P31], RSET_GPR);
+#if LJ_64
+      } else if (irt_isu64(ir->t)) {  /* FP to U64 conversion. */
+	MCLabel l_end;
+	emit_dj(as, LAI_MOVFR2GR_D, dest, tmp);
+	l_end = emit_label(as);
+	/* For inputs >= 2^63 add -2^64 and convert again. */
+	if (st == IRT_NUM) {
+	  emit_dj(as, LAI_FTINTRZ_L_D, tmp, tmp);
+	  emit_djk(as, LAI_FADD_D, tmp, left, tmp);
+	  emit_lsptr(as, LAI_FLD_D, (tmp & 31),
+		     (void *)&as->J->k64[LJ_K64_M2P64],
+		     rset_exclude(RSET_GPR, dest));
+	  //emit_dj(as, LAI_FTINTRZ_L_D, tmp, left);  /* Delay slot. */ //TODO
+	  //emit_branch21(as, LAI_BCNEZ, (left&7), l_end);
+	  emit_branch21(as, LAI_BCNEZ, 0, l_end);
+	  emit_dj(as, LAI_FTINTRZ_L_D, tmp, left);
+	  //emit_djk(as, LAI_FCMP_CLT_D, left&7, left, tmp);	// TODO
+	  emit_djk(as, LAI_FCMP_CLT_D, 0, left, tmp);
+	  emit_lsptr(as, LAI_FLD_D, (tmp & 31),
+		     (void *)&as->J->k64[LJ_K64_2P63],
+		     rset_exclude(RSET_GPR, dest));
+	} else {
+	  emit_dj(as, LAI_FTINTRZ_L_S, tmp, tmp);
+	  emit_djk(as, LAI_FADD_S, tmp, left, tmp);
+	  emit_lsptr(as, LAI_FLD_S, (tmp & 31),
+		     (void *)&as->J->k32[LJ_K32_M2P64],
+		     rset_exclude(RSET_GPR, dest));
+	  //emit_dj(as, LAI_FTINTRZ_L_S, tmp, left);  /* Delay slot. */ //TODO
+	  //emit_branch21(as, LAI_BCNEZ, (left&7), l_end);
+	  emit_branch21(as, LAI_BCNEZ, 0, l_end);
+	  emit_dj(as, LAI_FTINTRZ_L_S, tmp, left);
+	  //emit_djk(as, LAI_FCMP_CLT_S, left&7, left, tmp);	// TODO
+	  emit_djk(as, LAI_FCMP_CLT_S, 0, left, tmp);
+	  emit_lsptr(as, LAI_FLD_S, (tmp & 31),
+		     (void *)&as->J->k32[LJ_K32_2P63],
+		     rset_exclude(RSET_GPR, dest));
+	}
+#endif
+      } else {
+	LAIns lai = irt_is64(ir->t) ?
+	  (st == IRT_NUM ? LAI_FTINTRZ_L_D : LAI_FTINTRZ_L_S) :
+	  (st == IRT_NUM ? LAI_FTINTRZ_W_D : LAI_FTINTRZ_W_S);
+	emit_dj(as, irt_is64(ir->t) ? LAI_MOVFR2GR_D : LAI_MOVFR2GR_S, dest, left);
+	emit_dj(as, lai, left, left);
+      }
+    }
+  } else
+#else
+  if (irt_isfp(ir->t)) {
+#if LJ_64 && LJ_HASFFI
+    if (stfp) {  /* FP to FP conversion. */
+      asm_callid(as, ir, irt_isnum(ir->t) ? IRCALL_softfp_f2d :
+					    IRCALL_softfp_d2f);
+    } else {  /* Integer to FP conversion. */
+      IRCallID cid = ((IRT_IS64 >> st) & 1) ?
+	(irt_isnum(ir->t) ?
+	 (st == IRT_I64 ? IRCALL_fp64_l2d : IRCALL_fp64_ul2d) :
+	 (st == IRT_I64 ? IRCALL_fp64_l2f : IRCALL_fp64_ul2f)) :
+	(irt_isnum(ir->t) ?
+	 (st == IRT_INT ? IRCALL_softfp_i2d : IRCALL_softfp_ui2d) :
+	 (st == IRT_INT ? IRCALL_softfp_i2f : IRCALL_softfp_ui2f));
+      asm_callid(as, ir, cid);
+    }
+#else
+    asm_callid(as, ir, IRCALL_softfp_i2d);
+#endif
+  } else if (stfp) {  /* FP to integer conversion. */
+    if (irt_isguard(ir->t)) {
+      /* Checked conversions are only supported from number to int. */
+      lua_assert(irt_isint(ir->t) && st == IRT_NUM);
+      asm_tointg(as, ir, RID_NONE);
+    } else {
+      IRCallID cid = irt_is64(ir->t) ?
+	((st == IRT_NUM) ?
+	 (irt_isi64(ir->t) ? IRCALL_fp64_d2l : IRCALL_fp64_d2ul) :
+	 (irt_isi64(ir->t) ? IRCALL_fp64_f2l : IRCALL_fp64_f2ul)) :
+	((st == IRT_NUM) ?
+	 (irt_isint(ir->t) ? IRCALL_softfp_d2i : IRCALL_softfp_d2ui) :
+	 (irt_isint(ir->t) ? IRCALL_softfp_f2i : IRCALL_softfp_f2ui));
+      asm_callid(as, ir, cid);
+    }
+  } else
+#endif
+  {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    if (st >= IRT_I8 && st <= IRT_U16) {  /* Extend to 32 bit integer. */
+      Reg left = ra_alloc1(as, ir->op1, RSET_GPR);
+      lua_assert(irt_isint(ir->t) || irt_isu32(ir->t));
+      if ((ir->op2 & IRCONV_SEXT)) {
+	emit_dj(as, st == IRT_I8 ? LAI_EXT_W_B : LAI_EXT_W_H, dest, left);
+      } else {
+        if (st == IRT_U8) {
+          emit_dju(as, LAI_ANDI, dest, left, (int32_t)0xff);
+        } else {
+          emit_djk(as, LAI_AND, dest, left, RID_R20);
+          //emit_dj32i(as, RID_R20, RID_R0, 0xffff);
+          emit_djml(as, LAI_BSTRPICK_D, RID_R20, RID_R20, 15, 0);		// zero-extend
+          emit_d16i(as, RID_R20, 0xffff);
+        }
+      }
+    } else {  /* 32/64 bit integer conversions. */
+      if (irt_is64(ir->t)) {
+	if (st64) {
+	  /* 64/64 bit no-op (cast)*/
+	  ra_leftov(as, dest, lref);
+	} else {
+	  Reg left = ra_alloc1(as, lref, RSET_GPR);
+	  if ((ir->op2 & IRCONV_SEXT)) {  /* 32 to 64 bit sign extension. */
+	    emit_dju(as, LAI_SLLI_W, dest, left, 0);
+	  } else {  /* 32 to 64 bit zero extension. */
+	    emit_djml(as, LAI_BSTRPICK_D, dest, left, 31, 0);
+	  }
+	}
+      } else {
+	if (st64) {
+	  /* This is either a 32 bit reg/reg mov which zeroes the hiword
+	  ** or a load of the loword from a 64 bit address.
+	  */
+	  Reg left = ra_alloc1(as, lref, RSET_GPR);
+	  emit_djml(as, LAI_BSTRPICK_D, dest, left, 31, 0);
+	} else {  /* 32/32 bit no-op (cast). */
+	  /* Do nothing, but may need to move regs. */
+	  ra_leftov(as, dest, lref);
+	}
+      }
+    }
+  }
+}
+
+static void asm_strto(ASMState *as, IRIns *ir)
+{
+  const CCallInfo *ci = &lj_ir_callinfo[IRCALL_lj_strscan_num];
+  IRRef args[2];
+  int32_t ofs = 0;
+  RegSet drop = RSET_SCRATCH;
+  if (ra_hasreg(ir->r)) rset_set(drop, ir->r);  /* Spill dest reg (if any). */
+  ra_evictset(as, drop);
+  ofs = sps_scale(ir->s);
+  asm_guard(as, LAI_BEQ, RID_RET, RID_ZERO);  /* Test return status. */
+  args[0] = ir->op1;      /* GCstr *str */
+  args[1] = ASMREF_TMP1;  /* TValue *n  */
+  asm_gencall(as, ci, args);
+  /* Store the result to the spill slot or temp slots. */
+  //emit_dji(as, LAI_ADDI_D, ra_releasetmp(as, ASMREF_TMP1),
+	//   RID_SP, ofs&0xfff);
+  emit_djk(as, LAI_ADD_D, ra_releasetmp(as, ASMREF_TMP1), RID_SP, RID_R19);
+  emit_d16i(as, RID_R19, ofs);
+}
+
+/* -- Memory references --------------------------------------------------- */
+
+#if LJ_64
+/* Store tagged value for ref at base+ofs. */
+static void asm_tvstore64(ASMState *as, Reg base, int32_t ofs, IRRef ref)
+{
+  RegSet allow = rset_exclude(RSET_GPR, base);
+  IRIns *ir = IR(ref);
+  lua_assert(irt_ispri(ir->t) || irt_isaddr(ir->t) || irt_isinteger(ir->t));
+  if (irref_isk(ref)) {
+    TValue k;
+    lj_ir_kvalue(as->J->L, &k, ir);
+    //emit_dji(as, LAI_ST_D, ra_allock(as, (int64_t)k.u64, allow), base, ofs&0xfff);
+    emit_djk(as, LAI_STX_D, ra_allock(as, (int64_t)k.u64, allow), base, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+  } else {
+    Reg src = ra_alloc1(as, ref, allow);
+    Reg type = ra_allock(as, (int64_t)irt_toitype(ir->t) << 47,
+			 rset_exclude(allow, src));
+    //emit_dji(as, LAI_ST_D, RID_TMP, base, ofs&0xfff);
+    emit_djk(as, LAI_STX_D, RID_TMP, base, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+    if (irt_isinteger(ir->t)) {
+      emit_djk(as, LAI_ADD_D, RID_TMP, RID_TMP, type);
+      emit_djml(as, LAI_BSTRPICK_D, RID_TMP, src, 31, 0);
+    } else {
+      emit_djk(as, LAI_ADD_D, RID_TMP, src, type);
+    }
+  }
+}
+#endif
+
+/* Get pointer to TValue. */
+static void asm_tvptr(ASMState *as, Reg dest, IRRef ref)
+{
+  IRIns *ir = IR(ref);
+  if (irt_isnum(ir->t)) {
+    if (irref_isk(ref))  /* Use the number constant itself as a TValue. */
+      ra_allockreg(as, igcptr(ir_knum(ir)), dest);
+    else {  /* Otherwise force a spill and use the spill slot. */
+      emit_djk(as, LAI_ADD_D, dest, RID_SP, RID_R19);
+      emit_d16i(as, RID_R19, ra_spill(as, ir));
+    }
+  } else {
+    /* Otherwise use g->tmptv to hold the TValue. */
+    asm_tvstore64(as, dest, 0, ref);
+    emit_djk(as, LAI_ADD_D, dest, RID_JGL, RID_R19);
+    emit_d16i(as, RID_R19, (int32_t)(offsetof(global_State, tmptv)-32768));
+  }
+}
+
+static void asm_aref(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg idx, base;
+  if (irref_isk(ir->op2)) {
+    IRRef tab = IR(ir->op1)->op1;
+    int32_t ofs = asm_fuseabase(as, tab);
+    IRRef refa = ofs ? tab : ir->op1;
+    ofs += 8*IR(ir->op2)->i;
+    if (checki16(ofs)) {
+      base = ra_alloc1(as, refa, RSET_GPR);
+      //emit_dj32i(as, dest, base, ofs);		//TODO
+      emit_djk(as, LAI_ADD_D, dest, base, RID_R19);
+      emit_d16i(as, RID_R19, ofs);
+      return;
+    }
+  }
+  base = ra_alloc1(as, ir->op1, RSET_GPR);
+  idx = ra_alloc1(as, ir->op2, rset_exclude(RSET_GPR, base));
+  // emit_djka(as, LAI_ALSL_D, dest, idx, base, 2);
+  emit_djk(as, LAI_ADD_D, dest, RID_TMP, base);
+  emit_dju(as, LAI_SLLI_D, RID_TMP, idx, 3);
+}
+
+/* Inlined hash lookup. Specialized for key type and for const keys.
+** The equivalent C code is:
+**   Node *n = hashkey(t, key);
+**   do {
+**     if (lj_obj_equal(&n->key, key)) return &n->val;
+**   } while ((n = nextnode(n)));
+**   return niltv(L);
+*/
+static void asm_href(ASMState *as, IRIns *ir, IROp merge)
+{
+  RegSet allow = RSET_GPR;
+  int destused = ra_used(ir);
+  Reg dest = ra_dest(as, ir, allow);
+  Reg tab = ra_alloc1(as, ir->op1, rset_clear(allow, dest));
+  Reg key = RID_NONE, type = RID_NONE, tmpnum = RID_NONE, tmp1 = RID_TMP, tmp2;
+  Reg cmp64 = RID_NONE;
+  IRRef refkey = ir->op2;
+  IRIns *irkey = IR(refkey);
+  int isk = irref_isk(refkey);
+  IRType1 kt = irkey->t;
+  uint32_t khash;
+  MCLabel l_end, l_loop, l_next;
+
+  rset_clear(allow, tab);
+  if (!LJ_SOFTFP && irt_isnum(kt)) {
+    key = ra_alloc1(as, refkey, RSET_FPR);
+    tmpnum = ra_scratch(as, rset_exclude(RSET_FPR, key));
+  } else if (!irt_ispri(kt)) {
+    key = ra_alloc1(as, refkey, allow);
+    rset_clear(allow, key);
+  }
+  tmp2 = ra_scratch(as, allow);
+  rset_clear(allow, tmp2);
+  if (LJ_SOFTFP || !irt_isnum(kt)) {
+    /* Allocate cmp64 register used for 64-bit comparisons */
+    if (LJ_SOFTFP && irt_isnum(kt)) {
+      cmp64 = key;
+    } else if (!isk && irt_isaddr(kt)) {
+      cmp64 = tmp2;
+    } else {
+      int64_t k;
+      if (isk && irt_isaddr(kt)) {
+	k = ((int64_t)irt_toitype(irkey->t) << 47) | irkey[1].tv.u64;
+      } else {
+	lua_assert(irt_ispri(kt) && !irt_isnil(kt));
+	k = ~((int64_t)~irt_toitype(ir->t) << 47);
+      }
+      cmp64 = ra_allock(as, k, allow);
+      rset_clear(allow, cmp64);
+    }
+  }
+
+  /* Key not found in chain: jump to exit (if merged) or load niltv. */
+  l_end = emit_label(as);
+  as->invmcp = NULL;
+  if (merge == IR_NE)
+    asm_guard(as, LAI_BEQ, RID_ZERO, RID_ZERO);
+  else if (destused)
+    emit_loada(as, dest, niltvg(J2G(as->J)));
+  /* Follow hash chain until the end. */
+  l_loop = --as->mcp;
+  emit_move(as, dest, tmp1);
+  //emit_dji(as, LAI_LD_D, tmp1, dest, ((int32_t)offsetof(Node, next))&0xfff);	//TODO si12
+  emit_djk(as, LAI_LDX_D, tmp1, dest, RID_R19);
+  emit_d16i(as, RID_R19, (int32_t)offsetof(Node, next));
+  l_next = emit_label(as);
+
+  /* Type and value comparison. */
+  if (merge == IR_EQ) {  /* Must match asm_guard(). */
+    //emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);		//TODO
+    l_end = asm_exitstub_addr(as);
+  }
+  if (!LJ_SOFTFP && irt_isnum(kt)) {
+    //emit_branch21(as, LAI_BCNEZ, (tmpnum&7), l_end);
+    emit_branch21(as, LAI_BCNEZ, 0, l_end);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+    //emit_djk(as, LAI_FCMP_CEQ_D, tmpnum&7, tmpnum, key);	// TODO
+    emit_djk(as, LAI_FCMP_CEQ_D, 0, tmpnum, key);
+    *--as->mcp = LAI_NOP;  /* Avoid NaN comparison overhead. */
+    emit_branch(as, LAI_BEQ, tmp1, RID_ZERO, l_next);
+    //emit_dji(as, LAI_SLTUI, tmp1, tmp1, ((int32_t)LJ_TISNUM)&0xfff);
+    emit_djk(as, LAI_SLTU, tmp1, tmp1, RID_R19);
+    emit_d16i(as, RID_R19, (int32_t)LJ_TISNUM);
+    emit_dju(as, LAI_SRAI_D, tmp1, tmp1, 47);
+    emit_dj(as, LAI_MOVGR2FR_D, tmpnum, tmp1);
+    //emit_dji(as, LAI_LD_D, tmp1, dest, ((int32_t)offsetof(Node, key.u64))&0xfff);
+    emit_djk(as, LAI_LDX_D, tmp1, dest, RID_R19);
+  } else {
+    emit_branch(as, LAI_BEQ, RID_R20, cmp64, l_end);
+    emit_dj32i(as, RID_TMP, RID_ZERO, as->snapno);
+    emit_djk(as, LAI_OR, RID_R20, RID_R0, tmp1);
+    //emit_dji(as, LAI_LD_D, tmp1, dest, ((int32_t)offsetof(Node, key.u64))&0xfff);
+    emit_djk(as, LAI_LDX_D, tmp1, dest, RID_R19);
+  }
+  emit_d16i(as, RID_R19, (int32_t)offsetof(Node, key.u64));
+  // *l_loop = MIPSI_BNE | MIPSF_S(tmp1) | ((as->mcp-l_loop-1) & 0xffffu);
+  *l_loop = LAI_BNE | LAF_J(tmp1) | LAF_D(RID_ZERO) | LAF_I(((as->mcp-l_loop) & 0xffffu));
+  if (!isk && irt_isaddr(kt)) {
+    type = ra_allock(as, (int64_t)irt_toitype(kt) << 47, allow);
+    emit_djk(as, LAI_ADD_D, tmp2, key, type);
+    rset_clear(allow, type);
+  }
+
+  /* Load main position relative to tab->node into dest. */
+  khash = isk ? ir_khash(irkey) : 1;
+  if (khash == 0) {
+    //emit_dji(as, LAI_LD_D, dest, tab, ((int32_t)offsetof(GCtab, node))&0xfff);
+    emit_djk(as, LAI_LDX_D, dest, tab, RID_R19);
+    emit_d16i(as, RID_R19, (int32_t)offsetof(GCtab, node));
+  } else {
+    Reg tmphash = tmp1;
+    if (isk)
+      tmphash = ra_allock(as, khash, allow);
+    emit_djk(as, LAI_ADD_D, dest, dest, tmp1);
+    lua_assert(sizeof(Node) == 24);
+    emit_djk(as, LAI_SUB_W, tmp1, tmp2, tmp1);
+    emit_dju(as, LAI_SLLI_W, tmp1, tmp1, 3);
+    emit_dju(as, LAI_SLLI_W, tmp2, tmp1, 5);
+    emit_djk(as, LAI_AND, tmp1, tmp2, tmphash);
+    emit_dji(as, LAI_LD_D, dest, tab, ((int32_t)offsetof(GCtab, node))&0xfff);
+    emit_dji(as, LAI_LD_W, tmp2, tab, ((int32_t)offsetof(GCtab, hmask))&0xfff);
+    if (isk) {
+      /* Nothing to do. */
+    } else if (irt_isstr(kt)) {
+      emit_dji(as, LAI_LD_W, tmp1, key, ((int32_t)offsetof(GCstr, hash))&0xfff);
+    } else {  /* Must match with hash*() in lj_tab.c. */
+      emit_djk(as, LAI_SUB_W, tmp1, tmp1, tmp2);
+      emit_rotr(as, tmp2, tmp2, dest, (-HASH_ROT3)&31);		//TODO
+      emit_djk(as, LAI_XOR, tmp1, tmp1, tmp2);
+      emit_rotr(as, tmp1, tmp1, dest, (-HASH_ROT2-HASH_ROT1)&31);	//TODO
+      emit_djk(as, LAI_SUB_W, tmp2, tmp2, dest);
+      emit_djk(as, LAI_XOR, tmp2, tmp2, tmp1);
+      emit_dju(as, LAI_ROTRI_W, dest, tmp1, (-HASH_ROT1)&31);
+      if (irt_isnum(kt)) {
+	emit_djk(as, LAI_ADD_W, tmp1, tmp1, tmp1);
+	emit_dju(as, LAI_SRAI_D, tmp1, LJ_SOFTFP ? key : tmp1, 32);
+	emit_dju(as, LAI_SLLI_W, tmp2, LJ_SOFTFP ? key : tmp1, 0);
+#if !LJ_SOFTFP
+	emit_dj(as, LAI_MOVFR2GR_D, tmp1, key);
+#endif
+      } else {
+	checkmclim(as);
+	emit_dju(as, LAI_SRAI_D, tmp1, tmp1, 32);
+	emit_dju(as, LAI_SLLI_W, tmp2, key, 0);
+	emit_djk(as, LAI_ADD_D, tmp1, key, type);
+      }
+    }
+  }
+}
+
+static void asm_hrefk(ASMState *as, IRIns *ir)
+{
+  IRIns *kslot = IR(ir->op2);
+  IRIns *irkey = IR(kslot->op1);
+  int32_t ofs = (int32_t)(kslot->op2 * sizeof(Node));
+  int32_t kofs = ofs + (int32_t)offsetof(Node, key);
+  Reg dest = (ra_used(ir)||ofs > 32736) ? ra_dest(as, ir, RSET_GPR) : RID_NONE;		//TODO
+  Reg node = ra_alloc1(as, ir->op1, RSET_GPR);
+  RegSet allow = rset_exclude(RSET_GPR, node);
+  Reg idx = node;
+  Reg key = ra_scratch(as, allow);
+  int64_t k;
+  lua_assert(ofs % sizeof(Node) == 0);
+  if (ofs > 32736) {		//TODO why 32736 ?
+    idx = dest;
+    rset_clear(allow, dest);
+    kofs = (int32_t)offsetof(Node, key);
+  } else if (ra_hasreg(dest)) {
+    // emit_dj32i(as, dest, node, ofs);
+    //emit_add(as, dest, node, ofs);
+    emit_djk(as, LAI_ADD_D, dest, node, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+  }
+  if (irt_ispri(irkey->t)) {
+    lua_assert(!irt_isnil(irkey->t));
+    k = ~((int64_t)~irt_toitype(irkey->t) << 47);
+  } else if (irt_isnum(irkey->t)) {
+    k = (int64_t)ir_knum(irkey)->u64;
+  } else {
+    k = ((int64_t)irt_toitype(irkey->t) << 47) | (int64_t)ir_kgc(irkey);
+  }
+  asm_guard(as, LAI_BNE, key, ra_allock(as, k, allow));
+  //emit_dji(as, LAI_LD_D, key, idx, kofs&0xfff);	//TODO si12
+  emit_djk(as, LAI_LDX_D, key, idx, RID_R19);
+  emit_d16i(as, RID_R19, kofs);
+  if (ofs > 32736)
+    emit_djk(as, LAI_ADD_D, dest, node, ra_allock(as, ofs, allow));
+}
+
+static void asm_uref(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  if (irref_isk(ir->op1)) {
+    GCfunc *fn = ir_kfunc(IR(ir->op1));
+    MRef *v = &gcref(fn->l.uvptr[(ir->op2 >> 8)])->uv.v;
+    emit_lsptr(as, LAI_LD_D, dest, v, RSET_GPR);
+  } else {
+    Reg uv = ra_scratch(as, RSET_GPR);
+    Reg func = ra_alloc1(as, ir->op1, RSET_GPR);
+    if (ir->o == IR_UREFC) {
+      asm_guard(as, LAI_BEQ, RID_TMP, RID_ZERO);
+      emit_dji(as, LAI_ADDI_D, dest, uv, ((int32_t)offsetof(GCupval, tv))&0xfff);	//TODO si12
+      emit_dji(as, LAI_LD_BU, RID_TMP, uv, ((int32_t)offsetof(GCupval, closed))&0xfff);
+    } else {
+      emit_dji(as, LAI_LD_D, dest, uv, ((int32_t)offsetof(GCupval, v))&0xfff);
+    }
+    //emit_dji(as, LAI_LD_D, uv, func, ((int32_t)offsetof(GCfuncL, uvptr) +
+	  //   (int32_t)sizeof(MRef) * (int32_t)(ir->op2 >> 8))&0xfff);
+    emit_djk(as, LAI_LDX_D, uv, func, RID_R19);
+    emit_d16i(as, RID_R19, (int32_t)offsetof(GCfuncL, uvptr) +
+      (int32_t)sizeof(MRef) * (int32_t)(ir->op2 >> 8));
+  }
+}
+
+static void asm_fref(ASMState *as, IRIns *ir)
+{
+  UNUSED(as); UNUSED(ir);
+  lua_assert(!ra_used(ir));
+}
+
+static void asm_strref(ASMState *as, IRIns *ir)
+{
+  RegSet allow = RSET_GPR;
+  Reg dest = ra_dest(as, ir, allow);
+  Reg base = ra_alloc1(as, ir->op1, allow);
+  IRIns *irr = IR(ir->op2);
+  int32_t ofs = sizeof(GCstr);
+  rset_clear(allow, base);
+  if (irref_isk(ir->op2) && checki16(ofs + irr->i)) {		//TODO checki16
+    // emit_tsi(as, MIPSI_DADDIU, dest, base, ofs + irr->i);
+    //emit_dj32i(as, dest, base, ofs + irr->i);
+    emit_djk(as, LAI_ADD_D, dest, base, RID_R19);
+    emit_d16i(as, RID_R19, (ofs + irr->i));
+  } else {
+    // emit_tsi(as, MIPSI_DADDIU, dest, dest, ofs);
+    //emit_dj32i(as, dest, dest, ofs);				//TODO
+    emit_djk(as, LAI_ADD_D, dest, dest, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+    emit_djk(as, LAI_ADD_D, dest, base, ra_alloc1(as, ir->op2, allow));
+  }
+}
+
+/* -- Loads and stores ---------------------------------------------------- */
+
+static LAIns asm_fxloadins(ASMState *as, IRIns *ir)
+{
+  UNUSED(as);
+  switch (irt_type(ir->t)) {
+  case IRT_I8: return LAI_LD_B;
+  case IRT_U8: return LAI_LD_BU;
+  case IRT_I16: return LAI_LD_H;
+  case IRT_U16: return LAI_LD_HU;
+  case IRT_NUM:
+    lua_assert(!LJ_SOFTFP32);
+    if (!LJ_SOFTFP) return LAI_FLD_D;
+  /* fallthrough */
+  case IRT_FLOAT: if (!LJ_SOFTFP) return LAI_FLD_S;
+  /* fallthrough */
+  default: return (LJ_64 && irt_is64(ir->t)) ? LAI_LD_D : LAI_LD_W;
+  }
+}
+
+static LAIns asm_fxstoreins(ASMState *as, IRIns *ir)
+{
+  UNUSED(as);
+  switch (irt_type(ir->t)) {
+  case IRT_I8: case IRT_U8: return LAI_ST_B;
+  case IRT_I16: case IRT_U16: return LAI_ST_H;
+  case IRT_NUM:
+    lua_assert(!LJ_SOFTFP32);
+    if (!LJ_SOFTFP) return LAI_FST_D;
+  /* fallthrough */
+  case IRT_FLOAT: if (!LJ_SOFTFP) return LAI_FST_S;
+  /* fallthrough */
+  default: return (LJ_64 && irt_is64(ir->t)) ? LAI_ST_D : LAI_ST_W;
+  }
+}
+
+static void asm_fload(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  LAIns lai = asm_fxloadins(as, ir);
+  Reg idx;
+  int32_t ofs;
+  if (ir->op1 == REF_NIL) {  /* FLOAD from GG_State with offset. */
+    idx = RID_JGL;
+    ofs = (ir->op2 << 2) - 32768 - GG_OFS(g);	//TODO
+  } else {
+    idx = ra_alloc1(as, ir->op1, RSET_GPR);
+    if (ir->op2 == IRFL_TAB_ARRAY) {
+      ofs = asm_fuseabase(as, ir->op1);
+      if (ofs) {  /* Turn the t->array load into an add for colocated arrays. */
+	//emit_dji(as, LAI_ADDI_D, dest, idx, ofs&0xfff);
+	emit_djk(as, LAI_ADD_D, dest, idx, RID_R19);
+	emit_d16i(as, RID_R19, ofs);
+	return;
+      }
+    }
+    ofs = field_ofs[ir->op2];
+  }
+  lua_assert(!irt_isfp(ir->t));
+  // emit_dji(as, lai, dest, idx, ofs&0xfff);
+  /* li r17, ofs; ldx.d/w dest, idx, r17 */
+  switch (lai) {
+  case LAI_LD_B:
+    lai = LAI_LDX_B;
+    break;
+  case LAI_LD_BU:
+    lai = LAI_LDX_BU;
+    break;
+  case LAI_LD_H:
+    lai = LAI_LDX_H;
+    break;
+  case LAI_LD_HU:
+    lai = LAI_LDX_HU;
+    break;
+  case LAI_LD_D:
+    lai = LAI_LDX_D;
+    break;
+  case LAI_LD_W:
+    lai = LAI_LDX_W;
+    break;
+  case LAI_FLD_D:
+    lai = LAI_FLDX_D;
+    break;
+  case LAI_FLD_S:
+    lai = LAI_FLDX_S;
+    break;
+  default:
+    break;
+  }
+  emit_djk(as, lai, dest, idx, RID_R19);
+  //emit_loadi(as, RID_R19, ofs);
+  emit_d16i(as, RID_R19, ofs);
+}
+
+static void asm_fstore(ASMState *as, IRIns *ir)
+{
+  if (ir->r != RID_SINK) {
+    Reg src = ra_alloc1(as, ir->op2, RSET_GPR);
+    IRIns *irf = IR(ir->op1);
+    Reg idx = ra_alloc1(as, irf->op1, rset_exclude(RSET_GPR, src));
+    int32_t ofs = field_ofs[irf->op2];
+    LAIns lai = asm_fxstoreins(as, ir);
+    lua_assert(!irt_isfp(ir->t));
+    emit_dji(as, lai, src, idx, ofs&0xfff);
+  }
+}
+
+static void asm_xload(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir,
+    (!LJ_SOFTFP && irt_isfp(ir->t)) ? RSET_FPR : RSET_GPR);
+  lua_assert(LJ_TARGET_UNALIGNED || !(ir->op2 & IRXLOAD_UNALIGNED));
+  asm_fusexref(as, asm_fxloadins(as, ir), dest, ir->op1, RSET_GPR, 0);
+}
+
+static void asm_xstore_(ASMState *as, IRIns *ir, int32_t ofs)
+{
+  if (ir->r != RID_SINK) {
+    Reg src = ra_alloc1(as, ir->op2,
+      (!LJ_SOFTFP && irt_isfp(ir->t)) ? RSET_FPR : RSET_GPR);
+    asm_fusexref(as, asm_fxstoreins(as, ir), src, ir->op1,
+		 rset_exclude(RSET_GPR, src), ofs);
+  }
+}
+
+#define asm_xstore(as, ir)	asm_xstore_(as, ir, 0)
+
+static void asm_ahuvload(ASMState *as, IRIns *ir)
+{
+  Reg dest = RID_NONE, type = RID_TMP, idx;
+  RegSet allow = RSET_GPR;
+  int32_t ofs = 0;
+  IRType1 t = ir->t;
+
+  if (ra_used(ir)) {
+    lua_assert((irt_isnum(ir->t)) ||
+	       irt_isint(ir->t) || irt_isaddr(ir->t));
+    dest = ra_dest(as, ir, (!LJ_SOFTFP && irt_isnum(t)) ? RSET_FPR : allow);
+    rset_clear(allow, dest);
+    if (irt_isaddr(t))
+      emit_djml(as, LAI_BSTRPICK_D, dest, dest, 46, 0);		//TODO 14+1+32?
+    else if (irt_isint(t))
+      emit_dju(as, LAI_SLLI_W, dest, dest, 0);
+  }
+  idx = asm_fuseahuref(as, ir->op1, &ofs, allow);
+  rset_clear(allow, idx);
+  if (irt_isnum(t)) {
+    asm_guard(as, LAI_BEQ, RID_TMP, RID_ZERO);
+    //emit_dji(as, LAI_SLTUI, RID_TMP, type, ((int32_t)LJ_TISNUM)&0xfff);	//TODO
+    emit_djk(as, LAI_SLTU, RID_TMP, type, RID_R19);
+    emit_d16i(as, RID_R19, (int32_t)LJ_TISNUM);
+  } else {
+    asm_guard(as, LAI_BNE, type,
+	      ra_allock(as, (int32_t)irt_toitype(t), allow));
+  }
+  if (ra_hasreg(dest)) {
+    if (!LJ_SOFTFP && irt_isnum(t)) {
+      //emit_dji(as, LAI_FLD_D, dest, idx, ofs&0xfff);
+      emit_djk(as, LAI_FLDX_D, dest, idx, RID_R19);
+      emit_d16i(as, RID_R19, ofs);
+      dest = type;
+    }
+  } else {
+    dest = type;
+  }
+  emit_dju(as, LAI_SRAI_D, type, dest, (47 & 0x3f));
+  //emit_dji(as, LAI_LD_D, dest, idx, ofs&0xfff);
+  emit_djk(as, LAI_LDX_D, dest, idx, RID_R19);
+  emit_d16i(as, RID_R19, ofs);
+}
+
+static void asm_ahustore(ASMState *as, IRIns *ir)
+{
+  RegSet allow = RSET_GPR;
+  Reg idx, src = RID_NONE, type = RID_NONE;
+  int32_t ofs = 0;
+  if (ir->r == RID_SINK)
+    return;
+  if (irt_isnum(ir->t)) {
+    src = ra_alloc1(as, ir->op2, LJ_SOFTFP ? RSET_GPR : RSET_FPR);
+    idx = asm_fuseahuref(as, ir->op1, &ofs, allow);
+    //emit_dji(as, LJ_SOFTFP ? LAI_ST_D : LAI_FST_D, src, idx, ofs&0xfff);
+    emit_djk(as, LJ_SOFTFP ? LAI_STX_D : LAI_FSTX_D, src, idx, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+  } else {
+    Reg tmp = RID_TMP;
+    if (irt_ispri(ir->t)) {
+      tmp = ra_allock(as, ~((int64_t)~irt_toitype(ir->t) << 47), allow);
+      rset_clear(allow, tmp);
+    } else {
+      src = ra_alloc1(as, ir->op2, allow);
+      rset_clear(allow, src);
+      type = ra_allock(as, (int64_t)irt_toitype(ir->t) << 47, allow);
+      rset_clear(allow, type);
+    }
+    idx = asm_fuseahuref(as, ir->op1, &ofs, allow);
+    //emit_dji(as, LAI_ST_D, tmp, idx, ofs&0xfff);
+    emit_djk(as, LAI_STX_D, tmp, idx, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+    if (ra_hasreg(src)) {
+      if (irt_isinteger(ir->t)) {
+	emit_djk(as, LAI_ADD_D, tmp, tmp, type);
+	emit_djml(as, LAI_BSTRPICK_D, tmp, src, 31, 0);	//TODO
+      } else {
+	emit_djk(as, LAI_ADD_D, tmp, src, type);
+      }
+    }
+  }
+}
+
+static void asm_sload(ASMState *as, IRIns *ir)
+{
+  Reg dest = RID_NONE, type = RID_NONE, base;
+  RegSet allow = RSET_GPR;
+  IRType1 t = ir->t;
+  int32_t ofs = 8*((int32_t)ir->op1-2);
+  lua_assert(!(ir->op2 & IRSLOAD_PARENT));
+  lua_assert(irt_isguard(ir->t) || !(ir->op2 & IRSLOAD_TYPECHECK));
+  if ((ir->op2 & IRSLOAD_CONVERT) && irt_isguard(t) && irt_isint(t)) {
+    dest = ra_scratch(as, LJ_SOFTFP ? allow : RSET_FPR);
+    asm_tointg(as, ir, dest);
+    t.irt = IRT_NUM;  /* Continue with a regular number type check. */
+  } else
+  if (ra_used(ir)) {
+    lua_assert((irt_isnum(ir->t)) ||
+	       irt_isint(ir->t) || irt_isaddr(ir->t));
+    dest = ra_dest(as, ir, (!LJ_SOFTFP && irt_isnum(t)) ? RSET_FPR : allow);
+    rset_clear(allow, dest);
+    base = ra_alloc1(as, REF_BASE, allow);
+    rset_clear(allow, base);
+    if (ir->op2 & IRSLOAD_CONVERT) {
+      if (irt_isint(t)) {
+	Reg tmp = ra_scratch(as, LJ_SOFTFP ? RSET_GPR : RSET_FPR);
+#if LJ_SOFTFP
+	ra_evictset(as, rset_exclude(RSET_SCRATCH, dest));
+	ra_destreg(as, ir, RID_RET);
+	emit_call(as, (void *)lj_ir_callinfo[IRCALL_softfp_d2i].func);	//TODO
+	if (tmp != REGARG_FIRSTGPR)
+	  emit_move(as, REGARG_FIRSTGPR, tmp);
+#else
+	emit_dj(as, LAI_MOVFR2GR_S, dest, tmp);
+	emit_dj(as, LAI_FTINTRZ_W_D, tmp, tmp);
+#endif
+	dest = tmp;
+	t.irt = IRT_NUM;  /* Check for original type. */
+      } else {
+	Reg tmp = ra_scratch(as, RSET_GPR);
+#if LJ_SOFTFP
+	ra_evictset(as, rset_exclude(RSET_SCRATCH, dest));
+	ra_destreg(as, ir, RID_RET);
+	emit_call(as, (void *)lj_ir_callinfo[IRCALL_softfp_i2d].func);	//TODO
+	emit_dju(as, LAI_SLLI_W, REGARG_FIRSTGPR, tmp, 0);
+#else
+	emit_dj(as, LAI_FFINT_D_W, dest, dest);
+	emit_dj(as, LAI_MOVGR2FR_W, tmp, dest);
+#endif
+	dest = tmp;
+	t.irt = IRT_INT;  /* Check for original type. */
+      }
+    }
+    else if (irt_isaddr(t)) {
+      /* Clear type from pointers. */
+      emit_djml(as, LAI_BSTRPICK_D, dest, dest, 46, 0);
+    } else if (irt_isint(t) && (ir->op2 & IRSLOAD_TYPECHECK)) {
+      /* Sign-extend integers. */
+      emit_dju(as, LAI_SLLI_W, dest, dest, 0);
+    }
+    goto dotypecheck;
+  }
+  base = ra_alloc1(as, REF_BASE, allow);
+  rset_clear(allow, base);
+dotypecheck:
+  if ((ir->op2 & IRSLOAD_TYPECHECK)) {
+    type = dest < RID_MAX_GPR ? dest : RID_TMP;
+    if (irt_ispri(t)) {
+      asm_guard(as, LAI_BNE, type,
+		ra_allock(as, ~((int64_t)~irt_toitype(t) << 47) , allow));
+    } else {
+      if (irt_isnum(t)) {
+	asm_guard(as, LAI_BEQ, RID_TMP, RID_ZERO);
+	//emit_dji(as, LAI_SLTUI, RID_TMP, RID_TMP, ((int32_t)LJ_TISNUM)&0xfff);
+	emit_djk(as, LAI_SLTU, RID_TMP, RID_TMP, RID_R19);
+	emit_d16i(as, RID_R19, (int32_t)LJ_TISNUM);
+	if (!LJ_SOFTFP && ra_hasreg(dest)) {
+	  //emit_dji(as, LAI_FLD_D, dest, base, ofs&0xfff);
+	  emit_djk(as, LAI_FLDX_D, dest, base, RID_R19);
+	  emit_d16i(as, RID_R19, ofs);
+	}
+      } else {
+	asm_guard(as, LAI_BNE, RID_TMP,
+		  ra_allock(as, (int32_t)irt_toitype(t), allow));
+      }
+      emit_dju(as, LAI_SRAI_D, RID_TMP, type, 47);
+    }
+    //emit_dji(as, LAI_LD_D, type, base, ofs&0xfff);
+    emit_djk(as, LAI_LDX_D, type, base, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+  } else if (ra_hasreg(dest)) {
+    if (!LJ_SOFTFP && irt_isnum(t)) {
+      emit_djk(as, LAI_FLDX_D, dest, base, RID_R19);
+    } else {
+      emit_djk(as, irt_isint(t) ? LAI_LDX_W : LAI_LDX_D, dest, base, RID_R19);
+    }
+    emit_d16i(as, RID_R19, ofs);
+  }
+}
+
+/* -- Allocations --------------------------------------------------------- */
+
+#if LJ_HASFFI
+static void asm_cnew(ASMState *as, IRIns *ir)
+{
+  CTState *cts = ctype_ctsG(J2G(as->J));
+  CTypeID id = (CTypeID)IR(ir->op1)->i;
+  CTSize sz;
+  CTInfo info = lj_ctype_info(cts, id, &sz);
+  const CCallInfo *ci = &lj_ir_callinfo[IRCALL_lj_mem_newgco];
+  IRRef args[4];
+  RegSet drop = RSET_SCRATCH;
+  lua_assert(sz != CTSIZE_INVALID || (ir->o == IR_CNEW && ir->op2 != REF_NIL));
+
+  as->gcsteps++;
+  if (ra_hasreg(ir->r))
+    rset_clear(drop, ir->r);  /* Dest reg handled below. */
+  ra_evictset(as, drop);
+  if (ra_used(ir))
+    ra_destreg(as, ir, RID_RET);  /* GCcdata * */
+
+  /* Initialize immutable cdata object. */
+  if (ir->o == IR_CNEWI) {
+    RegSet allow = (RSET_GPR & ~RSET_SCRATCH);
+    emit_dji(as, sz == 8 ? LAI_ST_D : LAI_ST_W, ra_alloc1(as, ir->op2, allow),
+	     RID_RET, (sizeof(GCcdata))&0xfff);
+    lua_assert(sz == 4 || sz == 8);
+  } else if (ir->op2 != REF_NIL) {  /* Create VLA/VLS/aligned cdata. */
+    ci = &lj_ir_callinfo[IRCALL_lj_cdata_newv];
+    args[0] = ASMREF_L;     /* lua_State *L */
+    args[1] = ir->op1;      /* CTypeID id   */
+    args[2] = ir->op2;      /* CTSize sz    */
+    args[3] = ASMREF_TMP1;  /* CTSize align */
+    asm_gencall(as, ci, args);
+    emit_loadi(as, ra_releasetmp(as, ASMREF_TMP1), (int32_t)ctype_align(info));
+    return;
+  }
+
+  /* Initialize gct and ctypeid. lj_mem_newgco() already sets marked. */
+  emit_dji(as, LAI_ST_B, RID_RET+1, RID_RET, (offsetof(GCcdata, gct))&0xfff);
+  emit_dji(as, LAI_ST_H, RID_TMP, RID_RET, (offsetof(GCcdata, ctypeid))&0xfff);
+  //emit_dj32i(as, RID_RET+1, 0, ~LJ_TCDATA);
+  emit_djk(as, LAI_ADD_D, RID_RET+1, 0, RID_R19);
+  emit_d16i(as, RID_R19, ~LJ_TCDATA);
+  //emit_dj32i(as, RID_TMP, 0, id); /* Lower 16 bit used. Sign-ext ok. */
+  emit_djk(as, LAI_ADD_D, RID_TMP, 0, RID_R19);
+  emit_d16i(as, RID_R19, id);
+  args[0] = ASMREF_L;     /* lua_State *L */
+  args[1] = ASMREF_TMP1;  /* MSize size   */
+  asm_gencall(as, ci, args);
+  ra_allockreg(as, (int32_t)(sz+sizeof(GCcdata)),
+	       ra_releasetmp(as, ASMREF_TMP1));
+}
+#endif
+
+/* -- Write barriers ------------------------------------------------------ */
+
+static void asm_tbar(ASMState *as, IRIns *ir)
+{
+  Reg tab = ra_alloc1(as, ir->op1, RSET_GPR);
+  Reg mark = ra_scratch(as, rset_exclude(RSET_GPR, tab));
+  Reg link = RID_TMP;
+  MCLabel l_end = emit_label(as);
+  emit_dji(as, LAI_ST_D, link, tab, ((int32_t)offsetof(GCtab, gclist))&0xfff);
+  emit_dji(as, LAI_ST_B, mark, tab, ((int32_t)offsetof(GCtab, marked))&0xfff);
+  emit_setgl(as, tab, gc.grayagain);	//TODO
+  emit_getgl(as, link, gc.grayagain);	//TODO
+  //emit_djk(as, LAI_XOR, mark, mark, RID_TMP);  /* Clear black bit. */
+  emit_branch(as, LAI_BEQ, RID_TMP, RID_ZERO, l_end);
+  emit_djk(as, LAI_XOR, mark, mark, RID_TMP);
+  emit_dju(as, LAI_ANDI, RID_TMP, mark, LJ_GC_BLACK);
+  emit_dji(as, LAI_LD_BU, mark, tab, ((int32_t)offsetof(GCtab, marked))&0xfff);
+}
+
+static void asm_obar(ASMState *as, IRIns *ir)
+{
+  const CCallInfo *ci = &lj_ir_callinfo[IRCALL_lj_gc_barrieruv];
+  IRRef args[2];
+  MCLabel l_end;
+  Reg obj, val, tmp;
+  /* No need for other object barriers (yet). */
+  lua_assert(IR(ir->op1)->o == IR_UREFC);
+  ra_evictset(as, RSET_SCRATCH);
+  l_end = emit_label(as);
+  args[0] = ASMREF_TMP1;  /* global_State *g */
+  args[1] = ir->op1;      /* TValue *tv      */
+  asm_gencall(as, ci, args);
+  //emit_dji(as, LAI_ADDI_D, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, -32768);
+  //emit_dj32i(as, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, -32768);    //TODO daddiu
+  emit_djk(as, LAI_ADDI_D, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, RID_R19);
+  emit_d16i(as, RID_R19, -32768);
+  obj = IR(ir->op1)->r;
+  tmp = ra_scratch(as, rset_exclude(RSET_GPR, obj));
+  emit_branch(as, LAI_BEQ, RID_TMP, RID_ZERO, l_end);
+  emit_dju(as, LAI_ANDI, tmp, tmp, LJ_GC_BLACK);
+  emit_branch(as, LAI_BEQ, RID_TMP, RID_ZERO, l_end);
+  emit_dju(as, LAI_ANDI, RID_TMP, RID_TMP, LJ_GC_WHITES);
+  val = ra_alloc1(as, ir->op2, rset_exclude(RSET_GPR, obj));
+  emit_dji(as, LAI_LD_BU, tmp, obj,
+	   ((int32_t)offsetof(GCupval, marked)-(int32_t)offsetof(GCupval, tv))&0xfff);
+  emit_dji(as, LAI_LD_BU, RID_TMP, val, ((int32_t)offsetof(GChead, marked))&0xfff);
+}
+
+/* -- Arithmetic and logic operations ------------------------------------- */
+
+#if !LJ_SOFTFP
+static void asm_fparith(ASMState *as, IRIns *ir, LAIns lai)
+{
+  Reg dest = ra_dest(as, ir, RSET_FPR);
+  Reg right, left = ra_alloc2(as, ir, RSET_FPR);
+  right = (left >> 8); left &= 255;
+  emit_djk(as, lai, dest, left, right);
+}
+
+static void asm_fpunary(ASMState *as, IRIns *ir, LAIns lai)
+{
+  Reg dest = ra_dest(as, ir, RSET_FPR);
+  Reg left = ra_hintalloc(as, ir->op1, dest, RSET_FPR);
+  emit_dj(as, lai, dest, left);
+}
+#endif
+
+static void asm_fpmath(ASMState *as, IRIns *ir)
+{
+#if !LJ_SOFTFP
+  if (ir->op2 <= IRFPM_TRUNC)
+    asm_callround(as, ir, IRCALL_lj_vm_floor + ir->op2);
+  else if (ir->op2 == IRFPM_SQRT)
+    asm_fpunary(as, ir, LAI_FSQRT_D);
+  else
+#endif
+    asm_callid(as, ir, IRCALL_lj_vm_floor + ir->op2);
+}
+
+#if !LJ_SOFTFP
+#define asm_fpadd(as, ir)	asm_fparith(as, ir, LAI_FADD_D)
+#define asm_fpsub(as, ir)	asm_fparith(as, ir, LAI_FSUB_D)
+#define asm_fpmul(as, ir)	asm_fparith(as, ir, LAI_FMUL_D)
+#elif LJ_64  /* && LJ_SOFTFP */
+#define asm_fpadd(as, ir)	asm_callid(as, ir, IRCALL_softfp_add)
+#define asm_fpsub(as, ir)	asm_callid(as, ir, IRCALL_softfp_sub)
+#define asm_fpmul(as, ir)	asm_callid(as, ir, IRCALL_softfp_mul)
+#endif
+
+static void asm_add(ASMState *as, IRIns *ir)
+{
+  IRType1 t = ir->t;
+  if (irt_isnum(t)) {
+    asm_fpadd(as, ir);
+  } else
+  {
+    /* TODO fmadd.s/d */
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg right, left = ra_hintalloc(as, ir->op1, dest, RSET_GPR);
+    if (irref_isk(ir->op2)) {
+      intptr_t k = get_kval(as, ir->op2);
+      if (checki16(k)) {
+        if (LJ_64 && irt_is64(t)) {
+          emit_add(as, dest, left, k);
+        } else {
+          emit_addw(as, dest, left, k);
+        }
+	return;
+      }
+    }
+    right = ra_alloc1(as, ir->op2, rset_exclude(RSET_GPR, left));
+    emit_djk(as, (LJ_64 && irt_is64(t)) ? LAI_ADD_D : LAI_ADD_W, dest,
+	     left, right);
+  }
+}
+
+static void asm_sub(ASMState *as, IRIns *ir)
+{
+  if (irt_isnum(ir->t)) {
+    asm_fpsub(as, ir);
+  } else
+  {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg right, left = ra_alloc2(as, ir, RSET_GPR);
+    right = (left >> 8); left &= 255;
+    emit_djk(as, (LJ_64 && irt_is64(ir->t)) ? LAI_SUB_D : LAI_SUB_W, dest,
+	     left, right);
+  }
+}
+
+static void asm_mul(ASMState *as, IRIns *ir)
+{
+  if (irt_isnum(ir->t)) {
+    asm_fpmul(as, ir);
+  } else
+  {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg right, left = ra_alloc2(as, ir, RSET_GPR);
+    right = (left >> 8); left &= 255;
+    if (LJ_64 && irt_is64(ir->t)) {
+      emit_djk(as, LAI_MUL_D, dest, left, right);
+    } else {
+      emit_djk(as, LAI_MUL_W, dest, left, right);
+    }
+  }
+}
+
+static void asm_mod(ASMState *as, IRIns *ir)
+{
+#if LJ_64 && LJ_HASFFI
+  if (!irt_isint(ir->t))
+    asm_callid(as, ir, irt_isi64(ir->t) ? IRCALL_lj_carith_modi64 :
+					  IRCALL_lj_carith_modu64);
+  else
+#endif
+    asm_callid(as, ir, IRCALL_lj_vm_modi);
+}
+
+#if !LJ_SOFTFP
+static void asm_pow(ASMState *as, IRIns *ir)
+{
+#if LJ_64 && LJ_HASFFI
+  if (!irt_isnum(ir->t))
+    asm_callid(as, ir, irt_isi64(ir->t) ? IRCALL_lj_carith_powi64 :
+					  IRCALL_lj_carith_powu64);
+  else
+#endif
+    asm_callid(as, ir, IRCALL_lj_vm_powi);
+}
+
+static void asm_div(ASMState *as, IRIns *ir)
+{
+#if LJ_64 && LJ_HASFFI
+  if (!irt_isnum(ir->t))
+    asm_callid(as, ir, irt_isi64(ir->t) ? IRCALL_lj_carith_divi64 :
+					  IRCALL_lj_carith_divu64);
+  else
+#endif
+    asm_fparith(as, ir, LAI_DIV_D);
+}
+#endif
+
+static void asm_fpdiv(ASMState *as, IRIns *ir)
+{
+#if !LJ_SOFTFP
+    asm_fparith(as, ir, LAI_FDIV_D);
+#else
+    asm_callid(as, ir, IRCALL_softfp_div);
+#endif
+}
+
+static void asm_neg(ASMState *as, IRIns *ir)
+{
+#if !LJ_SOFTFP
+  if (irt_isnum(ir->t)) {
+    asm_fpunary(as, ir, LAI_FNEG_D);
+  } else
+#elif LJ_64  /* && LJ_SOFTFP */
+  if (irt_isnum(ir->t)) {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg left = ra_hintalloc(as, ir->op1, dest, RSET_GPR);
+    emit_djk(as, LAI_XOR, dest, left,
+	    ra_allock(as, 0x8000000000000000ll, rset_exclude(RSET_GPR, dest)));
+  } else
+#endif
+  {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg left = ra_hintalloc(as, ir->op1, dest, RSET_GPR);
+    emit_djk(as, (LJ_64 && irt_is64(ir->t)) ? LAI_SUB_D : LAI_SUB_W, dest,
+	     RID_ZERO, left);
+  }
+}
+
+#if !LJ_SOFTFP
+#define asm_abs(as, ir)		asm_fpunary(as, ir, LAI_FABS_D)
+#elif LJ_64   /* && LJ_SOFTFP */
+static void asm_abs(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg left = ra_alloc1(as, ir->op1, RSET_GPR);
+  emit_djml(as, LAI_BSTRPICK_D, dest, left, 62, 0);	//TODO 30+1+32
+}
+#endif
+#define asm_atan2(as, ir)	asm_callid(as, ir, IRCALL_atan2)
+#define asm_ldexp(as, ir)	asm_callid(as, ir, IRCALL_ldexp)
+
+static void asm_arithov(ASMState *as, IRIns *ir)
+{
+  /* TODO */
+  Reg right, left, tmp, dest = ra_dest(as, ir, RSET_GPR);
+  lua_assert(!irt_is64(ir->t));
+  if (irref_isk(ir->op2)) {
+    int k = IR(ir->op2)->i;
+    if (ir->o == IR_SUBOV) k = -k;
+    if (checki16(k)) {  /* (dest < left) == (k >= 0 ? 1 : 0) */
+      left = ra_alloc1(as, ir->op1, RSET_GPR);
+      asm_guard(as, k >= 0 ? LAI_BNE : LAI_BEQ, RID_TMP, RID_ZERO);
+      emit_djk(as, LAI_SLT, RID_TMP, dest, dest == left ? RID_TMP : left);
+      emit_dj32i(as, dest, left, k);	// addiu
+      if (dest == left) emit_move(as, RID_TMP, left);
+      return;
+    }
+  }
+  left = ra_alloc2(as, ir, RSET_GPR);
+  right = (left >> 8); left &= 255;
+  tmp = ra_scratch(as, rset_exclude(rset_exclude(rset_exclude(RSET_GPR, left),
+						 right), dest));
+  asm_guard(as, LAI_BLT, RID_TMP, RID_ZERO);
+  emit_djk(as, LAI_AND, RID_TMP, RID_TMP, tmp);
+  if (ir->o == IR_ADDOV) {  /* ((dest^left) & (dest^right)) < 0 */
+    emit_djk(as, LAI_XOR, RID_TMP, dest, dest == right ? RID_TMP : right);
+  } else {  /* ((dest^left) & (dest^~right)) < 0 */
+    emit_djk(as, LAI_XOR, RID_TMP, RID_TMP, dest);
+    emit_djk(as, LAI_NOR, RID_TMP, dest == right ? RID_TMP : right, RID_ZERO);
+  }
+  emit_djk(as, LAI_XOR, tmp, dest, dest == left ? RID_TMP : left);
+  emit_djk(as, ir->o == IR_ADDOV ? LAI_ADD_W : LAI_SUB_W, dest, left, right);
+  if (dest == left || dest == right)
+    emit_move(as, RID_TMP, dest == left ? left : right);
+}
+
+#define asm_addov(as, ir)	asm_arithov(as, ir)
+#define asm_subov(as, ir)	asm_arithov(as, ir)
+
+static void asm_mulov(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg tmp, right, left = ra_alloc2(as, ir, RSET_GPR);
+  right = (left >> 8); left &= 255;
+  tmp = ra_scratch(as, rset_exclude(rset_exclude(rset_exclude(RSET_GPR, left),
+						 right), dest));
+  asm_guard(as, LAI_BNE, RID_TMP, tmp);
+  emit_dju(as, LAI_SRAI_W, RID_TMP, dest, 31);
+  emit_djk(as, LAI_MUL_W, dest, left, right);
+  emit_djk(as, LAI_MULH_W, tmp, left, right);
+}
+
+static void asm_bnot(ASMState *as, IRIns *ir)
+{
+  Reg left, right, dest = ra_dest(as, ir, RSET_GPR);
+  IRIns *irl = IR(ir->op1);
+  if (mayfuse(as, ir->op1) && irl->o == IR_BOR) {
+    left = ra_alloc2(as, irl, RSET_GPR);
+    right = (left >> 8); left &= 255;
+  } else {
+    left = ra_hintalloc(as, ir->op1, dest, RSET_GPR);
+    right = RID_ZERO;
+  }
+  emit_djk(as, LAI_NOR, dest, left, right);
+}
+
+static void asm_bswap(ASMState *as, IRIns *ir)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg left = ra_alloc1(as, ir->op1, RSET_GPR);
+  if (irt_is64(ir->t)) {
+    emit_dj(as, LAI_REVH_D, dest, RID_TMP);
+    emit_dj(as, LAI_REVB_4H, RID_TMP, left);
+  } else {
+    emit_dju(as, LAI_ROTRI_W, dest, RID_TMP, 16);
+    emit_dj(as, LAI_REVB_2H, RID_TMP, left);
+  }
+}
+
+static void asm_bitop1(ASMState *as, LAIns lai, Reg rd, Reg rj, int32_t i)
+{
+  emit_djk(as, LAI_ADD_W, rd, rd, RID_R20);
+  emit_dju(as, LAI_SLLI_W, RID_R20, RID_R20, 12);
+  emit_dju(as, lai, RID_R20, RID_R20, (i&0xf000)>>12);
+  emit_dju(as, LAI_SRLI_W, RID_R20, RID_R20, 12);
+  emit_dju(as, lai, rd, RID_R20, i&0xfff);
+  emit_djk(as, LAI_OR, RID_R20, RID_R0, rj);
+}
+
+static void asm_bitop(ASMState *as, IRIns *ir, LAIns lai, LAIns laik)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  Reg right, left = ra_hintalloc(as, ir->op1, dest, RSET_GPR);
+  if (irref_isk(ir->op2)) {
+    intptr_t k = get_kval(as, ir->op2);
+    if (checku16(k)) {
+      asm_bitop1(as, laik, dest, left, k);
+      return;
+    }
+  }
+  right = ra_alloc1(as, ir->op2, rset_exclude(RSET_GPR, left));
+  emit_djk(as, lai, dest, left, right);
+}
+
+#define asm_band(as, ir)	asm_bitop(as, ir, LAI_AND, LAI_ANDI)
+#define asm_bor(as, ir)		asm_bitop(as, ir, LAI_OR, LAI_ORI)
+#define asm_bxor(as, ir)	asm_bitop(as, ir, LAI_XOR, LAI_XORI)
+
+static void asm_bitshift(ASMState *as, IRIns *ir, LAIns lai, LAIns laik)
+{
+  Reg dest = ra_dest(as, ir, RSET_GPR);
+  if (irref_isk(ir->op2)) {  /* Constant shifts. */
+    uint32_t shift = (uint32_t)IR(ir->op2)->i;
+    if (LJ_64 && irt_is64(ir->t)) laik = laik + 0x8000; 
+    emit_dju(as, laik, dest, ra_hintalloc(as, ir->op1, dest, RSET_GPR),
+	     shift);
+  } else {
+    Reg right, left = ra_alloc2(as, ir, RSET_GPR);
+    right = (left >> 8); left &= 255;
+    if (LJ_64 && irt_is64(ir->t)) {
+      if (lai == LAI_ROTR_W) {
+        lai = lai + 0x8000;
+      } else {
+        lai = lai + 0x18000;
+      }
+    }
+    emit_djk(as, lai, dest, left, right);  /* Shift amount is in rs. */
+  }
+}
+
+#define asm_bshl(as, ir)	asm_bitshift(as, ir, LAI_SLL_W, LAI_SLLI_W)
+#define asm_bshr(as, ir)	asm_bitshift(as, ir, LAI_SRL_W, LAI_SRLI_W)
+#define asm_bsar(as, ir)	asm_bitshift(as, ir, LAI_SRA_W, LAI_SRAI_W)
+#define asm_brol(as, ir)	lua_assert(0)
+#define asm_bror(as, ir)	asm_bitshift(as, ir, LAI_ROTR_W, LAI_ROTRI_W)
+
+
+#if LJ_SOFTFP
+static void asm_sfpmin_max(ASMState *as, IRIns *ir)
+{
+  CCallInfo ci = lj_ir_callinfo[(IROp)ir->o == IR_MIN ? IRCALL_lj_vm_sfmin : IRCALL_lj_vm_sfmax];
+  IRRef args[2];
+  args[0] = ir->op1;
+  args[1] = ir->op2;
+  asm_setupresult(as, ir, &ci);
+  emit_call(as, (void *)ci.func);	//TODO
+  ci.func = NULL;
+  asm_gencall(as, &ci, args);
+}
+#endif
+
+static void asm_min_max(ASMState *as, IRIns *ir, int ismax)
+{
+  if (irt_isnum(ir->t)) {
+#if LJ_SOFTFP
+    asm_sfpmin_max(as, ir);
+#else
+    Reg dest = ra_dest(as, ir, RSET_FPR);
+    Reg right, left = ra_alloc2(as, ir, RSET_FPR);
+    right = (left >> 8); left &= 255;
+    emit_djk(as, ismax ? LAI_FMAX_D : LAI_FMIN_D, dest, left, right);
+#endif
+  } else {
+    Reg dest = ra_dest(as, ir, RSET_GPR);
+    Reg right, left = ra_alloc2(as, ir, RSET_GPR);
+    right = (left >> 8); left &= 255;
+    if (left == right) {
+      if (dest != left) emit_move(as, dest, left);
+    } else {
+      emit_djk(as, LAI_OR, dest, dest, RID_TMP);
+      if (dest != right) {
+	emit_djk(as, LAI_MASKEQZ, RID_TMP, right, RID_TMP);
+	emit_djk(as, LAI_MASKNEZ, dest, left, RID_TMP);
+      } else {
+	emit_djk(as, LAI_MASKNEZ, RID_TMP, left, RID_TMP);
+	emit_djk(as, LAI_MASKEQZ, dest, right, RID_TMP);
+      }
+      emit_djk(as, LAI_SLT, RID_TMP,
+	       ismax ? left : right, ismax ? right : left);
+    }
+  }
+}
+
+#define asm_min(as, ir)		asm_min_max(as, ir, 0)
+#define asm_max(as, ir)		asm_min_max(as, ir, 1)
+
+/* -- Comparisons --------------------------------------------------------- */
+
+#if LJ_SOFTFP
+/* SFP comparisons. */
+static void asm_sfpcomp(ASMState *as, IRIns *ir)
+{
+  const CCallInfo *ci = &lj_ir_callinfo[IRCALL_softfp_cmp];
+  RegSet drop = RSET_SCRATCH;
+  Reg r;
+  IRRef args[2];
+  args[0] = ir->op1;
+  args[1] = ir->op2;
+
+  for (r = REGARG_FIRSTGPR; r <= REGARG_FIRSTGPR+1; r++) {
+    if (!rset_test(as->freeset, r) &&
+	regcost_ref(as->cost[r]) == args[r-REGARG_FIRSTGPR])
+      rset_clear(drop, r);
+  }
+  ra_evictset(as, drop);
+
+  asm_setupresult(as, ir, ci);
+
+  switch ((IROp)ir->o) {
+  case IR_LT:
+    asm_guard(as, LAI_BGE, RID_RET, RID_ZERO);
+    break;
+  case IR_ULT:
+    asm_guard(as, LAI_BEQ, RID_RET, RID_TMP);
+    emit_loadi(as, RID_TMP, 1);
+    asm_guard(as, LAI_BEQ, RID_RET, RID_ZERO);
+    break;
+  case IR_GE:
+    asm_guard(as, LAI_BEQ, RID_RET, RID_TMP);
+    emit_loadi(as, RID_TMP, 2);
+    asm_guard(as, LAI_BLT, RID_RET, RID_ZERO);
+    break;
+  case IR_LE:
+    asm_guard(as, LAI_BLT, RID_ZERO, RID_RET);
+    break;
+  case IR_GT:
+    asm_guard(as, LAI_BEQ, RID_RET, RID_TMP);
+    emit_loadi(as, RID_TMP, 2);
+    asm_guard(as, LAI_BGE, RID_ZERO, RID_RET);
+    break;
+  case IR_UGE:
+    asm_guard(as, LAI_BLT, RID_RET, RID_ZERO);
+    break;
+  case IR_ULE:
+    asm_guard(as, LAI_BEQ, RID_RET, RID_TMP);
+    emit_loadi(as, RID_TMP, 1);
+    break;
+  case IR_UGT: case IR_ABC:
+    asm_guard(as, LAI_BGE, RID_ZERO, RID_RET);
+    break;
+  case IR_EQ: case IR_NE:
+    asm_guard(as, (ir->o & 1) ? LAI_BEQ : LAI_BNE, RID_RET, RID_ZERO);
+  default:
+    break;
+  }
+  asm_gencall(as, ci, args);
+}
+#endif
+
+static void asm_comp(ASMState *as, IRIns *ir)
+{
+  /* ORDER IR: LT GE LE GT  ULT UGE ULE UGT. */
+  /*           00 01 10 11  100 101 110 111  */
+  IROp op = ir->o;
+  if (irt_isnum(ir->t)) {
+#if LJ_SOFTFP
+    asm_sfpcomp(as, ir);
+#else
+    Reg tmp, right, left = ra_alloc2(as, ir, RSET_FPR);
+    right = (left >> 8); left &= 255;
+    tmp = ra_scratch(as, rset_exclude(rset_exclude(RSET_FPR, left), right));
+    asm_guard21(as, (op&1) ? LAI_BCNEZ : LAI_BCEQZ, 0, (tmp&7));
+    // emit_dst(as, MIPSI_CMP_LT_D + ((op&3) ^ ((op>>2)&1)), tmp, left, right);	//TODO
+    // use case
+    switch (op) {
+      case IR_LT: case IR_UGE:
+        emit_djk(as, LAI_FCMP_CLT_D, 0, left, right);
+        break;
+      case IR_GE: case IR_ULT:
+        emit_djk(as, LAI_FCMP_CULT_D, 0, left, right);
+        break;
+      case IR_LE: case IR_UGT: case IR_ABC:
+        emit_djk(as, LAI_FCMP_CLE_D, 0, left, right);
+        break;
+      case IR_GT: case IR_ULE:
+        emit_djk(as, LAI_FCMP_CULE_D, 0, left, right);
+        break;
+      case IR_EQ:
+        emit_djk(as, LAI_FCMP_CEQ_D, 0, left, right);
+        break;
+      case IR_NE:
+        emit_djk(as, LAI_FCMP_CNE_D, 0, left, right);
+        break;
+      default:
+        break;
+    }
+#endif
+  } else {
+    Reg right, left = ra_alloc1(as, ir->op1, RSET_GPR);
+    if (op == IR_ABC) op = IR_UGT;
+    if ((op&4) == 0 && irref_isk(ir->op2) && get_kval(as, ir->op2) == 0) {
+      /* MIPSIns mi = (op&2) ? ((op&1) ? MIPSI_BLEZ : MIPSI_BGTZ) :
+			    ((op&1) ? MIPSI_BLTZ : MIPSI_BGEZ);
+      asm_guard(as, mi, left, 0);
+      */
+      if (op&2) {
+        if (op&1) {
+          asm_guard(as, LAI_BGE, RID_ZERO, left);
+        } else {
+          asm_guard(as, LAI_BLT, RID_ZERO, left);
+        }
+      } else {
+        if (op&1) {
+          asm_guard(as, LAI_BLT, left, RID_ZERO);
+        } else {
+          asm_guard(as, LAI_BGE, left, RID_ZERO);
+        }
+      }
+    } else {
+      if (irref_isk(ir->op2)) {
+	intptr_t k = get_kval(as, ir->op2);
+	if ((op&2)) k++;
+	if (checki16(k)) {
+	  asm_guard(as, (op&1) ? LAI_BNE : LAI_BEQ, RID_TMP, RID_ZERO);
+	  emit_djk(as, (op&4) ? LAI_SLTU : LAI_SLT,			//TODO si12
+		   RID_TMP, left, RID_R20);
+          //emit_djk(as, LAI_ADD_D, RID_R20, RID_R19, RID_ZERO);
+          //emit_dju(as, LAI_ORI, RID_R19, RID_R19, k&0xfff);
+          //emit_di(as, LAI_LU12I_W, RID_R19, (k>>12)&0xfffff);
+          //emit_dj32i(as, RID_R20, RID_ZERO, k);
+          emit_d16i(as, RID_R20, k);
+	  return;
+	}
+      }
+      right = ra_alloc1(as, ir->op2, rset_exclude(RSET_GPR, left));
+      asm_guard(as, ((op^(op>>1))&1) ? LAI_BNE : LAI_BEQ, RID_TMP, RID_ZERO);
+      emit_djk(as, (op&4) ? LAI_SLTU : LAI_SLT,
+	       RID_TMP, (op&2) ? right : left, (op&2) ? left : right);
+    }
+  }
+}
+
+static void asm_equal(ASMState *as, IRIns *ir)
+{
+  Reg right, left = ra_alloc2(as, ir, (!LJ_SOFTFP && irt_isnum(ir->t)) ?
+				       RSET_FPR : RSET_GPR);
+  right = (left >> 8); left &= 255;
+  if (irt_isnum(ir->t)) {
+#if LJ_SOFTFP
+    asm_sfpcomp(as, ir);
+#else
+    Reg tmp = ra_scratch(as, rset_exclude(rset_exclude(RSET_FPR, left), right));
+    asm_guard21(as, (ir->o & 1) ? LAI_BCNEZ : LAI_BCEQZ, 0, (tmp&7));
+    //emit_djk(as, LAI_FCMP_CEQ_D, tmp&7, left, right);
+    emit_djk(as, LAI_FCMP_CEQ_D, 0, left, right);
+#endif
+  } else {
+    asm_guard(as, (ir->o & 1) ? LAI_BEQ : LAI_BNE, left, right);
+  }
+}
+
+/* -- Support for 64 bit ops in 32 bit mode ------------------------------- */
+
+/* Hiword op of a split 64 bit op. Previous op must be the loword op. */
+static void asm_hiop(ASMState *as, IRIns *ir)
+{
+  UNUSED(as); UNUSED(ir);
+  lua_assert(0);  /* Unused on 64 bit. */
+}
+
+/* -- Profiling ----------------------------------------------------------- */
+
+static void asm_prof(ASMState *as, IRIns *ir)
+{
+  UNUSED(ir);
+  asm_guard(as, LAI_BNE, RID_TMP, RID_ZERO);
+  emit_dju(as, LAI_ANDI, RID_TMP, RID_TMP, HOOK_PROFILE);	//HOOK_PROFILE=0x80
+  emit_lsglptr2(as, LAI_LD_BU, RID_TMP,				//TODO
+	       (int32_t)offsetof(global_State, hookmask));
+}
+
+/* -- Stack handling ------------------------------------------------------ */
+
+/* Check Lua stack size for overflow. Use exit handler as fallback. */
+static void asm_stack_check(ASMState *as, BCReg topslot,
+			    IRIns *irp, RegSet allow, ExitNo exitno)
+{
+  /* Try to get an unused temp. register, otherwise spill/restore RID_RET*. */
+  Reg tmp, pbase = irp ? (ra_hasreg(irp->r) ? irp->r : RID_TMP) : RID_BASE;
+  ExitNo oldsnap = as->snapno;
+  rset_clear(allow, pbase);
+  tmp = allow ? rset_pickbot(allow) : RID_RET;
+  as->snapno = exitno;
+  asm_guard(as, LAI_BNE, RID_TMP, RID_ZERO);
+  as->snapno = oldsnap;
+  if (allow == RSET_EMPTY)  /* Restore temp. register. */
+    emit_dji(as, LAI_LD_D, tmp, RID_SP, 0);
+  else
+    ra_modified(as, tmp);
+  //emit_dji(as, LAI_SLTUI, RID_TMP, RID_TMP, ((int32_t)(8*topslot))&0xfff);	//TODO si12
+  emit_djk(as, LAI_SLTU, RID_TMP, RID_TMP, RID_R19);
+  emit_d16i(as, RID_R19, (int32_t)(8*topslot));
+  emit_djk(as, LAI_SUB_D, RID_TMP, tmp, pbase);
+  emit_djk(as, LAI_LDX_D, tmp, tmp, RID_R19);
+  emit_loadi(as, RID_R19, offsetof(lua_State, maxstack));
+  if (pbase == RID_TMP)
+    emit_getgl(as, RID_TMP, jit_base);
+  emit_getgl(as, tmp, cur_L);
+  if (allow == RSET_EMPTY)  /* Spill temp. register. */
+    emit_dji(as, LAI_ST_D, tmp, RID_SP, 0);
+}
+
+/* Restore Lua stack from on-trace state. */
+static void asm_stack_restore(ASMState *as, SnapShot *snap)
+{
+  SnapEntry *map = &as->T->snapmap[snap->mapofs];
+#if defined(LUA_USE_ASSERT)
+  SnapEntry *flinks = &as->T->snapmap[snap_nextofs(as->T, snap)-1-LJ_FR2];
+#endif
+  MSize n, nent = snap->nent;
+  /* Store the value of all modified slots to the Lua stack. */
+  for (n = 0; n < nent; n++) {
+    SnapEntry sn = map[n];
+    BCReg s = snap_slot(sn);
+    int32_t ofs = 8*((int32_t)s-1-LJ_FR2);
+    IRRef ref = snap_ref(sn);
+    IRIns *ir = IR(ref);
+    if ((sn & SNAP_NORESTORE))
+      continue;
+    if (irt_isnum(ir->t)) {
+#if LJ_SOFTFP  /* && LJ_64 */
+      Reg src = ra_alloc1(as, ref, rset_exclude(RSET_GPR, RID_BASE));
+      //emit_dji(as, LAI_ST_D, src, RID_BASE, ofs&0xfff);	//TODO si12
+      emit_djk(as, LAI_STX_D, src, RID_BASE, RID_R19);
+#else
+      Reg src = ra_alloc1(as, ref, RSET_FPR);
+      //emit_dji(as, LAI_FST_D, src, RID_BASE, ofs&0xfff);	//TODO si12
+      emit_djk(as, LAI_FSTX_D, src, RID_BASE, RID_R19);
+#endif
+      emit_d16i(as, RID_R19, ofs);
+    } else {
+      asm_tvstore64(as, RID_BASE, ofs, ref);
+    }
+    checkmclim(as);
+  }
+  lua_assert(map + nent == flinks);
+}
+
+/* -- GC handling --------------------------------------------------------- */
+
+/* Marker to prevent patching the GC check exit. */
+#define LA_NOPATCH_GC_CHECK	LAI_OR
+
+/* Check GC threshold and do one or more GC steps. */
+static void asm_gc_check(ASMState *as)
+{
+  const CCallInfo *ci = &lj_ir_callinfo[IRCALL_lj_gc_step_jit];
+  IRRef args[2];
+  MCLabel l_end;
+  Reg tmp;
+  ra_evictset(as, RSET_SCRATCH);
+  l_end = emit_label(as);
+  /* Exit trace if in GCSatomic or GCSfinalize. Avoids syncing GC objects. */
+  /* Assumes asm_snap_prep() already done. */
+  asm_guard(as, LAI_BNE, RID_RET, RID_ZERO);
+  args[0] = ASMREF_TMP1;  /* global_State *g */
+  args[1] = ASMREF_TMP2;  /* MSize steps     */
+  asm_gencall(as, ci, args);
+  l_end[-3] = LA_NOPATCH_GC_CHECK;  /* Replace the nop after the call. */	//TODO
+  //emit_dji(as, LAI_ADDI_D, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, -32768);	//TODO
+  //emit_dj32i(as, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, -32768);
+  emit_add(as, ra_releasetmp(as, ASMREF_TMP1), RID_JGL, -32768);
+  tmp = ra_releasetmp(as, ASMREF_TMP2);
+  /* Jump around GC step if GC total < GC threshold. */
+  emit_branch(as, LAI_BNE, RID_TMP, RID_ZERO, l_end);
+  emit_loadi(as, tmp, as->gcsteps);
+  emit_djk(as, LAI_SLTU, RID_TMP, RID_TMP, tmp);
+  emit_getgl(as, tmp, gc.threshold);
+  emit_getgl(as, RID_TMP, gc.total);
+  as->gcsteps = 0;
+  checkmclim(as);
+}
+
+/* -- Loop handling ------------------------------------------------------- */
+
+/* Fixup the loop branch. */
+static void asm_loop_fixup(ASMState *as)
+{
+  MCode *p = as->mctop;
+  MCode *target = as->mcp;
+  if (as->loopinv) {  /* Inverted loop branch? */
+    /* asm_guard already inverted the bceqz/bcnez/beq/bne/blt/bge, and patched the final b. */
+    uint32_t mask = (p[-2] & 0xfc000000) == 0x48000000 ? 0x1fffffu : 0xffffu;
+    ptrdiff_t delta = target - p ;
+    if (mask == 0x1fffffu) {
+      p[-2] = p[-2] | LAF_I((uint32_t)delta & 0xffffu) | (((uint32_t)delta & 0x1f0000u) >> 16);
+    } else {
+      p[-2] |= LAF_I(delta & 0xffffu);			//TODO
+    }
+    if (p[-1] == 0 || p[-1] == 0x109c21)		//TODO
+      p[-1] = LAI_NOP;
+  } else {
+    /* b */
+    ptrdiff_t delta = target - (p - 1);
+    p[-1] = LAI_B | LAF_I(delta & 0xffffu) | ((delta & 0x3ff0000) >> 16);	//TODO
+    if ( (p[-2] & LAI_B) == LAI_B || (p[-2] & LAI_BL) == LAI_BL || (p[-2] & LAI_BEQ) == LAI_BEQ || (p[-2] & LAI_BNE) == LAI_BNE ||(p[-2] & LAI_BLT) == LAI_BLT || (p[-2] & LAI_BGE) == LAI_BGE)
+      p[-3] = LAI_NOP;
+  }
+}
+
+/* Fixup the tail of the loop. */
+static void asm_loop_tail_fixup(ASMState *as)
+{
+  if (as->loopinv) as->mctop--;
+}
+
+/* -- Head of trace ------------------------------------------------------- */
+
+/* Coalesce BASE register for a root trace. */
+static void asm_head_root_base(ASMState *as)
+{
+  IRIns *ir = IR(REF_BASE);
+  Reg r = ir->r;
+  if (as->loopinv) as->mctop--;
+  if (ra_hasreg(r)) {
+    ra_free(as, r);
+    if (rset_test(as->modset, r) || irt_ismarked(ir->t))
+      ir->r = RID_INIT;  /* No inheritance for modified BASE register. */
+    if (r != RID_BASE)
+      emit_move(as, r, RID_BASE);
+  }
+}
+
+/* Coalesce BASE register for a side trace. */
+static RegSet asm_head_side_base(ASMState *as, IRIns *irp, RegSet allow)
+{
+  IRIns *ir = IR(REF_BASE);
+  Reg r = ir->r;
+  if (as->loopinv) as->mctop--;
+  if (ra_hasreg(r)) {
+    ra_free(as, r);
+    if (rset_test(as->modset, r) || irt_ismarked(ir->t))
+      ir->r = RID_INIT;  /* No inheritance for modified BASE register. */
+    if (irp->r == r) {
+      rset_clear(allow, r);  /* Mark same BASE register as coalesced. */
+    } else if (ra_hasreg(irp->r) && rset_test(as->freeset, irp->r)) {
+      rset_clear(allow, irp->r);
+      emit_move(as, r, irp->r);  /* Move from coalesced parent reg. */
+    } else {
+      emit_getgl(as, r, jit_base);  /* Otherwise reload BASE. */
+    }
+  }
+  return allow;
+}
+
+/* -- Tail of trace ------------------------------------------------------- */
+
+/* Fixup the tail code. */
+static void asm_tail_fixup(ASMState *as, TraceNo lnk)
+{
+  MCode *target = lnk ? traceref(as->J,lnk)->mcode : (MCode *)lj_vm_exit_interp;
+  int32_t spadj = as->T->spadjust;
+  MCode *p = as->mctop - 1;
+  if (spadj == 0) {
+    p[-1] = LAI_NOP;
+  } else {
+    p[-1] = LAI_ADDI_D|LAF_D(RID_SP)|LAF_J(RID_SP)|LAF_I(spadj);
+  }
+
+  MCode *tmp = p;
+  *p = LAI_B | LAF_I((uintptr_t)(target-tmp)&0xffffu) | (((uintptr_t)(target-tmp)&0x3ff0000u) >> 16);
+}
+
+/* Prepare tail of code. */
+static void asm_tail_prep(ASMState *as)
+{
+  // as->mcp = as->mctop-2;  /* Leave room for branch plus nop or stack adj. */
+  // as->invmcp = as->loopref ? as->mcp : NULL;
+  MCode *p = as->mctop - 1;  /* Leave room for exit branch. */
+  if (as->loopref) {
+    as->invmcp = as->mcp = p;
+  } else {
+    as->mcp = p-1;  /* Leave room for stack pointer adjustment. */
+    as->invmcp = NULL;
+  }
+  *p = LAI_NOP;  /* Prevent load/store merging. */
+}
+
+/* -- Trace setup --------------------------------------------------------- */
+
+/* Ensure there are enough stack slots for call arguments. */
+static Reg asm_setup_call_slots(ASMState *as, IRIns *ir, const CCallInfo *ci)
+{
+  IRRef args[CCI_NARGS_MAX*2];
+  uint32_t i, nargs = CCI_XNARGS(ci);
+  int nslots = 0, ngpr = REGARG_NUMGPR, nfpr = REGARG_NUMFPR;
+  asm_collectargs(as, ir, ci, args);
+  for (i = 0; i < nargs; i++) {
+    if (args[i] && irt_isfp(IR(args[i])->t)) {
+      if (nfpr > 0) nfpr--; else nslots += 2;
+    } else {
+      if (ngpr > 0) ngpr--; else nslots += 2;
+    }
+  }
+  if (nslots > as->evenspill)  /* Leave room for args in stack slots. */
+    as->evenspill = nslots;
+  return REGSP_HINT(RID_RET);
+  // return irt_isfp(ir->t) ? REGSP_HINT(RID_FPRET) : REGSP_HINT(RID_RET);
+}
+
+static void asm_sparejump_setup(ASMState *as)
+{
+  MCode *mxp = as->mctop;
+  if ((char *)mxp == (char *)as->J->mcarea + as->J->szmcarea) {
+    mxp -= 4*1;
+    as->mctop = mxp;
+  }
+}
+
+static void asm_setup_target(ASMState *as)
+{
+  asm_sparejump_setup(as);
+  asm_exitstub_setup(as);
+}
+
+/* -- Trace patching ------------------------------------------------------ */
+
+/* Patch exit jumps of existing machine code to a new target. */
+void lj_asm_patchexit(jit_State *J, GCtrace *T, ExitNo exitno, MCode *target)
+{
+  MCode *p = T->mcode;
+  MCode *pe = (MCode *)((char *)p + T->szmcode);
+  MCode *px = exitstub_trace_addr(T, exitno);
+  MCode *cstart = NULL;
+  MCode *mcarea = lj_mcode_patch(J, p, 0);
+
+  MCode exitload = LAI_ADDI_W | LAF_D(RID_TMP) | LAF_J(RID_ZERO) | LAF_I(exitno&0xfff);
+
+  for (p++; p < pe; p++) {
+    if (*p == exitload) {
+    /* Look for exitstub branch, replace with branch to target. */
+    ptrdiff_t delta = target - p - 1;
+    MCode ins = p[1];
+      if ((ins & 0xfc000000u) == LAI_BEQ ||
+          (ins & 0xfc000000u) == LAI_BNE ||
+          (ins & 0xfc000000u) == LAI_BLT ||
+          (ins & 0xfc000000u) == LAI_BGE) {
+        /* Patch beq/bne/blt/bge, if within range. */
+        if (LAF_S_OK(delta, 16)) {
+          p[1] = (ins & 0xfc0003ffu) | LAF_I(delta & 0xffff);
+          if (!cstart) cstart = p + 1;
+        }
+      } else if ((ins & 0xfc000000u) == LAI_BCEQZ ||
+                 (ins & 0xfc000100u) == LAI_BCNEZ) {
+        /* Patch bceqz/bcnez, if within range. */
+        if (p[-1] == LA_NOPATCH_GC_CHECK) {
+        } else if (LAF_S_OK(delta, 21)) {
+          *p = (ins & 0xfc0003e0u) | LAF_I(delta & 0xffff) | ((delta & 0x1f0000) >> 16);
+          if (!cstart) cstart = p;
+        }
+      } else if ((ins & 0xfc000000u) == LAI_B) {
+        /* Patch b. */
+        lua_assert(LAF_S_OK(delta, 26));
+        *p = (ins & 0xfc000000u) | LAF_I(delta & 0xffff) | ((delta & 0x3ff0000) >> 16);
+        if (!cstart) cstart = p;
+      } else if (p+2 == pe){
+         if (p[2] == LAI_NOP) {
+            ptrdiff_t delta = target - &p[2];
+            lua_assert(LAF_S_OK(delta, 26));
+            p[2] = LAI_B | LAF_I(delta & 0xffff) | ((delta & 0x3ff0000) >> 16);
+            *p = LAI_NOP;
+            if (!cstart) cstart = p + 2;
+         }
+       }
+    }
+  }
+  if (cstart) lj_mcode_sync(cstart, px+1);
+  lj_mcode_patch(J, mcarea, 1);
+}
diff --git a/libs/luajit/LuaJIT-src/src/lj_ccall.c b/libs/luajit/LuaJIT-src/src/lj_ccall.c
index 5c252e5..426e79a 100644
--- a/libs/luajit/LuaJIT-src/src/lj_ccall.c
+++ b/libs/luajit/LuaJIT-src/src/lj_ccall.c
@@ -562,6 +562,81 @@
     goto done; \
   }
 
+#elif LJ_TARGET_LOONGARCH64
+/* -- LoongArch lp64 calling conventions ---------------------------------------- */
+
+#define CCALL_HANDLE_STRUCTRET \
+  /* Return structs of size <= 16 in a GPR. */ \
+  cc->retref = !(sz <= 16); \
+  if (cc->retref) cc->gpr[ngpr++] = (GPRArg)dp;
+
+#define CCALL_HANDLE_STRUCTRET2 \
+  ccall_copy_struct(cc, ctr, dp, sp, ccall_classify_struct(cts, ctr, ct));
+
+#define CCALL_HANDLE_COMPLEXRET \
+  /* Complex values are returned in 1 or 2 FPRs. */ \
+  cc->retref = 0;
+
+#if LJ_ABI_SOFTFP       /* LoongArch64 soft-float */
+
+#define CCALL_HANDLE_COMPLEXRET2 \
+  if (ctr->size == 2*sizeof(float)) {  /* Copy complex float from GPRs. */ \
+    ((intptr_t *)dp)[0] = cc->gpr[0]; \
+  } else {  /* Copy complex double from GPRs. */ \
+    ((intptr_t *)dp)[0] = cc->gpr[0]; \
+    ((intptr_t *)dp)[1] = cc->gpr[1]; \
+  }
+
+#define CCALL_HANDLE_COMPLEXARG \
+  /* Pass complex by value in 2 or 4 GPRs. */
+
+/* Position of soft-float 'float' return value depends on endianess.  */
+#define CCALL_HANDLE_RET \
+  if (ctype_isfp(ctr->info) && ctr->size == sizeof(float)) \
+    sp = (uint8_t *)cc->gpr + LJ_ENDIAN_SELECT(0, 4);
+
+#else                   /* LoongArch64 hard-float */
+
+#define CCALL_HANDLE_COMPLEXRET2 \
+  if (ctr->size == 2*sizeof(float)) {  /* Copy complex float from FPRs. */ \
+    ((float *)dp)[0] = cc->fpr[0].f; \
+    ((float *)dp)[1] = cc->fpr[1].f; \
+  } else {  /* Copy complex double from FPRs. */ \
+    ((double *)dp)[0] = cc->fpr[0].d; \
+    ((double *)dp)[1] = cc->fpr[1].d; \
+  }
+
+#define CCALL_HANDLE_COMPLEXARG \
+  if (sz == 2*sizeof(float)) { \
+    isfp = 2; \
+    if (ngpr < maxgpr) \
+      sz *= 2; \
+  }
+#define CCALL_HANDLE_RET \
+  if (ctype_isfp(ctr->info) && ctr->size == sizeof(float)) \
+    sp = (uint8_t *)&cc->fpr[0].f;
+
+#endif
+
+#define CCALL_HANDLE_STRUCTARG \
+  /* Pass all structs by value in registers and/or on the stack. */
+
+#define CCALL_HANDLE_REGARG \
+  if (isfp) {  /* Try to pass argument in FPRs. */ \
+    int n2 = ctype_isvector(d->info) ? 1 : n; \
+    if (nfpr + n2 <= CCALL_NARG_FPR) { \
+      dp = &cc->fpr[nfpr]; \
+      nfpr += n2; \
+      goto done; \
+    } \
+  } else {  /* Try to pass argument in GPRs. */ \
+      if (ngpr + n <= maxgpr) { \
+        dp = &cc->gpr[ngpr]; \
+        ngpr += n; \
+        goto done; \
+    } \
+  }
+
 #else
 #error "Missing calling convention definitions for this architecture"
 #endif
@@ -873,6 +948,79 @@ void ccall_copy_struct(CCallState *cc, CType *ctr, void *dp, void *sp, int ft)
 
 #endif
 
+/* -- LoongArch64 ABI struct classification ---------------------------- */
+
+#if LJ_TARGET_LOONGARCH64
+
+#define FTYPE_FLOAT     1
+#define FTYPE_DOUBLE    2
+
+/* Classify FP fields (max. 2) and their types. */
+static unsigned int ccall_classify_struct(CTState *cts, CType *ct, CType *ctf)
+{
+  int n = 0, ft = 0;
+  if ((ctf->info & CTF_VARARG) || (ct->info & CTF_UNION))
+    goto noth;
+  while (ct->sib) {
+    CType *sct;
+    ct = ctype_get(cts, ct->sib);
+    if (n == 2) {
+      goto noth;
+    } else if (ctype_isfield(ct->info)) {
+      sct = ctype_rawchild(cts, ct);
+      if (ctype_isfp(sct->info)) {
+        ft |= (sct->size == 4 ? FTYPE_FLOAT : FTYPE_DOUBLE) << 2*n;
+        n++;
+      } else {
+        goto noth;
+      }
+    } else if (ctype_isbitfield(ct->info) ||
+               ctype_isxattrib(ct->info, CTA_SUBTYPE)) {
+      goto noth;
+    }
+  }
+  if (n <= 2)
+    return ft;
+noth:  /* Not a homogeneous float/double aggregate. */
+  return 0;  /* Struct is in GPRs. */
+}
+
+static void ccall_copy_struct(CCallState *cc, CType *ctr, void *dp, void *sp,
+                             int ft)
+{
+  if (LJ_ABI_SOFTFP ? ft :
+      ((ft & 3) == FTYPE_FLOAT || (ft >> 2) == FTYPE_FLOAT)) {
+    int i, ofs = 0;
+    for (i = 0; ft != 0; i++, ft >>= 2) {
+      if ((ft & 3) == FTYPE_FLOAT) {
+#if LJ_ABI_SOFTFP
+        /* The 2nd FP struct result is in CARG1 (gpr[2]) and not CRET2. */
+        memcpy((uint8_t *)dp + ofs, (uint8_t *)&cc->gpr[2*i], 4);
+#else
+        *(float *)((uint8_t *)dp + ofs) = cc->fpr[i].f;
+#endif
+        ofs += 4;
+      } else {
+        ofs = (ofs + 7) & ~7;  /* 64 bit alignment. */
+#if LJ_ABI_SOFTFP
+        *(intptr_t *)((uint8_t *)dp + ofs) = cc->gpr[2*i];
+#else
+        *(double *)((uint8_t *)dp + ofs) = cc->fpr[i].d;
+#endif
+        ofs += 8;
+      }
+    }
+  } else {
+#if !LJ_ABI_SOFTFP
+    if (ft) sp = (uint8_t *)&cc->fpr[0];
+#endif
+    memcpy(dp, sp, ctr->size);
+  }
+}
+
+#endif
+
+
 /* -- Common C call handling ---------------------------------------------- */
 
 /* Infer the destination CTypeID for a vararg argument. */
@@ -1068,7 +1216,7 @@ static int ccall_set_args(lua_State *L, CTState *cts, CType *ct,
       cc->fpr[nfpr-1].d[0] = cc->fpr[nfpr-2].d[1];  /* Split complex double. */
       cc->fpr[nfpr-2].d[1] = 0;
     }
-#elif LJ_TARGET_ARM64 || (LJ_TARGET_MIPS64 && !LJ_ABI_SOFTFP)
+#elif LJ_TARGET_ARM64 || (LJ_TARGET_MIPS64 && !LJ_ABI_SOFTFP) || (LJ_TARGET_LOONGARCH64 && !LJ_ABI_SOFTFP)
     if (isfp == 2 && (uint8_t *)dp < (uint8_t *)cc->stack) {
       /* Split float HFA or complex float into separate registers. */
       CTSize i = (sz >> 2) - 1;
@@ -1080,7 +1228,7 @@ static int ccall_set_args(lua_State *L, CTState *cts, CType *ct,
   }
   if (fid) lj_err_caller(L, LJ_ERR_FFI_NUMARG);  /* Too few arguments. */
 
-#if LJ_TARGET_X64 || LJ_TARGET_PPC
+#if LJ_TARGET_X64 || LJ_TARGET_PPC || LJ_TARGET_LOONGARCH64
   cc->nfpr = nfpr;  /* Required for vararg functions. */
 #endif
   cc->nsp = nsp;
diff --git a/libs/luajit/LuaJIT-src/src/lj_ccall.h b/libs/luajit/LuaJIT-src/src/lj_ccall.h
index 59f6648..1c150fa 100644
--- a/libs/luajit/LuaJIT-src/src/lj_ccall.h
+++ b/libs/luajit/LuaJIT-src/src/lj_ccall.h
@@ -126,6 +126,21 @@ typedef union FPRArg {
   struct { LJ_ENDIAN_LOHI(float f; , float g;) };
 } FPRArg;
 
+#elif LJ_TARGET_LOONGARCH64
+
+#define CCALL_NARG_GPR          8
+#define CCALL_NARG_FPR          8
+#define CCALL_NRET_GPR          2
+#define CCALL_NRET_FPR          (LJ_ABI_SOFTFP ? 0 : 2)
+#define CCALL_SPS_EXTRA         3
+#define CCALL_SPS_FREE          1
+
+typedef intptr_t GPRArg;
+typedef union FPRArg {
+  double d;
+  struct { LJ_ENDIAN_LOHI(float f; , float g;) };
+} FPRArg;
+
 #else
 #error "Missing calling convention definitions for this architecture"
 #endif
@@ -168,7 +183,7 @@ typedef LJ_ALIGN(CCALL_ALIGN_CALLSTATE) struct CCallState {
   uint8_t resx87;		/* Result on x87 stack: 1:float, 2:double. */
 #elif LJ_TARGET_ARM64
   void *retp;			/* Aggregate return pointer in x8. */
-#elif LJ_TARGET_PPC
+#elif LJ_TARGET_PPC || LJ_TARGET_LOONGARCH64
   uint8_t nfpr;			/* Number of arguments in FPRs. */
 #endif
 #if LJ_32
diff --git a/libs/luajit/LuaJIT-src/src/lj_ccallback.c b/libs/luajit/LuaJIT-src/src/lj_ccallback.c
index 846827b..c7cbd73 100644
--- a/libs/luajit/LuaJIT-src/src/lj_ccallback.c
+++ b/libs/luajit/LuaJIT-src/src/lj_ccallback.c
@@ -71,6 +71,10 @@ static MSize CALLBACK_OFS2SLOT(MSize ofs)
 
 #define CALLBACK_MCODE_HEAD		52
 
+#elif LJ_TARGET_LOONGARCH64
+
+#define CALLBACK_MCODE_HEAD		52
+
 #else
 
 /* Missing support for this architecture. */
@@ -238,6 +242,37 @@ static void callback_mcode_init(global_State *g, uint32_t *page)
   }
   lua_assert(p - page <= CALLBACK_MCODE_SIZE);
 }
+#elif LJ_TARGET_LOONGARCH64
+static void *callback_mcode_init(global_State *g, uint32_t *page)
+{
+  uint32_t *p = page;
+  uintptr_t target = (uintptr_t)(void *)lj_vm_ffi_callback;
+  uintptr_t ug = (uintptr_t)(void *)g;
+  MSize slot;
+  *p++ = LAI_LU12I_W | LAF_D(RID_R18) | LAF_I20((target >> 12) & 0xfffff);
+  *p++ = LAI_LU12I_W | LAF_D(RID_R17) | LAF_I20((ug >> 12) & 0xfffff);
+  *p++ = LAI_ORI  | LAF_D(RID_R18) | LAF_J(RID_R18) | LAF_I(target & 0xfff);
+  *p++ = LAI_ORI  | LAF_D(RID_R17) | LAF_J(RID_R17) | LAF_I(ug & 0xfff);
+  *p++ = LAI_LU32I_D | LAF_D(RID_R18) | LAF_I20((target >> 32) & 0xfffff);
+  *p++ = LAI_LU32I_D | LAF_D(RID_R17) | LAF_I20((ug >> 32) & 0xfffff);
+  *p++ = LAI_LU52I_D | LAF_D(RID_R18) | LAF_J(RID_R18) | LAF_I((target >> 52) & 0xfff);
+  *p++ = LAI_LU52I_D | LAF_D(RID_R17) | LAF_J(RID_R17) | LAF_I((ug >> 52) & 0xfff);
+  *p++ = LAI_NOP;
+  *p++ = LAI_NOP;
+  *p++ = LAI_NOP;
+  *p++ = LAI_NOP;
+  *p++ = LAI_JIRL | LAF_D(RID_R0) | LAF_J(RID_R18) | LAF_I(0);
+  for (slot = 0; slot < CALLBACK_MAX_SLOT; slot++) {
+    //*p = LAI_BEQ | LAF_D(RID_R0) | LAF_J(RID_R0) | ((page-p-1) & 0x0000ffffu);	//TODO
+    //p++;
+    //*p++ = LAI_LU12I_W | LAF_D(RID_R19) | LAF_I20((slot >> 12) & 0xfffff);		//TODO
+    *p++ = LAI_ORI  | LAF_D(RID_R19) | LAF_J(RID_R0) | LAF_I(slot & 0xfff);
+    //*p = LAI_BEQ | LAF_D(RID_ZERO) | LAF_J(RID_ZERO) | ((page-p-1) & 0x0000ffffu);
+    *p = LAI_B | LAF_I((page-p) & 0xffff) | (((page-p) >> 16) & 0x3ff);
+    p++;
+  }
+  return p;
+}
 #else
 /* Missing support for this architecture. */
 #define callback_mcode_init(g, p)	UNUSED(p)
@@ -491,6 +526,37 @@ void lj_ccallback_mcode_free(CTState *cts)
   }
 #endif
 
+#define CALLBACK_HANDLE_RET \
+  if (ctype_isfp(ctr->info) && ctr->size == sizeof(float)) \
+    ((float *)dp)[1] = *(float *)dp;
+
+#elif LJ_TARGET_LOONGARCH64
+
+#if !LJ_ABI_SOFTFP      /* LoongArch64 hard-float */
+#define CALLBACK_HANDLE_REGARG \
+  if (isfp) { \
+    if (nfpr + n <= CCALL_NARG_FPR) { \
+      sp = &cts->cb.fpr[nfpr]; \
+      nfpr += n; \
+      goto done; \
+    } \
+  } else { \
+    if (ngpr + n <= maxgpr) { \
+      sp = &cts->cb.gpr[ngpr]; \
+      ngpr += n; \
+      goto done; \
+    } \
+  }
+#else			/* LoongArch64 soft-float */
+#define CALLBACK_HANDLE_REGARG \
+  if (ngpr + n <= maxgpr) { \
+    UNUSED(isfp); \
+    sp = (void*) &cts->cb.gpr[ngpr]; \
+    ngpr += n; \
+    goto done; \
+  }
+#endif
+
 #define CALLBACK_HANDLE_RET \
   if (ctype_isfp(ctr->info) && ctr->size == sizeof(float)) \
     ((float *)dp)[1] = *(float *)dp;
diff --git a/libs/luajit/LuaJIT-src/src/lj_crecord.c b/libs/luajit/LuaJIT-src/src/lj_crecord.c
index e32ae23..89a70fa 100644
--- a/libs/luajit/LuaJIT-src/src/lj_crecord.c
+++ b/libs/luajit/LuaJIT-src/src/lj_crecord.c
@@ -132,7 +132,7 @@ static IRType crec_ct2irt(CTState *cts, CType *ct)
 #define CREC_COPY_REGWIN		2
 #elif LJ_TARGET_PPC || LJ_TARGET_MIPS
 #define CREC_COPY_REGWIN		8
-#else
+#else						//TODO
 #define CREC_COPY_REGWIN		4
 #endif
 
diff --git a/libs/luajit/LuaJIT-src/src/lj_emit_loongarch64.h b/libs/luajit/LuaJIT-src/src/lj_emit_loongarch64.h
new file mode 100644
index 0000000..bf778ea
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/src/lj_emit_loongarch64.h
@@ -0,0 +1,384 @@
+/*
+** LoongArch instruction emitter.
+** Copyright (C) 2005-2021 Mike Pall. See Copyright Notice in luajit.h
+** Copyright (C) 2021 Loongson Technology. All rights reserved.
+*/
+
+static intptr_t get_k64val(ASMState *as, IRRef ref)
+{
+  IRIns *ir = IR(ref);
+  if (ir->o == IR_KINT64) {
+    return (intptr_t)ir_kint64(ir)->u64;
+  } else if (ir->o == IR_KGC) {
+    return (intptr_t)ir_kgc(ir);
+  } else if (ir->o == IR_KPTR || ir->o == IR_KKPTR) {
+    return (intptr_t)ir_kptr(ir);
+  } else if (LJ_SOFTFP && ir->o == IR_KNUM) {
+    return (intptr_t)ir_knum(ir)->u64;
+  } else {
+    lua_assert(ir->o == IR_KINT || ir->o == IR_KNULL);
+    return ir->i;  /* Sign-extended. */
+  }
+}
+
+#define get_kval(as, ref)       get_k64val(as, ref)
+
+
+/* -- Emit basic instructions --------------------------------------------- */
+
+static void emit_djk(ASMState *as, LAIns lai, Reg rd, Reg rj, Reg rk)
+{
+  *--as->mcp = lai | LAF_D(rd & 0x1f) | LAF_J(rj & 0x1f) | LAF_K(rk & 0x1f);
+}
+
+#define emit_dj(as, lai, rd, rj)         emit_djk(as, (lai), (rd)&31, (rj)&31, 0)
+
+static void emit_di(ASMState *as, LAIns lai, Reg rd, int32_t i)
+{
+  *--as->mcp = lai | LAF_D(rd & 0x1f) | LAF_I20(i & 0xfffff);
+}
+
+static void emit_dji(ASMState *as, LAIns lai, Reg rd, Reg rj, int32_t i)
+{
+  *--as->mcp = lai | LAF_D(rd & 0x1f) | LAF_J(rj & 0x1f) | LAF_I(i);
+}
+
+static void emit_dju(ASMState *as, LAIns lai, Reg rd, Reg rj, uint32_t u)
+{
+  *--as->mcp = lai | LAF_D(rd & 0x1f) | LAF_J(rj & 0x1f) | LAF_I(u);
+}
+
+static void emit_dj32i(ASMState *as, Reg rd, Reg rj, int32_t i)
+{
+  if ((i>>12) == 0 || (i>>12) == 0xfffff) {
+    *--as->mcp = LAI_ADDI_D | LAF_D(rd) | LAF_J(rj) | LAF_I(i&0xfff);
+  } else {
+      emit_djk(as, LAI_ADD_D, rd, RID_R19, rj);
+      if ((i&0xfff) != 0) {
+        emit_dju(as, LAI_ORI, RID_R19, RID_R19, i&0xfff);
+      }
+      if (((i>>12)&0xfffff) != 0) {
+        emit_di(as, LAI_LU12I_W, RID_R19, (i>>12)&0xfffff);
+      }
+  }
+}
+
+static void emit_d16i(ASMState *as, Reg rd, int32_t i)
+{
+  emit_dji(as, LAI_SRAI_D, rd, rd, 16);
+  emit_dji(as, LAI_ADDU16I_D, rd, RID_ZERO, (i&0xffff));
+}
+
+static void emit_addw(ASMState *as, Reg rd, Reg rj, int32_t i)
+{
+  emit_djk(as, LAI_ADD_W, rd, rj, RID_R20);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_W, RID_R19, RID_R19, 24);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xff000000)>>24);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_W, RID_R19, RID_R19, 12);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xfff000)>>12);
+  emit_dji(as, LAI_ORI, RID_R20, RID_R0, i&0xfff);
+}
+
+static void emit_add(ASMState *as, Reg rd, Reg rj, int64_t i)
+{
+  emit_djk(as, LAI_ADD_D, rd, rj, RID_R20);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_D, RID_R19, RID_R19, 60);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xf000000000000000)>>60);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_D, RID_R19, RID_R19, 48);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xfff000000000000)>>48);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_D, RID_R19, RID_R19, 36);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xfff000000000)>>36);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_D, RID_R19, RID_R19, 24);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xfff000000)>>24);
+  emit_djk(as, LAI_OR, RID_R20, RID_R19, RID_R20);
+  emit_dji(as, LAI_SLLI_D, RID_R19, RID_R19, 12);
+  emit_dji(as, LAI_ORI, RID_R19, RID_R0, (i&0xfff000)>>12);
+  emit_dji(as, LAI_ORI, RID_R20, RID_R0, i&0xfff);
+}
+
+static void emit_rotr(ASMState *as, Reg dest, Reg src, Reg tmp, uint32_t shift)
+{
+  emit_dju(as, LAI_ROTRI_W, dest, src, shift);
+}
+
+static void emit_djml(ASMState *as, LAIns lai, Reg rd, Reg rj, uint32_t m, uint32_t l)
+{
+  *--as->mcp = lai | LAF_D(rd & 0x1f) | LAF_J(rj & 0x1f) | LAF_I(l & 0x3f) | LAF_M(m & 0x3f);
+}
+
+static void emit_b_bl(ASMState *as, LAIns lai, uint32_t i)
+{
+  *--as->mcp = lai | LAF_I(i & 0xffff) | ((i >> 16) & 0x3ff);
+}
+
+
+/* -- Emit loads/stores --------------------------------------------------- */
+
+/* Prefer rematerialization of BASE/L from global_State over spills. */
+#define emit_canremat(ref)	((ref) <= REF_BASE)
+
+/* Try to find a one step delta relative to another constant. */
+static int emit_kdelta1(ASMState *as, Reg t, intptr_t i)
+{
+  RegSet work = ~as->freeset & RSET_GPR;
+  while (work) {
+    Reg r = rset_picktop(work);
+    IRRef ref = regcost_ref(as->cost[r]);
+    lua_assert(r != t);
+    if (ref < ASMREF_L) {
+      intptr_t delta = (intptr_t)((uintptr_t)i -
+	(uintptr_t)(ra_iskref(ref) ? ra_krefk(as, ref) : get_kval(as, ref)));
+      if (checki16(delta)) {
+	//emit_dj32i(as, t, r, delta);	// daddiu
+	emit_djk(as, LAI_ADD_D, t, r, RID_R19);
+	emit_d16i(as, RID_R19, delta);
+	return 1;
+      }
+    }
+    rset_clear(work, r);
+  }
+  return 0;  /* Failed. */
+}
+
+/* Load a 32/64 bit constant into a GPR. */
+//#define emit_loadi(as, rd, i)   emit_loadk(as, rd, i)
+//#define emit_loadu64(as, rd, i)	emit_loadk(as, rd, i)
+
+//#define emit_loada(as, r, addr)		emit_loadu64(as, (r), u64ptr((addr)))
+
+/* Load a 32 bit constant into a GPR. */
+static void emit_loadi(ASMState *as, Reg r, int32_t i)
+{
+  if (checki16(i)) {
+    //emit_ti(as, MIPSI_LI, r, i);   // MIPSI_LI = MIPSI_ADDIU
+    emit_addw(as, r, RID_R0, i);
+  } else {
+    if ((i & 0xffff)) {
+      intptr_t jgl = (intptr_t)(void *)J2G(as->J);
+      if ((uintptr_t)(i-jgl) < 65536) {
+        //emit_tsi(as, MIPSI_ADDIU, r, RID_JGL, i-jgl-32768);
+        emit_addw(as, r, RID_JGL, i-jgl-32768);
+        return;
+      } else if (emit_kdelta1(as, r, i)) {
+        return;
+      } else if ((i >> 16) == 0) {
+        //emit_tsi(as, MIPSI_ORI, r, RID_ZERO, i);
+        emit_dji(as, LAI_ORI, r, RID_R20, i&0xfff);
+        emit_dji(as, LAI_SLLI_W, RID_R20, RID_R20, 12);
+        emit_dji(as, LAI_ORI, RID_R20, RID_R0, (i>>12)&0xf);
+        return;
+      }
+      //emit_tsi(as, MIPSI_ORI, r, r, i);
+      emit_djk(as, LAI_OR, r, r, RID_R19);
+      emit_dji(as, LAI_ORI, RID_R19, RID_R20, i&0xfff);
+      emit_dji(as, LAI_SLLI_W, RID_R20, RID_R20, 12);
+      emit_dji(as, LAI_ORI, RID_R20, RID_R0, (i>>12)&0xf);
+    }
+    //emit_ti(as, MIPSI_LUI, r, (i >> 16));
+    emit_dji(as, LAI_ADDU16I_D, r, RID_R0, (i>>16)&0xffff);
+  }
+}
+
+#if LJ_64
+/* Load a 64 bit constant into a GPR. */
+static void emit_loadu64(ASMState *as, Reg r, uint64_t u64)
+{
+  if (checki32((int64_t)u64)) {
+    emit_loadi(as, r, (int32_t)u64);
+  } else {
+    uint64_t delta = u64 - (uint64_t)(void *)J2G(as->J);
+    if (delta < 65536) {
+      //emit_tsi(as, MIPSI_DADDIU, r, RID_JGL, (int32_t)(delta-32768));
+      emit_add(as, r, RID_JGL, (int32_t)(delta-32768));
+    } else if (emit_kdelta1(as, r, (intptr_t)u64)) {
+      return;
+    } else {
+      *--as->mcp = LAI_LU52I_D | LAF_D(r) | LAF_J(r) | LAF_I((u64>>52)&0xfff);
+      *--as->mcp = LAI_LU32I_D | LAF_D(r) | LAF_I20((u64>>32)&0xfffff);
+      *--as->mcp = LAI_ORI | LAF_D(r) | LAF_J(r) | LAF_I(u64&0xfff);
+      *--as->mcp = LAI_LU12I_W | LAF_D(r) | LAF_I20((u64>>12)&0xfffff);
+    }
+    /* TODO: There are probably more optimization opportunities. */
+  }
+}
+
+#define emit_loada(as, r, addr)         emit_loadu64(as, (r), u64ptr((addr)))
+#else
+#define emit_loada(as, r, addr)         emit_loadi(as, (r), i32ptr((addr)))
+#endif
+
+static Reg ra_allock(ASMState *as, intptr_t k, RegSet allow);
+static void ra_allockreg(ASMState *as, intptr_t k, Reg r);
+
+/* Get/set from constant pointer. */
+static void emit_lsptr(ASMState *as, LAIns lai, Reg r, void *p, RegSet allow)
+{
+  intptr_t jgl = (intptr_t)(J2G(as->J));
+  intptr_t i = (intptr_t)(p);
+  Reg base;
+  if ((uint32_t)(i-jgl) < 65536) {	//TODO
+    i = i-jgl-32768;
+    base = RID_JGL;
+  } else {
+    base = ra_allock(as, i-(int16_t)i, allow);
+  }
+  // emit_dji(as, lai, r, base, i&0xfff);	/* ld.d rd, rj, si12 */
+  if ((i>>12) == 0) {
+    emit_dji(as, lai, r, base, i&0xfff);
+  }
+  else {
+    /* ld.d->ldx.d, fld.d->fldx.d, ld.s->fldx.s */
+    if (lai == LAI_LD_D)
+      lai = LAI_LDX_D;
+    else if (lai == LAI_FLD_D)
+      lai = LAI_FLDX_D;
+    else if (lai == LAI_FLD_S)
+      lai = LAI_FLDX_S;
+    emit_djk(as, lai, r, base, RID_R19);
+
+    /* move i to a GPR */
+    emit_d16i(as, RID_R19, i);
+  }
+}
+
+/* Load 64 bit IR constant into register. */
+static void emit_loadk64(ASMState *as, Reg r, IRIns *ir)
+{
+  const uint64_t *k = &ir_k64(ir)->u64;
+  Reg r64 = r;
+  if (rset_test(RSET_FPR, r)) {
+    r64 = RID_TMP;
+    emit_dj(as, LAI_MOVGR2FR_D, r, r64);
+  }
+  if ((uint32_t)((intptr_t)k-(intptr_t)J2G(as->J)) < 65536)
+    emit_lsptr(as, LAI_LD_D, r64, (void *)k, 0);	/*To copy a doubleword from a GPR to an FPR*/
+  else
+    emit_loadu64(as, r64, *k);
+}
+
+/* Get/set global_State fields. */
+static void emit_lsglptr2(ASMState *as, LAIns lai, Reg r, int32_t ofs)
+{
+  emit_djk(as, lai, r, RID_JGL, RID_R20);
+  emit_loadi(as, RID_R20, (ofs-32768));
+}
+
+#define emit_getgl(as, r, field) \
+  emit_lsglptr2(as, LAI_LDX_D, (r), (int32_t)offsetof(global_State, field))
+#define emit_setgl(as, r, field) \
+  emit_lsglptr2(as, LAI_STX_D, (r), (int32_t)offsetof(global_State, field))
+
+/* Trace number is determined from per-trace exit stubs. */
+#define emit_setvmstate(as, i)		UNUSED(i)
+
+/* -- Emit control-flow instructions -------------------------------------- */
+
+/* Label for internal jumps. */
+typedef MCode *MCLabel;
+
+/* Return label pointing to current PC. */
+#define emit_label(as)		((as)->mcp)
+
+static void emit_branch(ASMState *as, LAIns lai, Reg rj, Reg rd, MCode *target)
+{
+  MCode *p = as->mcp;
+  ptrdiff_t delta = target - (p - 1);
+  lua_assert(((delta + 0x8000) >> 16) == 0);
+  *--p = lai | LAF_D(rd) | LAF_J(rj) | LAF_I(((uint32_t)delta & 0xffffu));	/*BEQ BNE BGE BLZ*/
+  as->mcp = p;
+}
+
+static void emit_branch21(ASMState *as, LAIns lai, Reg rj, MCode *target)
+{
+  MCode *p = as->mcp;
+  ptrdiff_t delta = target - (p - 1);
+  lua_assert(((delta + 0x100000) >> 21) == 0);
+  *--p = lai | LAF_J(rj) | LAF_I(((uint32_t)delta & 0xffffu)) | ((uint32_t)delta & 0x1f0000u);	/*BEQZ BNEZ BCEQZ BCNEZ*/
+  as->mcp = p;
+}
+
+static void emit_jmp(ASMState *as, MCode *target)
+{
+  MCode *p = as->mcp;
+  ptrdiff_t delta = target - (p - 1);
+  emit_b_bl(as, LAI_B, (delta&0x3ffffff));	/*offs 26*/
+}
+
+#define emit_move(as, dst, src) \
+  emit_djk(as, LAI_OR, (dst), (src), RID_ZERO)
+
+static void emit_call(ASMState *as, void *target)
+{
+  RegSet pick = as->freeset & RID2RSET(RID_CFUNCADDR);
+  if (!pick) {
+    Reg r = rset_picktop(as->freeset & RSET_GPR);
+    rset_clear(as->freeset, r);
+    emit_move(as, RID_CFUNCADDR, r);
+    emit_dji(as, LAI_JIRL, RID_RA, RID_CFUNCADDR, 0);
+    //emit_dj32i(as, RID_CFUNCADDR, RID_ZERO, (intptr_t)target);
+    emit_add(as, RID_CFUNCADDR, RID_ZERO, (intptr_t)target);
+    emit_move(as, r, RID_CFUNCADDR);
+    rset_set(as->freeset, (r));
+  } else {
+    emit_dji(as, LAI_JIRL, RID_RA, RID_CFUNCADDR, 0);
+    ra_allockreg(as, (intptr_t)target, RID_CFUNCADDR);
+  }
+}
+
+/* -- Emit generic operations --------------------------------------------- */
+
+/* Generic move between two regs. */
+static void emit_movrr(ASMState *as, IRIns *ir, Reg dst, Reg src)
+{
+  if (dst < RID_MAX_GPR)
+    emit_move(as, dst, src);
+  else
+    emit_dj(as, irt_isnum(ir->t) ? LAI_FMOV_D : LAI_FMOV_S, dst, src);
+}
+
+/* Generic load of register with base and (small) offset address. */
+static void emit_loadofs(ASMState *as, IRIns *ir, Reg r, Reg base, int32_t ofs)
+{
+  if (r < RID_MAX_GPR) {
+    //emit_dji(as, irt_is64(ir->t) ? LAI_LD_D : LAI_LD_W, r, base, ofs&0xfff);
+    emit_djk(as, irt_is64(ir->t) ? LAI_LDX_D : LAI_LDX_W, r, base, RID_R19);
+  } else {
+    //emit_dji(as, irt_isnum(ir->t) ? LAI_FLD_D : LAI_FLD_S, r, base, ofs&0xfff);
+    emit_djk(as, irt_isnum(ir->t) ? LAI_FLDX_D : LAI_FLDX_S, r, base, RID_R19);
+  }
+  emit_d16i(as, RID_R19, ofs);
+}
+
+/* Generic store of register with base and (small) offset address. */
+static void emit_storeofs(ASMState *as, IRIns *ir, Reg r, Reg base, int32_t ofs)
+{
+  if (r < RID_MAX_GPR) {
+    //emit_dji(as, irt_is64(ir->t) ? LAI_ST_D : LAI_ST_W, r, base, ofs&0xfff);
+    emit_djk(as, irt_is64(ir->t) ? LAI_STX_D : LAI_STX_W, r, base, RID_R19);
+  } else {
+    //emit_dji(as, irt_isnum(ir->t) ? LAI_FST_D : LAI_FST_S,
+	  //   (r&31), base, ofs&0xfff);
+    emit_djk(as, irt_isnum(ir->t) ? LAI_FSTX_D : LAI_FSTX_S, (r&31), base, RID_R19);
+  }
+  emit_d16i(as, RID_R19, ofs);
+}
+
+/* Add offset to pointer. */
+static void emit_addptr(ASMState *as, Reg r, int32_t ofs)
+{
+  if (ofs) {
+    lua_assert(checki16(ofs));
+    //emit_dji(as, LAI_ADDI_D, r, r, ofs&0xfff);	//TODO 12bit -> 16bit
+    emit_djk(as, LAI_ADD_D, r, r, RID_R19);
+    emit_d16i(as, RID_R19, ofs);
+  }
+}
+
+
+#define emit_spsub(as, ofs)	emit_addptr(as, RID_SP, -(ofs))
diff --git a/libs/luajit/LuaJIT-src/src/lj_frame.h b/libs/luajit/LuaJIT-src/src/lj_frame.h
index 19c49a4..d129530 100644
--- a/libs/luajit/LuaJIT-src/src/lj_frame.h
+++ b/libs/luajit/LuaJIT-src/src/lj_frame.h
@@ -264,6 +264,24 @@ enum { LJ_CONT_TAILCALL, LJ_CONT_FFI_CALLBACK };  /* Special continuations. */
 #endif
 #define CFRAME_OFS_MULTRES	0
 #define CFRAME_SHIFT_MULTRES	3
+#elif LJ_TARGET_LOONGARCH64		//TODO
+#if LJ_ARCH_HASFPU
+#define CFRAME_OFS_ERRF		188
+#define CFRAME_OFS_NRES		184
+#define CFRAME_OFS_PREV		176
+#define CFRAME_OFS_L		168
+#define CFRAME_OFS_PC		160
+#define CFRAME_SIZE		192
+#else
+#define CFRAME_OFS_ERRF		124
+#define CFRAME_OFS_NRES		120
+#define CFRAME_OFS_PREV		112
+#define CFRAME_OFS_L		104
+#define CFRAME_OFS_PC		96
+#define CFRAME_SIZE		128
+#endif
+#define CFRAME_OFS_MULTRES	0
+#define CFRAME_SHIFT_MULTRES	3
 #else
 #error "Missing CFRAME_* definitions for this architecture"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_gdbjit.c b/libs/luajit/LuaJIT-src/src/lj_gdbjit.c
index c219ffa..5ac5db7 100644
--- a/libs/luajit/LuaJIT-src/src/lj_gdbjit.c
+++ b/libs/luajit/LuaJIT-src/src/lj_gdbjit.c
@@ -306,6 +306,9 @@ enum {
 #elif LJ_TARGET_MIPS
   DW_REG_SP = 29,
   DW_REG_RA = 31,
+#elif LJ_TARGET_LOONGARCH64
+  DW_REG_SP = 3,
+  DW_REG_RA = 1,
 #else
 #error "Unsupported target architecture"
 #endif
@@ -383,6 +386,8 @@ static const ELFheader elfhdr_template = {
   .machine = 20,
 #elif LJ_TARGET_MIPS
   .machine = 8,
+#elif LJ_TARGET_LOONGARCH64
+  .machine = 258,
 #else
 #error "Unsupported target architecture"
 #endif
@@ -591,6 +596,13 @@ static void LJ_FASTCALL gdbjit_ehframe(GDBJITctx *ctx)
       for (i = 23; i >= 16; i--) { DB(DW_CFA_offset|i); DUV(26-i); }
       for (i = 30; i >= 20; i -= 2) { DB(DW_CFA_offset|32|i); DUV(42-i); }
     }
+#elif LJ_TARGET_LOONGARCH64
+    {
+      int i;
+      DB(DW_CFA_offset|30); DUV(2);	//TODO
+      for (i = 30; i >= 23; i--) { DB(DW_CFA_offset|i); DUV(3+(30-i)); }
+      for (i = 31; i >= 24; i--) { DB(DW_CFA_offset|32|i); DUV(42-i); }		//TODO
+    }
 #else
 #error "Unsupported target architecture"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_ircall.h b/libs/luajit/LuaJIT-src/src/lj_ircall.h
index 973c36e..e136526 100644
--- a/libs/luajit/LuaJIT-src/src/lj_ircall.h
+++ b/libs/luajit/LuaJIT-src/src/lj_ircall.h
@@ -84,6 +84,12 @@ typedef struct CCallInfo {
 #define IRCALLCOND_SOFTFP_MIPS(x)	NULL
 #endif
 
+#if LJ_SOFTFP && LJ_TARGET_LOONGARCH64
+#define IRCALLCOND_SOFTFP_LOONGARCH64(x)	x
+#else
+#define IRCALLCOND_SOFTFP_LOONGARCH64(x)	NULL
+#endif
+
 #define LJ_NEED_FP64	(LJ_TARGET_ARM || LJ_TARGET_PPC || LJ_TARGET_MIPS32)
 
 #if LJ_HASFFI && (LJ_SOFTFP || LJ_NEED_FP64)
@@ -272,7 +278,7 @@ LJ_DATA const CCallInfo lj_ir_callinfo[IRCALL__MAX+1];
 #define fp64_f2l __aeabi_f2lz
 #define fp64_f2ul __aeabi_f2ulz
 #endif
-#elif LJ_TARGET_MIPS
+#elif LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
 #define softfp_add __adddf3
 #define softfp_sub __subdf3
 #define softfp_mul __muldf3
@@ -308,7 +314,7 @@ extern float softfp_ui2f(uint32_t a);
 extern int32_t softfp_f2i(float a);
 extern uint32_t softfp_f2ui(float a);
 #endif
-#if LJ_TARGET_MIPS
+#if LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
 extern double lj_vm_sfmin(double a, double b);
 extern double lj_vm_sfmax(double a, double b);
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_jit.h b/libs/luajit/LuaJIT-src/src/lj_jit.h
index 92054e3..db4b7f4 100644
--- a/libs/luajit/LuaJIT-src/src/lj_jit.h
+++ b/libs/luajit/LuaJIT-src/src/lj_jit.h
@@ -55,6 +55,13 @@
 #else
 #define JIT_F_CPUSTRING		"\010MIPS64R2"
 #endif
+
+#elif LJ_TARGET_LOONGARCH64
+#define JIT_F_CPU		0x00000010
+#define JIT_F_GS464V            (JIT_F_CPU << 0)
+#define JIT_F_CPU_FIRST		JIT_F_GS464V
+#define JIT_F_CPUSTRING         "\6GS464V"
+
 #else
 #define JIT_F_CPU_FIRST		0
 #define JIT_F_CPUSTRING		""
@@ -335,7 +342,7 @@ enum {
   LJ_K64_M2P64_31 = LJ_K64_M2P64,
 #endif
 #endif
-#if LJ_TARGET_MIPS
+#if LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
   LJ_K64_2P31,		/* 2^31 */
 #if LJ_64
   LJ_K64_2P63,		/* 2^63 */
@@ -353,10 +360,10 @@ enum {
   LJ_K32_2P52_2P31,	/* 2^52 + 2^31 */
   LJ_K32_2P52,		/* 2^52 */
 #endif
-#if LJ_TARGET_PPC || LJ_TARGET_MIPS
+#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
   LJ_K32_2P31,		/* 2^31 */
 #endif
-#if LJ_TARGET_MIPS64
+#if LJ_TARGET_MIPS64 || LJ_TARGET_LOONGARCH64
   LJ_K32_2P63,		/* 2^63 */
   LJ_K32_M2P64,		/* -2^64 */
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_target.h b/libs/luajit/LuaJIT-src/src/lj_target.h
index 8dcae95..52a0a7e 100644
--- a/libs/luajit/LuaJIT-src/src/lj_target.h
+++ b/libs/luajit/LuaJIT-src/src/lj_target.h
@@ -55,7 +55,7 @@ typedef uint32_t RegSP;
 /* Bitset for registers. 32 registers suffice for most architectures.
 ** Note that one set holds bits for both GPRs and FPRs.
 */
-#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_ARM64
+#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_ARM64 || LJ_TARGET_LOONGARCH64
 typedef uint64_t RegSet;
 #else
 typedef uint32_t RegSet;
@@ -69,7 +69,7 @@ typedef uint32_t RegSet;
 #define rset_set(rs, r)		(rs |= RID2RSET(r))
 #define rset_clear(rs, r)	(rs &= ~RID2RSET(r))
 #define rset_exclude(rs, r)	(rs & ~RID2RSET(r))
-#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_ARM64
+#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_ARM64 || LJ_TARGET_LOONGARCH64
 #define rset_picktop(rs)	((Reg)(__builtin_clzll(rs)^63))
 #define rset_pickbot(rs)	((Reg)__builtin_ctzll(rs))
 #else
@@ -144,6 +144,8 @@ typedef uint32_t RegCost;
 #include "lj_target_ppc.h"
 #elif LJ_TARGET_MIPS
 #include "lj_target_mips.h"
+#elif LJ_TARGET_LOONGARCH64
+#include "lj_target_loongarch64.h"
 #else
 #error "Missing include for target CPU"
 #endif
diff --git a/libs/luajit/LuaJIT-src/src/lj_target_loongarch64.h b/libs/luajit/LuaJIT-src/src/lj_target_loongarch64.h
new file mode 100644
index 0000000..6d96b45
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/src/lj_target_loongarch64.h
@@ -0,0 +1,339 @@
+/*
+** Definitions for LoongArch CPUs.
+** Copyright (C) 2005-2021 Mike Pall. See Copyright Notice in luajit.h
+** Copyright (C) 2021 Loongson Technology. All rights reserved.
+*/
+
+#ifndef _LJ_TARGET_LOONGARCH_H
+#define _LJ_TARGET_LOONGARCH_H
+
+/* -- Registers IDs ------------------------------------------------------- */
+
+#define GPRDEF(_) \
+  _(R0) _(RA) _(R2) _(SP) _(R4) _(R5) _(R6) _(R7) \
+  _(R8) _(R9) _(R10) _(R11) _(R12) _(R13) _(R14) _(R15) \
+  _(R16) _(R17) _(R18) _(R19) _(R20) _(R21) _(R22) _(R23) \
+  _(R24) _(R25) _(R26) _(R27) _(R28) _(R29) _(R30) _(R31)
+#if LJ_SOFTFP
+#define FPRDEF(_)
+#else
+#define FPRDEF(_) \
+  _(F0) _(F1) _(F2) _(F3) _(F4) _(F5) _(F6) _(F7) \
+  _(F8) _(F9) _(F10) _(F11) _(F12) _(F13) _(F14) _(F15) \
+  _(F16) _(F17) _(F18) _(F19) _(F20) _(F21) _(F22) _(F23) \
+  _(F24) _(F25) _(F26) _(F27) _(F28) _(F29) _(F30) _(F31)
+#endif
+#define VRIDDEF(_)
+
+#define RIDENUM(name)	RID_##name,
+
+enum {
+  GPRDEF(RIDENUM)		/* General-purpose registers (GPRs). */
+  FPRDEF(RIDENUM)		/* Floating-point registers (FPRs). */
+  RID_MAX,
+  RID_ZERO = RID_R0,
+  RID_TMP = RID_RA,		//TODO
+  RID_GP = RID_R31,
+
+  /* Calling conventions. */
+  RID_RET = RID_R4,
+
+  RID_RETHI = RID_R18,
+  RID_RETLO = RID_R17,
+
+#if LJ_SOFTFP
+  RID_FPRET = RID_R17,
+#else
+  RID_FPRET = RID_F0,
+#endif
+  RID_CFUNCADDR = RID_R16,
+
+  /* These definitions must match with the *.dasc file(s): */
+  RID_BASE = RID_R23,		/* Interpreter BASE. */
+  RID_LPC = RID_R25,		/* Interpreter PC. */
+  RID_DISPATCH = RID_R26,	/* Interpreter DISPATCH table. */
+  RID_LREG = RID_R27,		/* Interpreter L. */
+  RID_JGL = RID_R22,		/* On-trace: global_State + 32768. */
+
+  /* Register ranges [min, max) and number of registers. */
+  RID_MIN_GPR = RID_R0,
+  RID_MAX_GPR = RID_R31+1,
+  RID_MIN_FPR = RID_MAX_GPR,
+#if LJ_SOFTFP
+  RID_MAX_FPR = RID_MIN_FPR,
+#else
+  RID_MAX_FPR = RID_F31+1,
+#endif
+  RID_NUM_GPR = RID_MAX_GPR - RID_MIN_GPR,
+  RID_NUM_FPR = RID_MAX_FPR - RID_MIN_FPR
+};
+
+#define RID_NUM_KREF		RID_NUM_GPR
+#define RID_MIN_KREF		RID_R0
+
+/* -- Register sets ------------------------------------------------------- */
+
+/* Make use of all registers, except ZERO, TMP, SP, JGL. */
+#define RSET_FIXED \
+  (RID2RSET(RID_ZERO)|RID2RSET(RID_TMP)|RID2RSET(RID_R2)|\
+   RID2RSET(RID_SP)|RID2RSET(RID_JGL)|RID2RSET(RID_R31)|\
+   RID2RSET(RID_R19)|RID2RSET(RID_R20))
+#define RSET_GPR	(RSET_RANGE(RID_MIN_GPR, RID_MAX_GPR) - RSET_FIXED)
+#if LJ_SOFTFP
+#define RSET_FPR		0
+#else
+#define RSET_FPR		RSET_RANGE(RID_MIN_FPR, RID_MAX_FPR)
+#endif
+#define RSET_ALL		(RSET_GPR|RSET_FPR)
+#define RSET_INIT		RSET_ALL
+
+/* scratch register. */
+#define RSET_SCRATCH_GPR \
+  (RSET_RANGE(RID_R4, RID_R19))
+#if LJ_SOFTFP
+#define RSET_SCRATCH_FPR	0
+#else
+#define RSET_SCRATCH_FPR	RSET_RANGE(RID_F0, RID_F23+1)
+#endif
+#define RSET_SCRATCH		(RSET_SCRATCH_GPR|RSET_SCRATCH_FPR)
+#define REGARG_FIRSTGPR		RID_R4
+#define REGARG_LASTGPR		RID_R11
+#define REGARG_NUMGPR		8
+#if LJ_ABI_SOFTFP
+#define REGARG_FIRSTFPR		0
+#define REGARG_LASTFPR		0
+#define REGARG_NUMFPR		0
+#else
+#define REGARG_FIRSTFPR		RID_F0
+#define REGARG_LASTFPR		RID_F7
+#define REGARG_NUMFPR		8
+#endif
+
+/* -- Spill slots --------------------------------------------------------- */
+
+/* Spill slots are 32 bit wide. An even/odd pair is used for FPRs.
+**
+** SPS_FIXED: Available fixed spill slots in interpreter frame.
+** This definition must match with the *.dasc file(s).
+**
+** SPS_FIRST: First spill slot for general use.
+*/
+#define SPS_FIXED	4
+#define SPS_FIRST	4	//TODO
+
+#define SPOFS_TMP	0
+
+#define sps_scale(slot)		(4 * (int32_t)(slot))
+#define sps_align(slot)		(((slot) - SPS_FIXED + 1) & ~1)	//TODO
+
+/* -- Exit state ---------------------------------------------------------- */
+
+/* This definition must match with the *.dasc file(s). */
+typedef struct {
+#if !LJ_SOFTFP
+  lua_Number fpr[RID_NUM_FPR];	/* Floating-point registers. */
+#endif
+  intptr_t gpr[RID_NUM_GPR];	/* General-purpose registers. */
+  int32_t spill[256];		/* Spill slots. */
+} ExitState;
+
+/* Highest exit + 1 indicates stack check. */
+#define EXITSTATE_CHECKEXIT	1
+
+/* Return the address of a per-trace exit stub. */
+static LJ_AINLINE uint32_t *exitstub_trace_addr_(uint32_t *p)
+{
+  while (*p == 0x03400000) p++;		/* Skip LAI_NOP. */
+  return p;
+}
+/* Avoid dependence on lj_jit.h if only including lj_target.h. */
+#define exitstub_trace_addr(T, exitno) \
+  exitstub_trace_addr_((MCode *)((char *)(T)->mcode + (T)->szmcode))
+
+/* -- Instructions -------------------------------------------------------- */
+
+/* Instruction fields. */
+#define LAF_D(r)	(r)
+#define LAF_J(r)	((r) << 5)
+#define LAF_K(r)	((r) << 10)
+#define LAF_A(r)	((r) << 15)
+#define LAF_FC(r)	((r) << 5)
+#define LAF_I(n)	((n) << 10)
+#define LAF_I20(n)	((n) << 5)
+#define LAF_M(n)	((n) << 16)
+
+/* Check for valid field range. */
+#define LAF_S_OK(x, b) ((((x) + (1 << (b-1))) >> (b)) == 0)
+
+typedef enum LAIns {
+/* Integer instructions. */
+  LAI_MOVE = 0x00150000,
+  LAI_NOP = 0x03400000,
+
+  LAI_LU = 0x03800000,
+
+  LAI_AND = 0x00148000,
+  LAI_ANDI = 0x03400000,
+  LAI_OR = 0x00150000,
+  LAI_ORI = 0x03800000,
+  LAI_XOR = 0x00158000,
+  LAI_XORI = 0x03c00000,
+  LAI_NOR = 0x00140000,
+
+  LAI_SLT = 0x00120000,
+  LAI_SLTU = 0x00128000,
+  LAI_SLTI = 0x02000000,
+  LAI_SLTUI = 0x02400000,
+
+  LAI_ADD_W = 0x00100000,
+  LAI_ADDI_W = 0x02800000,
+  LAI_SUB_W = 0x00110000,
+  LAI_MUL_W = 0x001c0000,
+  LAI_MULH_W = 0x001c8000,
+  LAI_DIV_W = 0x00200000,
+  LAI_DIV_WU = 0x00210000,
+
+  LAI_SLLI_W = 0x00408000,
+  LAI_SRLI_W = 0x00448000,
+  LAI_SRAI_W = 0x00488000,
+  LAI_ROTRI_W = 0x004c8000,
+  LAI_ROTRI_D = 0x004d0000,
+  LAI_SLL_W = 0x00170000,
+  LAI_SRL_W = 0x00178000,
+  LAI_SRA_W = 0x00180000,
+  LAI_ROTR_W = 0x001b0000,
+  LAI_ROTR_D = 0x001b8000,
+
+  LAI_EXT_W_B = 0x00005c00,
+  LAI_EXT_W_H = 0x00005800,
+  LAI_REVB_2H = 0x00003000,
+  LAI_REVB_4H = 0x00003400,
+
+  LAI_ALSL_W = 0x00040000,
+  LAI_ALSL_D = 0x002c0000,
+
+  LAI_B = 0x50000000,
+  LAI_BL = 0x54000000,
+  LAI_JIRL = 0x4c000000,
+
+  LAI_BEQ = 0x58000000,
+  LAI_BNE = 0x5c000000,
+  LAI_BLT = 0x60000000,
+  LAI_BGE = 0x64000000,
+  LAI_BCEQZ = 0x48000000,
+  LAI_BCNEZ = 0x48000100,
+
+  /* Load/store instructions. */
+  LAI_LD_W = 0x28800000,
+  LAI_LD_D = 0x28c00000,
+  LAI_ST_W = 0x29800000,
+  LAI_ST_D = 0x29c00000,
+  LAI_LD_B = 0x28000000,
+  LAI_ST_B = 0x29000000,
+  LAI_LD_H = 0x28400000,
+  LAI_ST_H = 0x29400000,
+  LAI_LD_BU = 0x2a000000,
+  LAI_LD_HU = 0x2a400000,
+  LAI_LDX_B = 0x38000000,
+  LAI_LDX_BU = 0x38200000,
+  LAI_LDX_H = 0x38040000,
+  LAI_LDX_HU = 0x38240000,
+  LAI_LDX_D = 0x380c0000,
+  LAI_STX_D = 0x381c0000,
+  LAI_LDX_W = 0x38080000,
+  LAI_STX_W = 0x38180000,
+  LAI_FLD_S = 0x2b000000,
+  LAI_FST_S = 0x2b400000,
+  LAI_FLD_D = 0x2b800000,
+  LAI_FST_D = 0x2bc00000,
+  LAI_FLDX_D = 0x38340000,
+  LAI_FLDX_S = 0x38300000,
+  LAI_FSTX_D = 0x383c0000,
+  LAI_FSTX_S = 0x38380000,
+
+  /* LA64 instructions. */
+  LAI_ADD_D = 0x00108000,
+  LAI_ADDI_D = 0x02c00000,
+  LAI_ADDU16I_D = 0x10000000,
+  LAI_LU12I_W = 0x14000000,
+  LAI_LU32I_D = 0x16000000,
+  LAI_LU52I_D = 0x3000000,
+  LAI_SUB_D = 0x00118000,
+  LAI_DIV_D = 0x00220000,
+  LAI_DIV_DU = 0x00230000,
+  LAI_MUL_D = 0x001d8000,
+
+  LAI_SLLI_D = 0x00410000,
+  LAI_SRLI_D = 0x00450000,
+  LAI_SLL_D = 0x00188000,
+  LAI_SRL_D = 0x00190000,
+  LAI_SRAI_D = 0x00490000,
+  LAI_SRA_D = 0x00198000,
+  LAI_REVH_D = 0x00004400,
+
+  /* Extract/insert instructions. */
+  LAI_BSTRPICK_D = 0x00c00000,
+  LAI_BSTRINS_W = 0x00600000,
+  LAI_BSTRINS_D = 0x00800000,
+
+  LAI_MASKEQZ = 0x00130000,
+  LAI_MASKNEZ = 0x00138000,
+
+  LAI_FRINT_S = 0x011e4400,
+  LAI_FRINT_D = 0x011e4800,
+  LAI_FTINTRM_L_D = 0x011a2800,
+  LAI_FTINTRP_L_D = 0x011a6800,
+  LAI_FTINTRNE_L_D = 0x011ae800,
+
+  /* FP instructions. */
+  LAI_FMOV_S = 0x01149400,
+  LAI_FMOV_D = 0x01149800,
+
+  LAI_FABS_D = 0x01140800,
+  LAI_FNEG_D = 0x01141800,
+
+  LAI_FADD_D = 0x01010000,
+  LAI_FSUB_D = 0x01030000,
+  LAI_FMUL_D = 0x01050000,
+  LAI_FDIV_D = 0x01070000,
+  LAI_FSQRT_D = 0x01144800,
+
+  LAI_FMIN_D = 0x010b0000,
+  LAI_FMAX_D = 0x01090000,
+
+  LAI_FADD_S = 0x01008000,
+  LAI_FSUB_S = 0x01028000,
+
+  LAI_FCVT_D_S = 0x01192400,
+  LAI_FTINT_W_S = 0x011b0400,
+  LAI_FCVT_S_D = 0x01191800,
+  LAI_FTINT_W_D = 0x011b0800,
+  LAI_FFINT_S_W = 0x011d1000,
+  LAI_FFINT_D_W = 0x011d2000,
+  LAI_FFINT_S_L = 0x011d1800,
+  LAI_FFINT_D_L = 0x011d2800,
+
+  LAI_FTINTRZ_W_S = 0x011a8400,
+  LAI_FTINTRZ_W_D = 0x011a8800,
+  LAI_FTINTRZ_L_S = 0x011aa400,
+  LAI_FTINTRZ_L_D = 0x011aa800,
+  LAI_FTINTRM_W_S = 0x011a0400,
+  LAI_FTINTRM_W_D = 0x011a0800,
+
+  LAI_MOVFR2GR_S = 0x0114b400,
+  LAI_MOVGR2FR_W = 0x0114a400,
+  LAI_MOVGR2FR_D = 0x0114a800,
+  LAI_MOVFR2GR_D = 0x0114b800,
+
+  LAI_FCMP_CEQ_D = 0x0c220000,
+  LAI_FCMP_CLT_S = 0x0c110000,
+  LAI_FCMP_CLT_D = 0x0c210000,
+  LAI_FCMP_CLE_D = 0x0c230000,
+  LAI_FCMP_CULE_D = 0x0c270000,
+  LAI_FCMP_CULT_D = 0x0c250000,
+  LAI_FCMP_CNE_D = 0x0c280000, 
+  LAI_FSEL = 0x0d000000,
+} LAIns;
+
+#endif
+
diff --git a/libs/luajit/LuaJIT-src/src/lj_trace.c b/libs/luajit/LuaJIT-src/src/lj_trace.c
index d85b47f..021fd49 100644
--- a/libs/luajit/LuaJIT-src/src/lj_trace.c
+++ b/libs/luajit/LuaJIT-src/src/lj_trace.c
@@ -325,17 +325,17 @@ void lj_trace_initstate(global_State *g)
   J->k64[LJ_K64_2P64].u64 = U64x(43f00000,00000000);
   J->k32[LJ_K32_M2P64_31] = LJ_64 ? 0xdf800000 : 0xcf000000;
 #endif
-#if LJ_TARGET_X86ORX64 || LJ_TARGET_MIPS64
+#if LJ_TARGET_X86ORX64 || LJ_TARGET_MIPS64 || LJ_TARGET_LOONGARCH64
   J->k64[LJ_K64_M2P64].u64 = U64x(c3f00000,00000000);
 #endif
 #if LJ_TARGET_PPC
   J->k32[LJ_K32_2P52_2P31] = 0x59800004;
   J->k32[LJ_K32_2P52] = 0x59800000;
 #endif
-#if LJ_TARGET_PPC || LJ_TARGET_MIPS
+#if LJ_TARGET_PPC || LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
   J->k32[LJ_K32_2P31] = 0x4f000000;
 #endif
-#if LJ_TARGET_MIPS
+#if LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
   J->k64[LJ_K64_2P31].u64 = U64x(41e00000,00000000);
 #if LJ_64
   J->k64[LJ_K64_2P63].u64 = U64x(43e00000,00000000);
diff --git a/libs/luajit/LuaJIT-src/src/lj_vm.h b/libs/luajit/LuaJIT-src/src/lj_vm.h
index 1cc7eed..8bad4e6 100644
--- a/libs/luajit/LuaJIT-src/src/lj_vm.h
+++ b/libs/luajit/LuaJIT-src/src/lj_vm.h
@@ -54,7 +54,8 @@ LJ_ASMF void lj_vm_exit_handler(void);
 LJ_ASMF void lj_vm_exit_interp(void);
 
 /* Internal math helper functions. */
-#if LJ_TARGET_PPC || LJ_TARGET_ARM64 || (LJ_TARGET_MIPS && LJ_ABI_SOFTFP)
+#if LJ_TARGET_PPC || LJ_TARGET_ARM64 || (LJ_TARGET_MIPS && LJ_ABI_SOFTFP)\
+|| (LJ_TARGET_LOONGARCH64 && LJ_ABI_SOFTFP)
 #define lj_vm_floor	floor
 #define lj_vm_ceil	ceil
 #else
diff --git a/libs/luajit/LuaJIT-src/src/lj_vmmath.c b/libs/luajit/LuaJIT-src/src/lj_vmmath.c
index b231d3e..8484220 100644
--- a/libs/luajit/LuaJIT-src/src/lj_vmmath.c
+++ b/libs/luajit/LuaJIT-src/src/lj_vmmath.c
@@ -57,7 +57,7 @@ double lj_vm_foldarith(double x, double y, int op)
   }
 }
 
-#if (LJ_HASJIT && !(LJ_TARGET_ARM || LJ_TARGET_ARM64 || LJ_TARGET_PPC)) || LJ_TARGET_MIPS
+#if (LJ_HASJIT && !(LJ_TARGET_ARM || LJ_TARGET_ARM64 || LJ_TARGET_PPC)) || LJ_TARGET_MIPS || LJ_TARGET_LOONGARCH64
 int32_t LJ_FASTCALL lj_vm_modi(int32_t a, int32_t b)
 {
   uint32_t y, ua, ub;
diff --git a/libs/luajit/LuaJIT-src/src/vm_loongarch64.dasc b/libs/luajit/LuaJIT-src/src/vm_loongarch64.dasc
new file mode 100644
index 0000000..b91092a
--- /dev/null
+++ b/libs/luajit/LuaJIT-src/src/vm_loongarch64.dasc
@@ -0,0 +1,5219 @@
+|// Low-level VM code for LoongArch CPUs.
+|// Bytecode interpreter, fast functions and helper functions.
+|// Copyright (C) 2005-2021 Mike Pall. See Copyright Notice in luajit.h
+|// Copyright (C) 2021 Loongson Technology. All rights reserved.
+|
+|.arch loongarch64
+|.section code_op, code_sub
+|
+|.actionlist build_actionlist
+|.globals GLOB_
+|.globalnames globnames
+|.externnames extnames
+|
+|// Note: The ragged indentation of the instructions is intentional.
+|//       The starting columns indicate data dependencies.
+|
+|//-----------------------------------------------------------------------
+|
+|// Fixed register assignments for the interpreter.
+|// Don't use: r0 = 0, r1 = ra, r2 = tp, r3 = sp, r21 = reserved
+|
+|.macro .FPU, a, b, c
+|.if FPU
+|  a, b, c
+|.endif
+|.endmacro
+|
+|.macro .FPU2, a, b
+|.if FPU
+|  a, b
+|.endif
+|.endmacro
+|
+|.macro .LI, a, b
+|  addu16i.d r20, r0, b
+|  srai.d r20, r20, 16
+|  or a, r0, r20
+|.endmacro
+|
+|.macro .LUI, a, b
+|  addi.w a, r0, b>>5
+|  slli.w a, a, 5
+|  ori a, a, b&0x1f
+|  slli.w a, a, 16
+|.endmacro
+|
+|.macro .STXW, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  stx.w a, b, r20
+|.endmacro
+|
+|.macro .STXD, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  stx.d a, b, r20
+|.endmacro
+|
+|.macro .LDXW, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  ldx.w a, b, r20
+|.endmacro
+|
+|.macro .LDXD, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  ldx.d a, b, r20
+|.endmacro
+|
+|.macro .LDXBU, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  ldx.bu a, b, r20
+|.endmacro
+|
+|.macro .DADDIU, a, b, c
+|  addu16i.d r20, r0, c
+|  srai.d r20, r20, 16
+|  add.d a, b, r20
+|.endmacro
+|
+|// The following must be C callee-save (but BASE is often refetched).
+|.define BASE,		r23	// Base of current Lua stack frame.
+|.define KBASE,		r24	// Constants of current Lua function.
+|.define PC,		r25	// Next PC.
+|.define DISPATCH,	r26	// Opcode dispatch table.
+|.define LREG,		r27	// Register holding lua_State (also in SAVE_L).
+|.define MULTRES,	r28	// Size of multi-result: (nresults+1)*8.
+|
+|.define JGL,		r22	// On-trace: global_State + 32768.
+|
+|// Constants for type-comparisons, stores and conversions. C callee-save.
+|.define TISNIL,	r22
+|.define TISNUM,	r29
+|.if FPU
+|.define TOBIT,		f30	// 2^52 + 2^51.
+|.endif
+|
+|// The following temporaries are not saved across C calls, except for RA.
+|.define RA,		r30	// Callee-save.
+|.define RB,		r8
+|.define RC,		r9
+|.define RD,		r10
+|.define INS,		r11
+|
+|.define AT,		r19
+|.define TMP0,		r12
+|.define TMP1,		r13
+|.define TMP2,		r14
+|.define TMP3,		r15
+|
+|// Loongarch lp64 calling convention.
+|.define CFUNCADDR,	r16
+|.define CARG1,		r4
+|.define CARG2,		r5
+|.define CARG3,		r6
+|.define CARG4,		r7
+|.define CARG5,		r8
+|.define CARG6,		r9
+|.define CARG7,		r10
+|.define CARG8,		r11
+|
+|.define CRET1,		r4
+|.define CRET2,		r5
+|
+|.if FPU
+|.define FARG1,		f0
+|.define FARG2,		f1
+|.define FARG3,		f2
+|.define FARG4,		f3
+|.define FARG5,		f4
+|.define FARG6,		f5
+|.define FARG7,		f6
+|.define FARG8,		f7
+|
+|.define FRET1,		f22
+|.define FRET2,		f23
+|
+|.define FTMP0,		f18
+|.define FTMP1,		f19
+|.define FTMP2,		f20
+|
+|.define FCC0,		fcc0
+|.define FCC1,		fcc1
+|.endif
+|
+|// Stack layout while in interpreter. Must match with lj_frame.h.
+|.if FPU		// LoongArch64 hard-float.
+|
+|.define CFRAME_SPACE,	192	// Delta for sp.
+|
+|//----- 16 byte aligned, <-- sp entering interpreter
+|.define SAVE_ERRF,	188	// 32 bit values.
+|.define SAVE_NRES,	184
+|.define SAVE_CFRAME,	176	// 64 bit values.
+|.define SAVE_L,	168
+|.define SAVE_PC,	160
+|//----- 16 byte aligned
+|.define SAVE_GPR_,	80	// .. 80+10*8: 64 bit GPR saves.
+|.define SAVE_FPR_,	16	// .. 16+8*8: 64 bit FPR saves.
+|
+|.else			// LoongArch64 soft-float
+|
+|.define CFRAME_SPACE,	128	// Delta for sp.
+|
+|//----- 16 byte aligned, <-- sp entering interpreter
+|.define SAVE_ERRF,	124	// 32 bit values.
+|.define SAVE_NRES,	120
+|.define SAVE_CFRAME,	112	// 64 bit values.
+|.define SAVE_L,	104
+|.define SAVE_PC,	96
+|//----- 16 byte aligned
+|.define SAVE_GPR_,	16	// .. 16+10*8: 64 bit GPR saves.
+|
+|.endif
+|
+|.define TMPX,		8	// Unused by interpreter, temp for JIT code.
+|.define TMPD,		0
+|//----- 16 byte aligned
+|
+|.define TMPD_OFS,	0
+|
+|//.define SAVE_MULTRES,	sp, TMPD
+|
+|//-----------------------------------------------------------------------
+|
+|.macro saveregs
+|  addi.d sp, sp, -CFRAME_SPACE
+|  st.d ra, SAVE_GPR_+9*8(sp)
+|  st.d r22, SAVE_GPR_+8*8(sp)
+|   .FPU2 fst.d f31, SAVE_FPR_+7*8(sp)
+|  st.d r30, SAVE_GPR_+7*8(sp)
+|   .FPU2 fst.d f30, SAVE_FPR_+6*8(sp)
+|  st.d r29, SAVE_GPR_+6*8(sp)
+|   .FPU2 fst.d f29, SAVE_FPR_+5*8(sp)
+|  st.d r28, SAVE_GPR_+5*8(sp)
+|   .FPU2 fst.d f28, SAVE_FPR_+4*8(sp)
+|  st.d r27, SAVE_GPR_+4*8(sp)
+|   .FPU2 fst.d f27, SAVE_FPR_+3*8(sp)
+|  st.d r26, SAVE_GPR_+3*8(sp)
+|   .FPU2 fst.d f26, SAVE_FPR_+2*8(sp)
+|  st.d r25, SAVE_GPR_+2*8(sp)
+|   .FPU2 fst.d f25, SAVE_FPR_+1*8(sp)
+|  st.d r24, SAVE_GPR_+1*8(sp)
+|   .FPU2 fst.d f24, SAVE_FPR_+0*8(sp)
+|  st.d r23, SAVE_GPR_+0*8(sp)
+|.endmacro
+|
+|.macro restoreregs_ret
+|  ld.d ra, SAVE_GPR_+9*8(sp)
+|  ld.d r22, SAVE_GPR_+8*8(sp)
+|  ld.d r30, SAVE_GPR_+7*8(sp)
+|   .FPU2 fld.d f31, SAVE_FPR_+7*8(sp)
+|  ld.d r29, SAVE_GPR_+6*8(sp)
+|   .FPU2 fld.d f30, SAVE_FPR_+6*8(sp)
+|  ld.d r28, SAVE_GPR_+5*8(sp)
+|   .FPU2 fld.d f29, SAVE_FPR_+5*8(sp)
+|  ld.d r27, SAVE_GPR_+4*8(sp)
+|   .FPU2 fld.d f28, SAVE_FPR_+4*8(sp)
+|  ld.d r26, SAVE_GPR_+3*8(sp)
+|   .FPU2 fld.d f27, SAVE_FPR_+3*8(sp)
+|  ld.d r25, SAVE_GPR_+2*8(sp)
+|   .FPU2 fld.d f26, SAVE_FPR_+2*8(sp)
+|  ld.d r24, SAVE_GPR_+1*8(sp)
+|   .FPU2 fld.d f25, SAVE_FPR_+1*8(sp)
+|  ld.d r23, SAVE_GPR_+0*8(sp)
+|   .FPU2 fld.d f24, SAVE_FPR_+0*8(sp)
+|  addi.d sp, sp, CFRAME_SPACE
+|  jirl r0, ra, 0
+|.endmacro
+|
+|// Type definitions. Some of these are only used for documentation.
+|.type L,		lua_State,	LREG
+|.type GL,		global_State
+|.type TVALUE,		TValue
+|.type GCOBJ,		GCobj
+|.type STR,		GCstr
+|.type TAB,		GCtab
+|.type LFUNC,		GCfuncL
+|.type CFUNC,		GCfuncC
+|.type PROTO,		GCproto
+|.type UPVAL,		GCupval
+|.type NODE,		Node
+|.type NARGS8,		int
+|.type TRACE,		GCtrace
+|.type SBUF,		SBuf
+|
+|//-----------------------------------------------------------------------
+|
+|// Trap for not-yet-implemented parts.	TODO
+|.macro NYI; .long 0xf0f0f0f0; .endmacro
+|
+|//-----------------------------------------------------------------------
+|
+|// Access to frame relative to BASE.
+|.define FRAME_PC,	-8
+|.define FRAME_FUNC,	-16
+|
+|//-----------------------------------------------------------------------
+|
+|// Endian-specific defines. LoongArch is little endian. TODO
+|.define HI,		4
+|.define LO,		0
+|.define OFS_RD,	2
+|.define OFS_RA,	1
+|.define OFS_OP,	0
+|
+|// Instruction decode.
+|.macro decode_OP1, dst, ins; andi dst, ins, 0xff; .endmacro
+|.macro decode_OP8a, dst, ins; andi dst, ins, 0xff; .endmacro
+|.macro decode_OP8b, dst; slli.w dst, dst, 3; .endmacro
+|.macro decode_RC8a, dst, ins; srli.w dst, ins, 13; .endmacro
+|.macro decode_RC8b, dst; andi dst, dst, 0x7f8; .endmacro
+|.macro decode_RD4b, dst; slli.w dst, dst, 2; .endmacro
+|.macro decode_RA8a, dst, ins; srli.w dst, ins, 5; .endmacro
+|.macro decode_RA8b, dst; andi dst, dst, 0x7f8; .endmacro
+|.macro decode_RB8a, dst, ins; srli.w dst, ins, 21; .endmacro
+|.macro decode_RB8b, dst; andi dst, dst, 0x7f8; .endmacro
+|.macro decode_RD8a, dst, ins; srli.w dst, ins, 16; .endmacro
+|.macro decode_RD8b, dst; slli.w dst, dst, 3; .endmacro
+|.macro decode_RDtoRC8, dst, src; andi dst, src, 0x7f8; .endmacro
+|
+|// Instruction fetch.
+|.macro ins_NEXT1
+|  ld.w INS, 0(PC)
+|   addi.d PC, PC, 4
+|.endmacro
+|// Instruction decode+dispatch.
+|.macro ins_NEXT2
+|  decode_OP8a TMP1, INS
+|  decode_OP8b TMP1
+|  add.d TMP0, DISPATCH, TMP1
+|   decode_RD8a RD, INS
+|  ld.d AT, 0(TMP0)
+|   decode_RA8a RA, INS
+|   decode_RD8b RD
+|  decode_RA8b RA
+|  jirl r0, AT, 0
+|.endmacro
+|.macro ins_NEXT
+|  ins_NEXT1
+|  ins_NEXT2
+|.endmacro
+|
+|// Instruction footer.
+|.if 1
+|  // Replicated dispatch. Less unpredictable branches, but higher I-Cache use.
+|  .define ins_next, ins_NEXT
+|  .define ins_next_, ins_NEXT
+|  .define ins_next1, ins_NEXT1
+|  .define ins_next2, ins_NEXT2
+|.else
+|  // Common dispatch. Lower I-Cache use, only one (very) unpredictable branch.
+|  // Affects only certain kinds of benchmarks (and only with -j off).
+|  .macro ins_next
+|    b ->ins_next
+|  .endmacro
+|  .macro ins_next1
+|  .endmacro
+|  .macro ins_next2
+|    b ->ins_next
+|  .endmacro
+|  .macro ins_next_
+|  ->ins_next:
+|    ins_NEXT
+|  .endmacro
+|.endif
+|
+|// Call decode and dispatch.
+|.macro ins_callt
+|  // BASE = new base, RB = LFUNC/CFUNC, RC = nargs*8, FRAME_PC(BASE) = PC
+|  ld.d PC, LFUNC:RB->pc
+|  ld.w INS, 0(PC)
+|   addi.d PC, PC, 4
+|  decode_OP8a TMP1, INS
+|   decode_RA8a RA, INS
+|  decode_OP8b TMP1
+|   decode_RA8b RA
+|  add.d TMP0, DISPATCH, TMP1
+|  ld.d TMP0, 0(TMP0)
+|  add.d RA, RA, BASE
+|  jirl r0, TMP0, 0
+|.endmacro
+|
+|.macro ins_call
+|  // BASE = new base, RB = LFUNC/CFUNC, RC = nargs*8, PC = caller PC
+|  st.d PC, FRAME_PC(BASE)
+|  ins_callt
+|.endmacro
+|
+|//-----------------------------------------------------------------------
+|
+|.macro branch_RD
+|  srli.w TMP0, RD, 1
+|  .LUI AT, (-(BCBIAS_J*4 >> 16) & 65535)
+|  add.w TMP0, TMP0, AT
+|  add.d PC, PC, TMP0
+|.endmacro
+|
+|// Assumes DISPATCH is relative to GL.
+#define DISPATCH_GL(field)	(GG_DISP2G + (int)offsetof(global_State, field))
+#define DISPATCH_J(field)	(GG_DISP2J + (int)offsetof(jit_State, field))
+|
+#define PC2PROTO(field)  ((int)offsetof(GCproto, field)-(int)sizeof(GCproto))
+|
+|.macro hotcheck, delta, target
+|  srli.d TMP1, PC, 1
+|  andi TMP1, TMP1, 126
+|  add.d TMP1, TMP1, DISPATCH
+|  ld.hu TMP2, GG_DISP2HOT(TMP1)
+|  addi.w TMP2, TMP2, -delta
+|  st.h TMP2, GG_DISP2HOT(TMP1)
+|  blt TMP2, r0, target
+|.endmacro
+|
+|.macro hotloop
+|  hotcheck HOTCOUNT_LOOP, ->vm_hotloop
+|.endmacro
+|
+|.macro hotcall
+|  hotcheck HOTCOUNT_CALL, ->vm_hotcall
+|.endmacro
+|
+|// Set current VM state. Uses TMP0.
+|.macro li_vmstate, st; addi.w TMP0, r0, ~LJ_VMST_..st; .endmacro
+|.macro st_vmstate; .STXW TMP0, DISPATCH, DISPATCH_GL(vmstate); .endmacro
+|
+|// Move table write barrier back. Overwrites mark and tmp.
+|.macro barrierback, tab, mark, tmp, target
+|  .LDXD tmp, DISPATCH, DISPATCH_GL(gc.grayagain)
+|   andi mark, mark, ~LJ_GC_BLACK & 255		// black2gray(tab)
+|  .STXD tab, DISPATCH, DISPATCH_GL(gc.grayagain)
+|   st.b mark, tab->marked
+|  st.d tmp, tab->gclist
+|  beq r0, r0, target
+|.endmacro
+|
+|// Clear type tag. Isolate lowest 47 bits of reg.
+|.macro cleartp, reg; bstrpick.d reg, reg, 46, 0; .endmacro
+|.macro cleartp, dst, reg; bstrpick.d dst, reg, 46, 0; .endmacro
+|
+|// Set type tag: Merge 17 type bits into bits [47, 63] of dst.
+|.macro settp, dst, tp; bstrins.d dst, tp, 63, 47; .endmacro
+|
+|// Extract (negative) type tag.
+|.macro gettp, dst, src; srai.d dst, src, 47; .endmacro
+|
+|// Macros to check the TValue type and extract the GCobj. Branch on failure.
+|.macro checktp, reg, tp, target
+|  gettp AT, reg
+|  addi.d AT, AT, tp
+|  cleartp reg
+|  bnez AT, target
+|.endmacro
+|.macro checktp, dst, reg, tp, target
+|  gettp AT, reg
+|  addi.d AT, AT, tp
+|  cleartp dst, reg
+|  bnez AT, target
+|.endmacro
+|.macro checkstr, reg, target; checktp reg, -LJ_TSTR, target; .endmacro
+|.macro checktab, reg, target; checktp reg, -LJ_TTAB, target; .endmacro
+|.macro checkfunc, reg, target; checktp reg, -LJ_TFUNC, target; .endmacro
+|.macro checkint, reg, target
+|  gettp AT, reg
+|  bne AT, TISNUM, target
+|.endmacro
+|.macro checknum, reg, target
+|  gettp AT, reg
+|  sltui AT, AT, LJ_TISNUM
+|//  or TMP0, r0, LJ_TISNUM
+|//  sltu AT, AT, TMP0
+|  beqz AT, target
+|.endmacro
+|
+|.macro mov_false, reg
+|  addi.d reg, r0, 0x0001
+|  slli.d reg, reg, 47
+|  nor reg, reg, r0
+|.endmacro
+|.macro mov_true, reg
+|  addi.d reg, r0, 0x0001
+|  slli.d reg, reg, 48
+|  nor reg, reg, r0
+|.endmacro
+|
+|//-----------------------------------------------------------------------
+
+/* Generate subroutines used by opcodes and other parts of the VM. */
+/* The .code_sub section should be last to help static branch prediction. */
+static void build_subroutines(BuildCtx *ctx)
+{
+  |.code_sub
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Return handling ----------------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |->vm_returnp:
+  |  // See vm_return. Also: TMP2 = previous base.
+  |  andi AT, PC, FRAME_P
+  |//  beqz AT, ->cont_dispatch
+  |
+  |  // Return from pcall or xpcall fast func.
+  |  mov_true TMP1
+  |  beqz AT, ->cont_dispatch
+  |  ld.d PC, FRAME_PC(TMP2)		// Fetch PC of previous frame.
+  |  or BASE, TMP2, r0			// Restore caller base.
+  |  // Prepending may overwrite the pcall frame, so do it at the end.
+  |   st.d TMP1, -8(RA)			// Prepend true to results.
+  |   addi.d RA, RA, -8
+  |
+  |->vm_returnc:
+  |   addi.w RD, RD, 8			// RD = (nresults+1)*8.
+  |  andi TMP0, PC, FRAME_TYPE
+  |  addi.w CRET1, r0, LUA_YIELD
+  |   beqz RD, ->vm_unwind_c_eh
+  |  or MULTRES, RD, r0
+  |  beqz TMP0, ->BC_RET_Z		// Handle regular return to Lua.
+  |
+  |->vm_return:
+  |  // BASE = base, RA = resultptr, RD/MULTRES = (nresults+1)*8, PC = return
+  |  // TMP0 = PC & FRAME_TYPE
+  |  addi.w TMP2, r0, -8
+  |  xori AT, TMP0, FRAME_C
+  |   and TMP2, PC, TMP2
+  |   sub.d TMP2, BASE, TMP2            // TMP2 = previous base.
+  |  bnez AT, ->vm_returnp
+  |
+  |  addi.w TMP1, RD, -8
+  |   st.d TMP2, L->base
+  |    li_vmstate C
+  |   ld.w TMP2, SAVE_NRES(sp)
+  |   addi.d BASE, BASE, -16
+  |    st_vmstate
+  |   slli.w TMP2, TMP2, 3
+  |  beqz TMP1, >2
+  |1:
+  |  addi.w TMP1, TMP1, -8
+  |   ld.d CRET1, 0(RA)
+  |    addi.d RA, RA, 8
+  |   st.d CRET1, 0(BASE)
+  |  addi.d BASE, BASE, 8
+  |  bnez TMP1, <1
+  |
+  |2:
+  |  bne TMP2, RD, >6
+  |3:
+  |  st.d BASE, L->top			// Store new top.
+  |
+  |->vm_leave_cp:
+  |  ld.d TMP0, SAVE_CFRAME(sp)		// Restore previous C frame.
+  |   or CRET1, r0, r0			// Ok return status for vm_pcall.
+  |  st.d TMP0, L->cframe
+  |
+  |->vm_leave_unw:
+  |  restoreregs_ret
+  |
+  |6:
+  |  ld.d TMP1, L->maxstack
+  |  slt AT, TMP2, RD
+  |  or r17, AT, r0
+  |//  bnez AT, >7			// Less results wanted?
+  |  // More results wanted. Check stack size and fill up results with nil.
+  |  slt AT, BASE, TMP1
+  |  bnez r17, >7
+  |  beqz AT, >8
+  |  st.d TISNIL, 0(BASE)
+  |  addi.w RD, RD, 8
+  |  addi.d BASE, BASE, 8
+  |  beq r0, r0, <2
+  |
+  |7:  // Less results wanted.
+  |  sub.w TMP0, RD, TMP2
+  |  sub.d TMP0, BASE, TMP0		// Either keep top or shrink it.
+  |  maskeqz TMP0, TMP0, TMP2		// LUA_MULTRET+1 case?
+  |  masknez BASE, BASE, TMP2
+  |  or BASE, BASE, TMP0
+  |  b <3
+  |
+  |8:  // Corner case: need to grow stack for filling up results.
+  |  // This can happen if:
+  |  // - A C function grows the stack (a lot).
+  |  // - The GC shrinks the stack in between.
+  |  // - A return back from a lua_call() with (high) nresults adjustment.
+  |
+  |  st.d BASE, L->top                   // Save current top held in BASE (yes).
+  |   or MULTRES, RD, r0
+  |  srli.w CARG2, TMP2, 3
+  |  or CARG1, L, r0
+  |  bl extern lj_state_growstack       // (lua_State *L, int n)
+  |  ld.w TMP2, SAVE_NRES(sp)
+  |  ld.d BASE, L->top			// Need the (realloced) L->top in BASE.
+  |  or RD, MULTRES, r0
+  |  slli.w TMP2, TMP2, 3
+  |  beq r0, r0, <2
+
+  |->vm_unwind_c:			// Unwind C stack, return from vm_pcall.
+  |  // (void *cframe, int errcode)
+  |  or sp, CARG1, r0
+  |  or CRET1, CARG2, r0
+  |->vm_unwind_c_eh:			// Landing pad for external unwinder.
+  |  ld.d L, SAVE_L(sp)
+  |  addi.w TMP0, r0, ~LJ_VMST_C
+  |  ld.d GL:TMP1, L->glref
+  |  st.w TMP0, GL:TMP1->vmstate
+  |  beq r0, r0, ->vm_leave_unw
+  |
+  |->vm_unwind_ff:			// Unwind C stack, return from ff pcall.
+  |  // (void *cframe)
+  |  .LI AT, -4
+  |  and sp, CARG1, AT
+  |->vm_unwind_ff_eh:			// Landing pad for external unwinder.
+  |  ld.d L, SAVE_L(sp)
+  |     .FPU addu16i.d TMP3, r0, 0x59c0		// TOBIT = 2^52 + 2^51 (float).
+  |     .LI TISNIL, LJ_TNIL
+  |    .LI TISNUM, LJ_TISNUM
+  |  ld.d BASE, L->base
+  |   ld.d DISPATCH, L->glref		// Setup pointer to dispatch table.
+  |     .FPU2 movgr2fr.w TOBIT, TMP3
+  |  mov_false TMP1
+  |    li_vmstate INTERP
+  |  ld.d PC, FRAME_PC(BASE)		// Fetch PC of previous frame.
+  |     .FPU2 fcvt.d.s TOBIT, TOBIT
+  |  addi.d RA, BASE, -8		// Results start at BASE-8.
+  |   .DADDIU DISPATCH, DISPATCH, GG_G2DISP
+  |  st.d TMP1, 0(RA)			// Prepend false to error message.
+  |    st_vmstate
+  |  .LI RD, 16				// 2 results: false + error message.
+  |  beq r0, r0, ->vm_returnc
+  |
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Grow stack for calls -----------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |->vm_growstack_c:			// Grow stack for C function.
+  |  .LI CARG2, LUA_MINSTACK
+  |  beq r0, r0, >2
+  |
+  |->vm_growstack_l:			// Grow stack for Lua function.
+  |  // BASE = new base, RA = BASE+framesize*8, RC = nargs*8, PC = first PC
+  |  add.d RC, BASE, RC
+  |   sub.d RA, RA, BASE
+  |  st.d BASE, L->base
+  |   addi.d PC, PC, 4			// Must point after first instruction.
+  |  st.d RC, L->top
+  |   srli.w CARG2, RA, 3
+  |2:
+  |  // L->base = new base, L->top = top
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_state_growstack	// (lua_State *L, int n)
+  |  ld.d BASE, L->base
+  |  ld.d RC, L->top
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |  sub.d RC, RC, BASE
+  |  cleartp LFUNC:RB
+  |  // BASE = new base, RB = LFUNC/CFUNC, RC = nargs*8, FRAME_PC(BASE) = PC
+  |  ins_callt				// Just retry the call.
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Entry points into the assembler VM ---------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |->vm_resume:				// Setup C frame and resume thread.
+  |  // (lua_State *L, TValue *base, int nres1 = 0, ptrdiff_t ef = 0)
+  |  saveregs
+  |  or L, CARG1, r0
+  |    ld.d DISPATCH, L->glref		// Setup pointer to dispatch table.
+  |  or BASE, CARG2, r0
+  |    ld.bu TMP1, L->status
+  |   st.d L, SAVE_L(sp)
+  |  .LI PC, FRAME_CP
+  |  addi.d TMP0, sp, CFRAME_RESUME
+  |    .DADDIU DISPATCH, DISPATCH, GG_G2DISP
+  |   st.w r0, SAVE_NRES(sp)
+  |   st.w r0, SAVE_ERRF(sp)
+  |   st.d CARG1, SAVE_PC(sp)			// Any value outside of bytecode is ok.
+  |   st.d r0, SAVE_CFRAME(sp)
+  |   st.d TMP0, L->cframe
+  |    beqz TMP1, >3
+  |
+  |  // Resume after yield (like a return).
+  |  .STXD L, DISPATCH, DISPATCH_GL(cur_L)
+  |  or RA, BASE, r0
+  |   ld.d BASE, L->base
+  |   ld.d TMP1, L->top
+  |  ld.d PC, FRAME_PC(BASE)
+  |     .FPU  addu16i.d TMP3, r0, 0x59c0		// TOBIT = 2^52 + 2^51 (float).
+  |   sub.d RD, TMP1, BASE
+  |     .FPU2  movgr2fr.w TOBIT, TMP3
+  |    st.b r0, L->status
+  |     .FPU2  fcvt.d.s TOBIT, TOBIT
+  |    li_vmstate INTERP
+  |   addi.d RD, RD, 8
+  |    st_vmstate
+  |   or MULTRES, RD, r0
+  |  andi TMP0, PC, FRAME_TYPE
+  |    .LI TISNIL, LJ_TNIL
+  |    .LI TISNUM, LJ_TISNUM
+  |  beqz TMP0, ->BC_RET_Z
+  |  beq r0, r0, ->vm_return
+  |
+  |->vm_pcall:				// Setup protected C frame and enter VM.
+  |  // (lua_State *L, TValue *base, int nres1, ptrdiff_t ef)
+  |  saveregs
+  |  st.w CARG4, SAVE_ERRF(sp)
+  |  .LI PC, FRAME_CP
+  |  beq r0, r0, >1
+  |
+  |->vm_call:				// Setup C frame and enter VM.
+  |  // (lua_State *L, TValue *base, int nres1)
+  |  saveregs
+  |  .LI PC, FRAME_C
+  |
+  |1:  // Entry point for vm_pcall above (PC = ftype).
+  |  ld.d TMP1, L:CARG1->cframe
+  |    or L, CARG1, r0
+  |   st.w CARG3, SAVE_NRES(sp)
+  |    ld.d DISPATCH, L->glref		// Setup pointer to dispatch table.
+  |   st.d CARG1, SAVE_L(sp)
+  |     or BASE, CARG2, r0
+  |    .DADDIU DISPATCH, DISPATCH, GG_G2DISP
+  |   st.d CARG1, SAVE_PC(sp)			// Any value outside of bytecode is ok.
+  |  st.d TMP1, SAVE_CFRAME(sp)
+  |  st.d sp, L->cframe			// Add our C frame to cframe chain.
+  |
+  |3:  // Entry point for vm_cpcall/vm_resume (BASE = base, PC = ftype).
+  |  .STXD L, DISPATCH, DISPATCH_GL(cur_L)
+  |  ld.d TMP2, L->base			// TMP2 = old base (used in vmeta_call).
+  |     .FPU2 .LUI TMP3, 0x59c0		// TOBIT = 2^52 + 2^51 (float).
+  |   ld.d TMP1, L->top
+  |     .FPU2 movgr2fr.w TOBIT, TMP3
+  |  add.d PC, PC, BASE
+  |   sub.d NARGS8:RC, TMP1, BASE
+  |     .LI TISNUM, LJ_TISNUM
+  |  sub.d PC, PC, TMP2			// PC = frame delta + frame type
+  |     .FPU2 fcvt.d.s TOBIT, TOBIT
+  |    li_vmstate INTERP
+  |     .LI TISNIL, LJ_TNIL
+  |    st_vmstate
+  |
+  |->vm_call_dispatch:
+  |  // TMP2 = old base, BASE = new base, RC = nargs*8, PC = caller PC
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |  checkfunc LFUNC:RB, ->vmeta_call
+  |
+  |->vm_call_dispatch_f:
+  |  ins_call
+  |  // BASE = new base, RB = func, RC = nargs*8, PC = caller PC
+  |
+  |->vm_cpcall:				// Setup protected C frame, call C.
+  |  // (lua_State *L, lua_CFunction func, void *ud, lua_CPFunction cp)
+  |  saveregs
+  |  or L, CARG1, r0
+  |   ld.d TMP0, L:CARG1->stack
+  |  st.d CARG1, SAVE_L(sp)
+  |   ld.d TMP1, L->top
+  |     ld.d DISPATCH, L->glref		// Setup pointer to dispatch table.
+  |  st.d CARG1, SAVE_PC(sp)			// Any value outside of bytecode is ok.
+  |   sub.d TMP0, TMP0, TMP1		// Compute -savestack(L, L->top).
+  |    ld.d TMP1, L->cframe
+  |     .DADDIU DISPATCH, DISPATCH, GG_G2DISP
+  |   st.w TMP0, SAVE_NRES(sp)		// Neg. delta means cframe w/o frame.
+  |  st.w r0, SAVE_ERRF(sp)			// No error function.
+  |    st.d TMP1, SAVE_CFRAME(sp)
+  |    st.d sp, L->cframe			// Add our C frame to cframe chain.
+  |     .STXD L, DISPATCH, DISPATCH_GL(cur_L)
+  |  or CFUNCADDR, CARG4, r0
+  |  jirl r1, CARG4, 0			// (lua_State *L, lua_CFunction func, void *ud)
+  |  or BASE, CRET1, r0
+  |  .LI PC, FRAME_CP
+  |  bnez CRET1, <3			// Else continue with the call.
+  |  beq r0, r0, ->vm_leave_cp			// No base? Just remove C frame.
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Metamethod handling ------------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |// The lj_meta_* functions (except for lj_meta_cat) don't reallocate the
+  |// stack, so BASE doesn't need to be reloaded across these calls.
+  |
+  |//-- Continuation dispatch ----------------------------------------------
+  |
+  |->cont_dispatch:
+  |  // BASE = meta base, RA = resultptr, RD = (nresults+1)*8
+  |  ld.d TMP0, -32(BASE)		// Continuation.
+  |   or RB, BASE, r0
+  |   or BASE, TMP2, r0			// Restore caller BASE.
+  |    ld.d LFUNC:TMP1, FRAME_FUNC(TMP2)
+  |.if FFI
+  |  sltui AT, TMP0, 2
+  |.endif
+  |     ld.d PC, -24(RB)			// Restore PC from [cont|PC].
+  |    cleartp LFUNC:TMP1
+  |   add.d TMP2, RA, RD
+  |    ld.d TMP1, LFUNC:TMP1->pc
+  |  st.d TISNIL, -8(TMP2)               // Ensure one valid arg.
+  |.if FFI
+  |  bnez AT, >1
+  |.endif
+  |  // BASE = base, RA = resultptr, RB = meta base
+  |  ld.d KBASE, PC2PROTO(k)(TMP1)
+  |  jirl r0, TMP0, 0				// Jump to continuation.
+  |
+  |.if FFI
+  |1:
+  |  addi.d TMP1, RB, -32
+  |  bnez TMP0, ->cont_ffi_callback	// cont = 1: return from FFI callback.
+  |  // cont = 0: tailcall from C function.
+  |  sub.d RC, TMP1, BASE
+  |  beq r0, r0, ->vm_call_tail
+  |.endif
+  |
+  |->cont_cat:				// RA = resultptr, RB = meta base
+  |  ld.w INS, -4(PC)
+  |   addi.d CARG2, RB, -32
+  |  ld.d CRET1, 0(RA)
+  |  decode_RB8a MULTRES, INS
+  |   decode_RA8a RA, INS
+  |  decode_RB8b MULTRES
+  |   decode_RA8b RA
+  |  add.d TMP1, BASE, MULTRES
+  |   st.d BASE, L->base
+  |   sub.d CARG3, CARG2, TMP1
+  |  st.d CRET1, 0(CARG2)
+  |  bne TMP1, CARG2, ->BC_CAT_Z
+  |  add.d RA, BASE, RA
+  |  st.d CRET1, 0(RA)
+  |  beq r0, r0, ->cont_nop
+  |
+  |//-- Table indexing metamethods -----------------------------------------
+  |
+  |->vmeta_tgets1:
+  |  .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv)
+  |  .LI TMP0, LJ_TSTR
+  |  settp STR:RC, TMP0
+  |  st.d STR:RC, 0(CARG3)
+  |  beq r0, r0, >1
+  |
+  |->vmeta_tgets:
+  |  .DADDIU CARG2, DISPATCH, DISPATCH_GL(tmptv)
+  |  .LI TMP0, LJ_TTAB
+  |  .LI TMP1, LJ_TSTR
+  |  settp TAB:RB, TMP0
+  |   .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv2)
+  |  st.d TAB:RB, 0(CARG2)
+  |   settp STR:RC, TMP1
+  |  st.d STR:RC, 0(CARG3)
+  |  beq r0, r0, >1
+  |
+  |->vmeta_tgetb:			// TMP0 = index
+  |  .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv)
+  |  settp TMP0, TISNUM
+  |  st.d TMP0, 0(CARG3)
+  |
+  |->vmeta_tgetv:
+  |1:
+  |  st.d BASE, L->base
+  |  st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_tget		// (lua_State *L, TValue *o, TValue *k)
+  |  // Returns TValue * (finished) or NULL (metamethod).
+  |  addi.d TMP1, BASE, -FRAME_CONT
+  |  beqz CRET1, >3
+  |  ld.d CARG1, 0(CRET1)
+  |  ins_next1
+  |  st.d CARG1, 0(RA)
+  |  ins_next2
+  |
+  |3:  // Call __index metamethod.
+  |  // BASE = base, L->top = new base, stack = cont/func/t/k
+  |  ld.d BASE, L->top
+  |  st.d PC, -24(BASE)			// [cont|PC]
+  |   sub.d PC, BASE, TMP1
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)	// Guaranteed to be a function here.
+  |  cleartp LFUNC:RB
+  |  .LI NARGS8:RC, 16                  // 2 args for func(t, k).
+  |  beq r0, r0, ->vm_call_dispatch_f
+  |
+  |->vmeta_tgetr:
+  |  bl extern lj_tab_getinth		// (GCtab *t, int32_t key)
+  |  // Returns cTValue * or NULL.
+  |  or CARG2, TISNIL, r0
+  |  beqz CRET1, ->BC_TGETR_Z
+  |  ld.d CARG2, 0(CRET1)
+  |  beq r0, r0, ->BC_TGETR_Z
+  |
+  |//-----------------------------------------------------------------------
+  |
+  |->vmeta_tsets1:
+  |  .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv)
+  |  .LI TMP0, LJ_TSTR
+  |  settp STR:RC, TMP0
+  |  st.d STR:RC, 0(CARG3)
+  |  beq r0, r0, >1
+  |
+  |->vmeta_tsets:
+  |  .DADDIU CARG2, DISPATCH, DISPATCH_GL(tmptv)
+  |  .LI TMP0, LJ_TTAB
+  |   .LI TMP1, LJ_TSTR
+  |  settp TAB:RB, TMP0
+  |   .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv2)
+  |  st.d TAB:RB, 0(CARG2)
+  |   settp STR:RC, TMP1
+  |  st.d STR:RC, 0(CARG3)
+  |  beq r0, r0,  >1
+  |
+  |->vmeta_tsetb:			// TMP0 = index
+  |  .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv)
+  |  settp TMP0, TISNUM
+  |  st.d TMP0, 0(CARG3)
+  |
+  |->vmeta_tsetv:
+  |1:
+  |  st.d BASE, L->base
+  |  st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_tset		// (lua_State *L, TValue *o, TValue *k)
+  |  // Returns TValue * (finished) or NULL (metamethod).
+  |  ld.d r17, 0(RA)
+  |  beqz CRET1, >3
+  |  // NOBARRIER: lj_meta_tset ensures the table is not black.
+  |  ins_next1
+  |  st.d r17, 0(CRET1)
+  |  ins_next2
+  |
+  |3:  // Call __newindex metamethod.
+  |  // BASE = base, L->top = new base, stack = cont/func/t/k/(v)
+  |  addi.d TMP1, BASE, -FRAME_CONT
+  |  ld.d BASE, L->top
+  |  st.d PC, -24(BASE)		// [cont|PC]
+  |   sub.d PC, BASE, TMP1
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)	// Guaranteed to be a function here.
+  |  cleartp LFUNC:RB
+  |  st.d r17, 16(BASE)			// Copy value to third argument.
+  |  .LI NARGS8:RC, 24                  // 3 args for func(t, k, v)
+  |  beq r0, r0, ->vm_call_dispatch_f
+  |
+  |->vmeta_tsetr:
+  |  st.d BASE, L->base
+  |  st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_tab_setinth	// (lua_State *L, GCtab *t, int32_t key)
+  |  // Returns TValue *.
+  |  beq r0, r0, ->BC_TSETR_Z
+  |
+  |//-- Comparison metamethods ---------------------------------------------
+  |
+  |->vmeta_comp:
+  |  // RA/RD point to o1/o2.
+  |  or CARG2, RA, r0
+  |  or CARG3, RD, r0
+  |  addi.d PC, PC, -4
+  |  st.d BASE, L->base
+  |  st.d PC, SAVE_PC(sp)
+  |  decode_OP1 CARG4, INS
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_comp	// (lua_State *L, TValue *o1, *o2, int op)
+  |  // Returns 0/1 or TValue * (metamethod).
+  |3:
+  |  sltui AT, CRET1, 2
+  |  beqz AT, ->vmeta_binop
+  |   sub.w TMP2, r0, CRET1
+  |4:
+  |  ld.hu RD, OFS_RD(PC)
+  |   addi.d PC, PC, 4
+  |   .LUI TMP1, (-(BCBIAS_J*4 >> 16) & 65535)
+  |  slli.w RD, RD, 2
+  |  add.w RD, RD, TMP1
+  |  and RD, RD, TMP2
+  |  add.d PC, PC, RD
+  |->cont_nop:
+  |  ins_next
+  |
+  |->cont_ra:				// RA = resultptr
+  |  ld.bu TMP1, -4+OFS_RA(PC)
+  |   ld.d CRET1, 0(RA)
+  |  slli.w TMP1, TMP1, 3
+  |  add.d TMP1, BASE, TMP1
+  |   st.d CRET1, 0(TMP1)
+  |  beq r0, r0, ->cont_nop
+  |
+  |->cont_condt:			// RA = resultptr
+  |  ld.d TMP0, 0(RA)
+  |  gettp TMP0, TMP0
+  |  sltui AT, TMP0, LJ_TISTRUECOND
+  |  sub.w TMP2, r0, AT                     // Branch if result is true.
+  |  beq r0, r0, <4
+  |
+  |->cont_condf:			// RA = resultptr
+  |  ld.d TMP0, 0(RA)
+  |  gettp TMP0, TMP0
+  |  sltui AT, TMP0, LJ_TISTRUECOND
+  |  addi.w TMP2, AT, -1                // Branch if result is false.
+  |  beq r0, r0, <4
+  |
+  |->vmeta_equal:
+  |  // CARG1/CARG2 point to o1/o2. TMP0 is set to 0/1.
+  |   cleartp LFUNC:CARG3, CARG2
+  |  cleartp LFUNC:CARG2, CARG1
+  |    or CARG4, TMP0, r0
+  |  addi.d PC, PC, -4
+  |   st.d BASE, L->base
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_equal	// (lua_State *L, GCobj *o1, *o2, int ne)
+  |  // Returns 0/1 or TValue * (metamethod).
+  |  beq r0, r0, <3
+  |
+  |->vmeta_equal_cd:
+  |.if FFI
+  |  or CARG2, INS, r0
+  |  addi.d PC, PC, -4
+  |   st.d BASE, L->base
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_equal_cd	// (lua_State *L, BCIns op)
+  |  // Returns 0/1 or TValue * (metamethod).
+  |  beq r0, r0, <3
+  |.endif
+  |
+  |->vmeta_istype:
+  |  addi.d PC, PC, -4
+  |   st.d BASE, L->base
+  |   srli.w CARG2, RA, 3
+  |   srli.w CARG3, RD, 3
+  |  st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_istype	// (lua_State *L, BCReg ra, BCReg tp)
+  |  beq r0, r0, ->cont_nop
+  |
+  |//-- Arithmetic metamethods ---------------------------------------------
+  |
+  |->vmeta_unm:
+  |  or RC, RB, r0
+  |
+  |->vmeta_arith:
+  |   st.d BASE, L->base
+  |  or CARG2, RA, r0
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG3, RB, r0
+  |  or CARG4, RC, r0
+  |  decode_OP1 CARG5, INS	// CARG5 == RB.
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_arith	// (lua_State *L, TValue *ra,*rb,*rc, BCReg op)
+  |  // Returns NULL (finished) or TValue * (metamethod).
+  |  beqz CRET1, ->cont_nop
+  |
+  |  // Call metamethod for binary op.
+  |->vmeta_binop:
+  |  // BASE = old base, CRET1 = new base, stack = cont/func/o1/o2
+  |  sub.d TMP1, CRET1, BASE
+  |   st.d PC, -24(CRET1)			// [cont|PC]
+  |   or TMP2, BASE, r0
+  |  addi.d PC, TMP1, FRAME_CONT
+  |   or BASE, CRET1, r0
+  |  .LI NARGS8:RC, 16                  // 2 args for func(o1, o2).
+  |  beq r0, r0, ->vm_call_dispatch
+  |
+  |->vmeta_len:
+  |  // CARG2 already set by BC_LEN.
+#if LJ_52
+  |  or MULTRES, CARG1, r0
+#endif
+  |   st.d BASE, L->base
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_len		// (lua_State *L, TValue *o)
+  |  // Returns NULL (retry) or TValue * (metamethod base).
+#if LJ_52
+  |  bnez CRET1, ->vmeta_binop		// Binop call for compatibility.
+  |  or CARG1, MULTRES, r0
+  |  beq r0, r0, ->BC_LEN_Z
+#else
+  |  beq r0, r0, ->vmeta_binop			// Binop call for compatibility.
+#endif
+  |
+  |//-- Call metamethod ----------------------------------------------------
+  |
+  |->vmeta_call:			// Resolve and call __call metamethod.
+  |  // TMP2 = old base, BASE = new base, RC = nargs*8
+  |   st.d TMP2, L->base			// This is the callers base!
+  |  addi.d CARG2, BASE, -16
+  |   st.d PC, SAVE_PC(sp)
+  |  add.d CARG3, BASE, RC
+  |   or MULTRES, NARGS8:RC, r0
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_call	// (lua_State *L, TValue *func, TValue *top)
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)	// Guaranteed to be a function here.
+  |   addi.d NARGS8:RC, MULTRES, 8	// Got one more argument now.
+  |  cleartp LFUNC:RB
+  |  ins_call
+  |
+  |->vmeta_callt:			// Resolve __call for BC_CALLT.
+  |  // BASE = old base, RA = new base, RC = nargs*8
+  |   st.d BASE, L->base
+  |  addi.d CARG2, RA, -16
+  |   st.d PC, SAVE_PC(sp)
+  |  add.d CARG3, RA, RC
+  |   or MULTRES, NARGS8:RC, r0
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_call		// (lua_State *L, TValue *func, TValue *top)
+  |   ld.d RB, FRAME_FUNC(RA)		// Guaranteed to be a function here.
+  |  ld.d TMP1, FRAME_PC(BASE)
+  |  addi.d NARGS8:RC, MULTRES, 8	// Got one more argument now.
+  |  cleartp LFUNC:CARG3, RB
+  |  beq r0, r0, ->BC_CALLT_Z
+  |
+  |//-- Argument coercion for 'for' statement ------------------------------
+  |
+  |->vmeta_for:
+  |   st.d BASE, L->base
+  |  or CARG2, RA, r0
+  |   st.d PC, SAVE_PC(sp)
+  |  or MULTRES, INS, r0
+  |  or CARG1, L, r0
+  |  bl extern lj_meta_for	// (lua_State *L, TValue *base)
+  |.if JIT
+  |  decode_OP1 TMP0, MULTRES
+  |  .LI AT, BC_JFORI
+  |.endif
+  |  decode_RA8a RA, MULTRES
+  |   decode_RD8a RD, MULTRES
+  |  decode_RA8b RA
+  |.if JIT
+  |  decode_RD8b RD
+  |  beq TMP0, AT, =>BC_JFORI
+  |  beq r0, r0, =>BC_FORI
+  |.else
+  |  decode_RD8b RD
+  |  beq r0, r0, =>BC_FORI
+  |.endif
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Fast functions -----------------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |.macro .ffunc, name
+  |->ff_ .. name:
+  |.endmacro
+  |
+  |.macro .ffunc_1, name
+  |->ff_ .. name:
+  |  ld.d CARG1, 0(BASE)
+  |  beqz NARGS8:RC, ->fff_fallback
+  |.endmacro
+  |
+  |.macro .ffunc_2, name
+  |->ff_ .. name:
+  |  sltui AT, NARGS8:RC, 16
+  |  ld.d CARG1, 0(BASE)
+  |  ld.d CARG2, 8(BASE)
+  |  bnez AT, ->fff_fallback
+  |.endmacro
+  |
+  |.macro .ffunc_n, name
+  |->ff_ .. name:
+  |  ld.d CARG1, 0(BASE)
+  |  .FPU2 fld.d FARG1, 0(BASE)
+  |  beqz NARGS8:RC, ->fff_fallback
+#if name == math_sqrt
+  |  fsqrt.d FRET1, FARG1
+#endif
+  |  checknum CARG1, ->fff_fallback
+  |.endmacro
+  |
+  |.macro .ffunc_nn, name	// Caveat: has delay slot!
+  |->ff_ .. name:
+  |  ld.d CARG1, 0(BASE)
+  |    sltui AT, NARGS8:RC, 16
+  |   ld.d CARG2, 8(BASE)
+  |  gettp TMP0, CARG1
+  |  bnez AT, ->fff_fallback
+  |   gettp TMP1, CARG2
+  |  sltui TMP0, TMP0, LJ_TISNUM
+  |   sltui TMP1, TMP1, LJ_TISNUM
+  |  .FPU2 fld.d FARG1, 0(BASE)
+  |  and TMP0, TMP0, TMP1
+  |   .FPU2 fld.d FARG2, 8(BASE)
+  |  beqz TMP0, ->fff_fallback
+  |.endmacro
+  |
+  |// Inlined GC threshold check.
+  |.macro ffgccheck
+  |  .LDXD TMP0, DISPATCH, DISPATCH_GL(gc.total)
+  |  .LDXD TMP1, DISPATCH, DISPATCH_GL(gc.threshold)
+  |  blt TMP0, TMP1, >1
+  |  bl ->fff_gcstep
+  |1:
+  |.endmacro
+  |
+  |//-- Base library: checks -----------------------------------------------
+  |.ffunc_1 assert
+  |  gettp AT, CARG1
+  |  sltui AT, AT, LJ_TISTRUECOND
+  |  addi.d RA, BASE, -16
+  |  beqz AT, ->fff_fallback
+  |  ld.d PC, FRAME_PC(BASE)
+  |  addi.w RD, NARGS8:RC, 8		// Compute (nresults+1)*8.
+  |  add.d TMP2, RA, RD
+  |  addi.d TMP1, BASE, 8
+  |  st.d CARG1, 0(RA)
+  |  beq BASE, TMP2, ->fff_res		// Done if exactly 1 argument.
+  |1:
+  |  ld.d r17, 0(TMP1)
+  |  st.d r17, -16(TMP1)
+  |  or r18, TMP1, r0
+  |  addi.d TMP1, TMP1, 8
+  |  bne r18, TMP2, <1
+  |  beq r0, r0, ->fff_res
+  |
+  |.ffunc_1 type
+  |  gettp TMP0, CARG1
+  |  sltu TMP1, TISNUM, TMP0
+  |  nor TMP2, TMP0, r0
+  |  .LI TMP3, ~LJ_TISNUM
+  |  maskeqz TMP2, TMP2, TMP1
+  |  masknez TMP3, TMP3, TMP1
+  |  or TMP2, TMP2, TMP3
+  |  slli.d TMP2, TMP2, 3
+  |  add.d TMP2, CFUNC:RB, TMP2
+  |  ld.d CARG1, CFUNC:TMP2->upvalue
+  |  beq r0, r0, ->fff_restv
+  |
+  |//-- Base library: getters and setters ---------------------------------
+  |
+  |.ffunc_1 getmetatable
+  |  gettp TMP2, CARG1
+  |  addi.d TMP0, TMP2, -LJ_TTAB
+  |  addi.d TMP1, TMP2, -LJ_TUDATA
+  |  maskeqz TMP0, TMP1, TMP0
+  |  cleartp TAB:CARG1
+  |  bnez TMP0, >6
+  |1:  // Field metatable must be at same offset for GCtab and GCudata!
+  |  ld.d TAB:RB, TAB:CARG1->metatable
+  |2:
+  |  .LDXD STR:RC, DISPATCH, DISPATCH_GL(gcroot[GCROOT_MMNAME+MM_metatable])
+  |  .LI CARG1, LJ_TNIL
+  |  beqz TAB:RB, ->fff_restv
+  |  ld.w TMP0, TAB:RB->hmask
+  |   ld.w TMP1, STR:RC->hash
+  |    ld.d NODE:TMP2, TAB:RB->node
+  |  and TMP1, TMP1, TMP0		// idx = str->hash & tab->hmask
+  |  slli.d TMP0, TMP1, 5
+  |  slli.d TMP1, TMP1, 3
+  |  sub.d TMP1, TMP0, TMP1
+  |  add.d NODE:TMP2, NODE:TMP2, TMP1	// node = tab->node + (idx*32-idx*8)
+  |  .LI CARG4, LJ_TSTR
+  |  settp STR:RC, CARG4		// Tagged key to look for.
+  |3:  // Rearranged logic, because we expect _not_ to find the key.
+  |  ld.d TMP0, NODE:TMP2->key
+  |   ld.d CARG1, NODE:TMP2->val
+  |    ld.d NODE:TMP2, NODE:TMP2->next
+  |  .LI AT, LJ_TTAB
+  |  beq RC, TMP0, >5
+  |  bnez NODE:TMP2, <3
+  |4:
+  |  or CARG1, RB, r0
+  |  settp CARG1, AT
+  |  beq r0, r0, ->fff_restv			// Not found, keep default result.
+  |5:
+  |  bne CARG1, TISNIL, ->fff_restv
+  |  beq r0, r0, <4				// Ditto for nil value.
+  |
+  |6:
+  |  sltui AT, TMP2, LJ_TISNUM
+  |  maskeqz TMP0, TISNUM, AT
+  |  masknez AT, TMP2, AT
+  |  or TMP2, TMP0, AT
+  |  slli.d TMP2, TMP2, 3
+  |   sub.d TMP0, DISPATCH, TMP2
+  |  .LDXD TAB:RB, TMP0, DISPATCH_GL(gcroot[GCROOT_BASEMT])-8
+  |  beq r0, r0, <2
+  |
+  |.ffunc_2 setmetatable
+  |  // Fast path: no mt for table yet and not clearing the mt.
+  |  checktp TMP1, CARG1, -LJ_TTAB, ->fff_fallback
+  |  gettp TMP3, CARG2
+  |   ld.d TAB:TMP0, TAB:TMP1->metatable
+  |   ld.bu TMP2, TAB:TMP1->marked
+  |  addi.d AT, TMP3, -LJ_TTAB
+  |   cleartp TAB:CARG2
+  |  or AT, AT, TAB:TMP0
+  |  or r18, AT, r0
+  |  andi AT, TMP2, LJ_GC_BLACK        // isblack(table)
+  |  bnez r18, ->fff_fallback
+  |  st.d TAB:CARG2, TAB:TMP1->metatable
+  |  beqz AT, ->fff_restv
+  |  barrierback TAB:TMP1, TMP2, TMP0, ->fff_restv
+  |
+  |.ffunc rawget
+  |  ld.d CARG2, 0(BASE)
+  |  sltui AT, NARGS8:RC, 16
+  |  gettp TMP0, CARG2
+  |   cleartp CARG2
+  |  addi.d TMP0, TMP0, -LJ_TTAB
+  |  or AT, AT, TMP0
+  |  addi.d CARG3, BASE, 8
+  |  bnez AT, ->fff_fallback
+  |  or CARG1, L, r0
+  |  bl extern lj_tab_get	// (lua_State *L, GCtab *t, cTValue *key)
+  |  ld.d CARG1, 0(CRET1)
+  |  beq r0, r0, ->fff_restv
+  |
+  |//-- Base library: conversions ------------------------------------------
+  |
+  |.ffunc tonumber
+  |  // Only handles the number case inline (without a base argument).
+  |  ld.d CARG1, 0(BASE)
+  |  xori AT, NARGS8:RC, 8		// Exactly one number argument.
+  |  gettp TMP1, CARG1
+  |  sltu TMP0, TISNUM, TMP1
+  |  or AT, AT, TMP0
+  |  bnez AT, ->fff_fallback
+  |  beq r0, r0, ->fff_restv
+  |
+  |.ffunc_1 tostring
+  |  // Only handles the string or number case inline.
+  |  gettp TMP0, CARG1
+  |  addi.d AT, TMP0, -LJ_TSTR
+  |  .LDXD TMP1, DISPATCH, DISPATCH_GL(gcroot[GCROOT_BASEMT_NUM])
+  |  // A __tostring method in the string base metatable is ignored.
+  |  beqz AT, ->fff_restv	// String key?
+  |  // Handle numbers inline, unless a number base metatable is present.
+  |  sltu TMP0, TISNUM, TMP0
+  |  or TMP0, TMP0, TMP1
+  |  st.d BASE, L->base                  // Add frame since C call can throw.
+  |  bnez TMP0, ->fff_fallback
+  |  st.d PC, SAVE_PC(sp)                     // Redundant (but a defined value).
+  |  ffgccheck
+  |  or CARG1, L, r0
+  |  or CARG2, BASE, r0
+  |  bl extern lj_strfmt_number	// (lua_State *L, cTValue *o)
+  |  // Returns GCstr *.
+  |  .LI AT, LJ_TSTR
+  |  settp CRET1, AT
+  |  or CARG1, CRET1, r0
+  |  beq r0, r0, ->fff_restv
+  |
+  |//-- Base library: iterators -------------------------------------------
+  |
+  |.ffunc_1 next
+  |  checktp CARG2, CARG1, -LJ_TTAB, ->fff_fallback
+  |  add.d TMP2, BASE, NARGS8:RC
+  |  st.d TISNIL, 0(TMP2)			// Set missing 2nd arg to nil.
+  |  ld.d PC, FRAME_PC(BASE)
+  |   st.d BASE, L->base			// Add frame since C call can throw.
+  |   st.d BASE, L->top			// Dummy frame length is ok.
+  |  addi.d CARG3, BASE, 8
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_tab_next		// (lua_State *L, GCtab *t, TValue *key)
+  |  // Returns 0 at end of traversal.
+  |  or r17, CRET1, r0
+  |  or CARG1, TISNIL, r0
+  |  beqz r17, ->fff_restv		// End of traversal: return nil.
+  |  ld.d TMP0, 8(BASE)
+  |    addi.d RA, BASE, -16
+  |  ld.d TMP2, 16(BASE)
+  |  st.d TMP0, 0(RA)
+  |  st.d TMP2, 8(RA)
+  |  .LI RD, (2+1)*8
+  |  beq r0, r0, ->fff_res
+  |
+  |.ffunc_1 pairs
+  |  checktp TAB:TMP1, CARG1, -LJ_TTAB, ->fff_fallback
+  |  ld.d PC, FRAME_PC(BASE)
+#if LJ_52
+  |  ld.d TAB:TMP2, TAB:TMP1->metatable
+  |  ld.d TMP0, CFUNC:RB->upvalue[0]
+  |  addi.d RA, BASE, -16
+  |  bnez TAB:TMP2, ->fff_fallback
+#else
+  |  ld.d TMP0, CFUNC:RB->upvalue[0]
+  |  addi.d RA, BASE, -16
+#endif
+  |  st.d TISNIL, 0(BASE)
+  |   st.d CARG1, -8(BASE)
+  |    st.d TMP0, 0(RA)
+  |  .LI RD, (3+1)*8
+  |  beq r0, r0, ->fff_res
+  |
+  |.ffunc_2 ipairs_aux
+  |  checktab CARG1, ->fff_fallback
+  |  ld.w TMP0, TAB:CARG1->asize
+  |   checkint CARG2, ->fff_fallback
+  |   ld.d TMP1, TAB:CARG1->array
+  |    ld.d PC, FRAME_PC(BASE)
+  |  slli.w TMP2, CARG2, 0		// sextw -> slli.w
+  |  addi.w TMP2, TMP2, 1
+  |  sltu AT, TMP2, TMP0
+  |    addi.d RA, BASE, -16
+  |   bstrpick.d TMP0, TMP2, 31, 0		// zextw -> bstrpick.d
+  |   settp TMP0, TISNUM
+  |  st.d TMP0, 0(RA)
+  |  beqz AT, >2			// Not in array part?
+  |  slli.d TMP3, TMP2, 3
+  |  add.d TMP3, TMP1, TMP3
+  |  ld.d TMP1, 0(TMP3)
+  |1:
+  |  .LI RD, (0+1)*8
+  |  beq TMP1, TISNIL, ->fff_res	// End of iteration, return 0 results.
+  |  st.d TMP1, -8(BASE)
+  |  .LI RD, (2+1)*8
+  |  beq r0, r0, ->fff_res
+  |2:  // Check for empty hash part first. Otherwise call C function.
+  |  ld.w TMP0, TAB:CARG1->hmask
+  |  .LI RD, (0+1)*8
+  |  beqz TMP0, ->fff_res
+  |  or CARG2, TMP2, r0
+  |  bl extern lj_tab_getinth		// (GCtab *t, int32_t key)
+  |  // Returns cTValue * or NULL.
+  |  .LI RD, (0+1)*8
+  |  beqz CRET1, ->fff_res
+  |  ld.d TMP1, 0(CRET1)
+  |  beq r0, r0, <1
+  |
+  |.ffunc_1 ipairs
+  |  checktp TAB:TMP1, CARG1, -LJ_TTAB, ->fff_fallback
+  |  ld.d PC, FRAME_PC(BASE)
+#if LJ_52
+  |  ld.d TAB:TMP2, TAB:TMP1->metatable
+  |  ld.d CFUNC:TMP0, CFUNC:RB->upvalue[0]
+  |  addi.d RA, BASE, -16
+  |  bnez TAB:TMP2, ->fff_fallback
+#else
+  |  ld.d TMP0, CFUNC:RB->upvalue[0]
+  |  addi.d RA, BASE, -16
+#endif
+  |  slli.d AT, TISNUM, 47
+  |  st.d CARG1, -8(BASE)
+  |   st.d AT, 0(BASE)
+  |    st.d CFUNC:TMP0, 0(RA)
+  |  .LI RD, (3+1)*8
+  |  beq r0, r0, ->fff_res
+  |
+  |//-- Base library: catch errors ----------------------------------------
+  |
+  |.ffunc pcall
+  |  addi.d NARGS8:RC, NARGS8:RC, -8
+  |  .LDXBU TMP3, DISPATCH, DISPATCH_GL(hookmask)
+  |   or TMP2, BASE, r0
+  |  blt NARGS8:RC, r0, ->fff_fallback
+  |   addi.d BASE, BASE, 16
+  |  // Remember active hook before pcall.
+  |  srli.w TMP3, TMP3, HOOK_ACTIVE_SHIFT
+  |  andi TMP3, TMP3, 1
+  |  addi.d PC, TMP3, 16+FRAME_PCALL
+  |  beqz NARGS8:RC, ->vm_call_dispatch
+  |1:
+  |  add.d TMP0, BASE, NARGS8:RC
+  |//  beqz NARGS8:RC, ->vm_call_dispatch
+  |2:
+  |  ld.d TMP1, -16(TMP0)
+  |  st.d TMP1, -8(TMP0)
+  |  addi.d TMP0, TMP0, -8
+  |  bne TMP0, BASE, <2
+  |  beq r0, r0, ->vm_call_dispatch
+  |
+  |.ffunc xpcall
+  |  addi.d NARGS8:TMP0, NARGS8:RC, -16
+  |  ld.d CARG1, 0(BASE)
+  |   ld.d CARG2, 8(BASE)
+  |    .LDXBU TMP1, DISPATCH, DISPATCH_GL(hookmask)
+  |    blt NARGS8:TMP0, r0, ->fff_fallback
+  |  gettp AT, CARG2
+  |  addi.d AT, AT, -LJ_TFUNC
+  |   or TMP2, BASE, r0
+  |  bnez AT, ->fff_fallback		// Traceback must be a function.
+  |  or NARGS8:RC, NARGS8:TMP0, r0
+  |   addi.d BASE, BASE, 24
+  |  // Remember active hook before pcall.
+  |  srli.w TMP3, TMP3, HOOK_ACTIVE_SHIFT
+  |   st.d CARG2, 0(TMP2)			// Swap function and traceback.
+  |  andi TMP3, TMP3, 1
+  |   st.d CARG1, 8(TMP2)
+  |  addi.d PC, TMP3, 24+FRAME_PCALL
+  |  beqz NARGS8:RC, ->vm_call_dispatch
+  |  beq r0, r0, <1
+  |
+  |//-- Coroutine library --------------------------------------------------
+  |
+  |.macro coroutine_resume_wrap, resume
+  |.if resume
+  |.ffunc_1 coroutine_resume
+  |  checktp CARG1, CARG1, -LJ_TTHREAD, ->fff_fallback
+  |.else
+  |.ffunc coroutine_wrap_aux
+  |  ld.d L:CARG1, CFUNC:RB->upvalue[0].gcr
+  |  cleartp L:CARG1
+  |.endif
+  |  ld.bu TMP0, L:CARG1->status
+  |   ld.d TMP1, L:CARG1->cframe
+  |    ld.d CARG2, L:CARG1->top
+  |    ld.d TMP2, L:CARG1->base
+  |  addi.w AT, TMP0, -LUA_YIELD
+  |    add.d CARG3, CARG2, TMP0
+  |   addi.d TMP3, CARG2, 8
+  |  masknez CARG2, CARG2, AT
+  |  maskeqz TMP3, TMP3, AT
+  |  or CARG2, TMP3, CARG2
+  |  blt r0, AT, ->fff_fallback		// st > LUA_YIELD?
+  |   xor TMP2, TMP2, CARG3
+  |  or AT, TMP2, TMP0
+  |  bnez TMP1, ->fff_fallback		// cframe != 0?
+  |  ld.d TMP0, L:CARG1->maxstack
+  |  ld.d PC, FRAME_PC(BASE)
+  |  beqz AT, ->fff_fallback		// base == top && st == 0?
+  |  add.d TMP2, CARG2, NARGS8:RC
+  |  sltu AT, TMP0, TMP2
+  |  st.d PC, SAVE_PC(sp)
+  |  bnez AT, ->fff_fallback		// Stack overflow?
+  |   st.d BASE, L->base
+  |1:
+  |.if resume
+  |  addi.d BASE, BASE, 8		// Keep resumed thread in stack for GC.
+  |  addi.d NARGS8:RC, NARGS8:RC, -8
+  |  addi.d TMP2, TMP2, -8
+  |.endif
+  |  st.d TMP2, L:CARG1->top
+  |  add.d TMP1, BASE, NARGS8:RC
+  |  or CARG3, CARG2, r0
+  |  st.d BASE, L->top
+  |2:  // Move args to coroutine.
+  |   ld.d r17, 0(BASE)
+  |  sltu AT, BASE, TMP1
+  |  addi.d BASE, BASE, 8
+  |  beqz AT, >3
+  |   st.d r17, 0(CARG3)
+  |  addi.d CARG3, CARG3, 8
+  |  beq r0, r0, <2
+  |3:
+  |  or L:RA, L:CARG1, r0
+  |  bl ->vm_resume			// (lua_State *L, TValue *base, 0, 0)
+  |  // Returns thread status.
+  |4:
+  |  ld.d TMP2, L:RA->base
+  |   sltui AT, CRET1, LUA_YIELD+1
+  |  ld.d TMP3, L:RA->top
+  |    li_vmstate INTERP
+  |  ld.d BASE, L->base
+  |    .STXD L, DISPATCH, DISPATCH_GL(cur_L)
+  |    st_vmstate
+  |  sub.d RD, TMP3, TMP2
+  |   beqz AT, >8
+  |   ld.d TMP0, L->maxstack
+  |  add.d TMP1, BASE, RD
+  |  beqz RD, >6			// No results?
+  |  sltu AT, TMP0, TMP1
+  |  add.d TMP3, TMP2, RD
+  |  bnez AT, >9			// Need to grow stack?
+  |  st.d TMP2, L:RA->top			// Clear coroutine stack.
+  |  or TMP1, BASE, r0
+  |5:  // Move results from coroutine.
+  |   ld.d r17, 0(TMP2)
+  |  addi.d TMP2, TMP2, 8
+  |  sltu AT, TMP2, TMP3
+  |   st.d r17, 0(TMP1)
+  |  addi.d TMP1, TMP1, 8
+  |  bnez AT, <5
+  |6:
+  |  andi TMP0, PC, FRAME_TYPE
+  |.if resume
+  |  mov_true TMP1
+  |   addi.d RA, BASE, -8
+  |  st.d TMP1, -8(BASE)	// Prepend true to results.
+  |  addi.d RD, RD, 16
+  |.else
+  |  or RA, BASE, r0
+  |  addi.d RD, RD, 8
+  |.endif
+  |7:
+  |  st.d PC, SAVE_PC(sp)
+  |  or MULTRES, RD, r0
+  |  beqz TMP0, ->BC_RET_Z
+  |  beq r0, r0, ->vm_return
+  |
+  |8:  // Coroutine returned with error (at co->top-1).
+  |.if resume
+  |  addi.d TMP3, TMP3, -8
+  |   mov_false TMP1
+  |  ld.d r17, 0(TMP3)
+  |   st.d TMP3, L:RA->top		// Remove error from coroutine stack.
+  |    .LI RD, (2+1)*8
+  |   st.d TMP1, -8(BASE)			// Prepend false to results.
+  |    addi.d RA, BASE, -8
+  |  st.d r17, 0(BASE)			// Copy error message.
+  |  andi TMP0, PC, FRAME_TYPE
+  |  beq r0, r0, <7
+  |.else
+  |  or CARG2, L:RA, r0
+  |  or CARG1, L, r0
+  |  bl extern lj_ffh_coroutine_wrap_err  // (lua_State *L, lua_State *co)
+  |.endif
+  |
+  |9:  // Handle stack expansion on return from yield.
+  |  srli.w CARG2, RD, 3
+  |  or CARG1, L, r0
+  |  bl extern lj_state_growstack	// (lua_State *L, int n)
+  |  .LI CRET1, 0
+  |  beq r0, r0, <4
+  |.endmacro
+  |
+  |  coroutine_resume_wrap 1		// coroutine.resume
+  |  coroutine_resume_wrap 0		// coroutine.wrap
+  |
+  |.ffunc coroutine_yield
+  |  ld.d TMP0, L->cframe
+  |   add.d TMP1, BASE, NARGS8:RC
+  |   st.d BASE, L->base
+  |  andi TMP0, TMP0, CFRAME_RESUME
+  |   st.d TMP1, L->top
+  |   .LI CRET1, LUA_YIELD
+  |  beqz TMP0, ->fff_fallback
+  |  st.d r0, L->cframe
+  |   st.b CRET1, L->status
+  |  beq r0, r0, ->vm_leave_unw
+  |
+  |//-- Math library -------------------------------------------------------
+  |
+  |.ffunc_1 math_abs
+  |  gettp CARG2, CARG1
+  |  addi.d AT, CARG2, -LJ_TISNUM
+  |  slli.w TMP1, CARG1, 0		// sextw -> slli.w
+  |  bnez AT, >1
+  |  srai.w TMP0, TMP1, 31			// Extract sign.
+  |  xor TMP1, TMP1, TMP0
+  |  sub.d CARG1, TMP1, TMP0
+  |  slli.d TMP3, CARG1, 32
+  |  settp CARG1, TISNUM
+  |  bge TMP3, r0, ->fff_restv
+  |  .LI CARG1, 0x41e0			// 2^31 as a double.
+  |  slli.d CARG1, CARG1, 48
+  |  beq r0, r0, ->fff_restv
+  |1:
+  |  sltui AT, CARG2, LJ_TISNUM
+  |  bstrpick.d CARG1, CARG1, 62, 0
+  |  beqz AT, ->fff_fallback
+  |// fallthrough
+  |
+  |->fff_restv:
+  |  // CARG1 = TValue result.
+  |  ld.d PC, FRAME_PC(BASE)
+  |  addi.d RA, BASE, -16
+  |   st.d CARG1, -16(BASE)
+  |->fff_res1:
+  |  // RA = results, PC = return.
+  |  .LI RD, (1+1)*8
+  |->fff_res:
+  |  // RA = results, RD = (nresults+1)*8, PC = return.
+  |  andi TMP0, PC, FRAME_TYPE
+  |  or MULTRES, RD, r0
+  |  bnez TMP0, ->vm_return
+  |  ld.w INS, -4(PC)
+  |  decode_RB8a RB, INS
+  |  decode_RB8b RB
+  |5:
+  |  sltu AT, RD, RB
+  |  decode_RA8a TMP0, INS
+  |  bnez AT, >6			// More results expected?
+  |  decode_RA8b TMP0
+  |  ins_next1
+  |  // Adjust BASE. KBASE is assumed to be set for the calling frame.
+  |   sub.d BASE, RA, TMP0
+  |  ins_next2
+  |
+  |6:  // Fill up results with nil.
+  |  add.d TMP1, RA, RD
+  |   addi.d RD, RD, 8
+  |  st.d TISNIL, -8(TMP1)
+  |  beq r0, r0, <5
+  |
+  |.macro math_extern, func
+  |  .ffunc_n math_ .. func
+  |  bl extern func
+  |  fmov.d FRET1, FARG1
+  |  beq r0, r0, ->fff_resn
+  |.endmacro
+  |
+  |.macro math_extern2, func
+  |  .ffunc_nn math_ .. func
+  |  bl extern func
+  |  fmov.d FRET1, FARG1
+  |  beq r0, r0, ->fff_resn
+  |.endmacro
+  |
+  |// TODO: Return integer type if result is integer (own sf implementation).
+  |.macro math_round, func
+  |->ff_math_ .. func:
+  |  ld.d CARG1, 0(BASE)
+  |  gettp TMP0, CARG1
+  |  beqz NARGS8:RC, ->fff_fallback
+  |  sltu AT, TMP0, TISNUM
+  |  beq TMP0, TISNUM, ->fff_restv
+  |//  beqz AT, ->fff_fallback
+  |.if FPU
+  |  fld.d FARG1, 0(BASE)
+  |  beqz AT, ->fff_fallback
+  |  bl ->vm_ .. func
+  |.else
+  |  beqz AT, ->fff_fallback
+  |   bl extern func
+  |.endif
+  |  beq r0, r0, ->fff_resn
+  |.endmacro
+  |
+  |  math_round floor
+  |  math_round ceil
+  |
+  |.ffunc math_log
+  |  .LI AT, 8
+  |  ld.d CARG1, 0(BASE)
+  |  bne NARGS8:RC, AT, ->fff_fallback	// Exactly 1 argument.
+  |  checknum CARG1, ->fff_fallback
+  |.if FPU
+  |  fld.d FARG1, 0(BASE)
+  |  bl extern log
+  |.else
+  |  bl extern log
+  |.endif
+  |  fmov.d FRET1, FARG1
+  |  beq r0, r0, ->fff_resn
+  |
+  |  math_extern log10
+  |  math_extern exp
+  |  math_extern sin
+  |  math_extern cos
+  |  math_extern tan
+  |  math_extern asin
+  |  math_extern acos
+  |  math_extern atan
+  |  math_extern sinh
+  |  math_extern cosh
+  |  math_extern tanh
+  |  math_extern2 pow
+  |  math_extern2 atan2
+  |  math_extern2 fmod
+  |
+  |.if FPU
+  |//  fsqrt.d FRET1, FARG1
+  |.ffunc_n math_sqrt
+  |//  fsqrt.d FRET1, FARG1
+  |// fallthrough to ->fff_resn
+  |.else
+  |  math_extern sqrt
+  |.endif
+  |
+  |->fff_resn:
+  |  ld.d PC, FRAME_PC(BASE)
+  |  addi.d RA, BASE, -16
+  |.if FPU
+  |  fst.d FRET1, 0(RA)
+  |  beq r0, r0, ->fff_res1
+  |.else
+  |  st.d CRET1, 0(RA)
+  |  beq r0, r0, ->fff_res1
+  |.endif
+  |
+  |
+  |.ffunc_2 math_ldexp
+  |  checknum CARG1, ->fff_fallback
+  |  checkint CARG2, ->fff_fallback
+  |  .FPU2 fld.d FARG1, 0(BASE)
+  |  ld.w CARG1, 8+LO(BASE)
+  |  bl extern ldexp
+  |  fmov.d FRET1, FARG1
+  |  beq r0, r0, ->fff_resn
+  |
+  |.ffunc_n math_frexp
+  |   ld.d PC, FRAME_PC(BASE)
+  |  .DADDIU CARG1, DISPATCH, DISPATCH_GL(tmptv)
+  |  bl extern frexp
+  |   .LDXW TMP1, DISPATCH, DISPATCH_GL(tmptv)
+  |  addi.d RA, BASE, -16
+  |.if FPU
+  |   movgr2fr.w FARG2, TMP1
+  |  fst.d FRET1, 0(RA)
+  |   ffint.d.w FARG2, FARG2
+  |   fst.d FARG2, 8(RA)
+  |.else
+  |  st.d CRET1, 0(RA)
+  |  bstrpick.d TMP1, TMP1, 31, 0		// zextw -> bstrpick.d
+  |  settp TMP1, TISNUM
+  |  st.d TMP1, 8(RA)
+  |.endif
+  |  .LI RD, (2+1)*8
+  |  beq r0, r0, ->fff_res
+  |
+  |.ffunc_n math_modf
+  |   ld.d PC, FRAME_PC(BASE)
+  |  addi.d CARG1, BASE, -16
+  |  bl extern modf
+  |  addi.d RA, BASE, -16
+  |.if FPU
+  |  fst.d FRET1, -8(BASE)
+  |.else
+  |  st.d CRET1, -8(BASE)
+  |.endif
+  |  .LI RD, (2+1)*8
+  |  beq r0, r0, ->fff_res
+  |
+  |.macro math_minmax, name, intins, intinsc, fpins
+  |  .ffunc_1 name
+  |  add.d TMP3, BASE, NARGS8:RC
+  |  addi.d TMP2, BASE, 8
+  |  checkint CARG1, >5
+  |1:  // Handle integers.
+  |  ld.d CARG2, 0(TMP2)
+  |  beq TMP2, TMP3, ->fff_restv
+  |  slli.w CARG1, CARG1, 0	// sextw -> slli.w
+  |  checkint CARG2, >3
+  |  ld.w CARG2, LO(TMP2)
+  |  slt AT, CARG1, CARG2
+  |  intins TMP1, CARG2, AT
+  |  intinsc CARG1, CARG1, AT
+  |  or CARG1, CARG1, TMP1
+  |  addi.d TMP2, TMP2, 8
+  |  bstrpick.d CARG1, CARG1, 31, 0		// zextw -> bstrpick.d
+  |  settp CARG1, TISNUM
+  |  beq r0, r0, <1
+  |
+  |3:  // Convert intermediate result to number and continue with number loop.
+  |//  checknum CARG2, ->fff_fallback
+  |.if FPU
+  |  movgr2fr.w FRET1, CARG1	//TODO checknum slot ins
+  |  checknum CARG2, ->fff_fallback
+  |  ffint.d.w FRET1, FRET1
+  |  fld.d FARG1, 0(TMP2)
+  |  beq r0, r0, >7
+  |.else
+  |  checknum CARG2, ->fff_fallback
+  |  bl ->vm_sfi2d_1
+  |  beq r0, r0, >7
+  |.endif
+  |
+  |5:
+  |  .FPU2 fld.d FRET1, 0(BASE)
+  |//  checknum CARG1, ->fff_fallback
+  |6:  // Handle numbers.
+  |  ld.d CARG2, 0(TMP2)	//TODO  mips slot ins
+  |  checknum CARG1, ->fff_fallback
+  |//  beq TMP2, TMP3, ->fff_resn
+  |.if FPU
+  |  fld.d FARG1, 0(TMP2)
+  |.else
+  |  or CRET1, CARG1, r0
+  |.endif
+  |  beq TMP2, TMP3, ->fff_resn
+  |  checknum CARG2, >8
+  |7:
+  |.if FPU
+  |  fpins FRET1, FRET1, FARG1
+  |.else
+  |.if fpins  // ismax
+  |  bl ->vm_sfcmpogt
+  |.else
+  |  bl ->vm_sfcmpolt
+  |.endif
+  |  masknez AT, CARG2, CRET1
+  |  maskeqz CARG1, CARG1, CRET1
+  |  or CARG1, CARG1, AT
+  |.endif
+  |  addi.d TMP2, TMP2, 8
+  |  beq r0, r0, <6
+  |
+  |8:  // Convert integer to number and continue with number loop.
+  |//  checkint CARG2, ->fff_fallback	//TODO doesnot process the mips slot ins
+  |.if FPU
+  |  fld.s FARG1, LO(TMP2)
+  |  checkint CARG2, ->fff_fallback
+  |  ffint.d.w FARG1, FARG1
+  |  beq r0, r0, <7
+  |.else
+  |  ld.w CARG2, LO(TMP2)
+  |  checkint CARG2, ->fff_fallback
+  |  bl ->vm_sfi2d_2
+  |  beq r0, r0, <7
+  |.endif
+  |
+  |.endmacro
+  |
+  |  math_minmax math_min, masknez, maskeqz, fmin.d
+  |  math_minmax math_max, maskeqz, masknez, fmax.d
+  |
+  |//-- String library -----------------------------------------------------
+  |
+  |.ffunc string_byte			// Only handle the 1-arg case here.
+  |  ld.d CARG1, 0(BASE)
+  |  gettp TMP0, CARG1
+  |  xori AT, NARGS8:RC, 8
+  |  addi.d TMP0, TMP0, -LJ_TSTR
+  |  or AT, AT, TMP0
+  |  cleartp STR:CARG1
+  |  bnez AT, ->fff_fallback		// Need exactly 1 string argument.
+  |  ld.w TMP0, STR:CARG1->len
+  |    addi.d RA, BASE, -16
+  |    ld.d PC, FRAME_PC(BASE)
+  |  sltu RD, r0, TMP0
+  |   ld.bu TMP1, STR:CARG1[1]		// Access is always ok (NUL at end).
+  |  addi.w RD, RD, 1
+  |  slli.w RD, RD, 3			// RD = ((str->len != 0)+1)*8
+  |  settp TMP1, TISNUM
+  |  st.d TMP1, 0(RA)
+  |  beq r0, r0, ->fff_res
+  |
+  |.ffunc string_char			// Only handle the 1-arg case here.
+  |  ffgccheck
+  |  ld.d CARG1, 0(BASE)
+  |  gettp TMP0, CARG1
+  |  xori AT, NARGS8:RC, 8		// Exactly 1 argument.
+  |  addi.d TMP0, TMP0, -LJ_TISNUM	// Integer.
+  |  .LI TMP1, 255
+  |   slli.w CARG1, CARG1, 0		// sextw -> slli.w
+  |  or AT, AT, TMP0
+  |   sltu TMP1, TMP1, CARG1		// !(255 < n).
+  |   or AT, AT, TMP1
+  |  .LI CARG3, 1
+  |  bnez AT, ->fff_fallback
+  |  addi.d CARG2, sp, TMPD_OFS
+  |  st.b CARG1, TMPD(sp)
+  |->fff_newstr:
+  |   st.d BASE, L->base
+  |   st.d PC, SAVE_PC(sp)
+  |  or CARG1, L, r0
+  |  bl extern lj_str_new		// (lua_State *L, char *str, size_t l)
+  |  // Returns GCstr *.
+  |  ld.d BASE, L->base
+  |->fff_resstr:
+  |  .LI AT, LJ_TSTR
+  |  settp CRET1, AT
+  |  or CARG1, CRET1, r0
+  |  beq r0, r0, ->fff_restv
+  |
+  |.ffunc string_sub
+  |  ffgccheck
+  |  addi.d AT, NARGS8:RC, -16
+  |  ld.d TMP0, 0(BASE)
+  |  gettp TMP3, TMP0
+  |  blt AT, r0, ->fff_fallback
+  |  cleartp STR:CARG1, TMP0
+  |  ld.d CARG2, 8(BASE)
+  |  .LI CARG4, -1
+  |  beqz AT, >1
+  |  ld.d CARG3, 16(BASE)
+  |//  checkint CARG3, ->fff_fallback
+  |  slli.w CARG4, CARG3, 0		//TODO it`s also a mips slot ins, sextw -> slli.w
+  |  checkint CARG3, ->fff_fallback
+  |1:
+  |  checkint CARG2, ->fff_fallback
+  |  .LI AT, LJ_TSTR			//TODO mips slot ins
+  |//  checkint CARG2, ->fff_fallback
+  |  slli.w CARG3, CARG2, 0		// sextw -> slli.w
+  |  bne TMP3, AT, ->fff_fallback
+  |  ld.w CARG2, STR:CARG1->len
+  |  // STR:CARG1 = str, CARG2 = str->len, CARG3 = start, CARG4 = end
+  |  slt AT, CARG4, r0
+  |  addi.w TMP0, CARG2, 1
+  |  add.w TMP1, CARG4, TMP0
+  |   slt TMP3, CARG3, r0
+  |  masknez CARG4, CARG4, AT
+  |  maskeqz TMP1, TMP1, AT
+  |  or CARG4, TMP1, CARG4		// if (end < 0) end += len+1
+  |   add.w TMP1, CARG3, TMP0
+  |   maskeqz TMP1, TMP1, TMP3
+  |   masknez CARG3, CARG3, TMP3
+  |   or CARG3, TMP1, CARG3		// if (start < 0) start += len+1
+  |   .LI TMP2, 1
+  |  slt AT, CARG4, r0
+  |   slt TMP3, r0, CARG3
+  |  masknez CARG4, CARG4, AT		// if (end < 0) end = 0
+  |  maskeqz CARG3, CARG3, TMP3
+  |   masknez TMP2, TMP2, TMP3
+  |   or CARG3, TMP2, CARG3		// if (start < 1) start = 1
+  |  slt AT, CARG2, CARG4
+  |  masknez CARG4, CARG4, AT
+  |  maskeqz CARG2, CARG2, AT
+  |  or CARG4, CARG2, CARG4		// if (end > len) end = len
+  |   add.d CARG2, STR:CARG1, CARG3
+  |  sub.d CARG3, CARG4, CARG3		// len = end - start
+  |   addi.d CARG2, CARG2, sizeof(GCstr)-1
+  |  or r17, CARG3, r0
+  |  addi.w CARG3, CARG3, 1             // len++
+  |  bge r17, r0, ->fff_newstr
+  |->fff_emptystr:  // Return empty string.
+  |  .LI AT, LJ_TSTR
+  |  .DADDIU STR:CARG1, DISPATCH, DISPATCH_GL(strempty)
+  |  settp CARG1, AT
+  |  beq r0, r0, ->fff_restv
+  |
+  |.macro ffstring_op, name
+  |  .ffunc string_ .. name
+  |  ffgccheck
+  |  ld.d CARG2, 0(BASE)
+  |  beqz NARGS8:RC, ->fff_fallback
+  |  checkstr STR:CARG2, ->fff_fallback
+  |  .DADDIU SBUF:CARG1, DISPATCH, DISPATCH_GL(tmpbuf)
+  |  ld.d TMP0, SBUF:CARG1->b
+  |   st.d L, SBUF:CARG1->L
+  |   st.d BASE, L->base
+  |  st.d TMP0, SBUF:CARG1->p
+  |  st.d PC, SAVE_PC(sp)
+  |  bl extern lj_buf_putstr_ .. name
+  |  or SBUF:CARG1, SBUF:CRET1, r0
+  |  bl extern lj_buf_tostr
+  |  ld.d BASE, L->base
+  |  beq r0, r0, ->fff_resstr
+  |.endmacro
+  |
+  |ffstring_op reverse
+  |ffstring_op lower
+  |ffstring_op upper
+  |
+  |//-- Bit library --------------------------------------------------------
+  |
+  |->vm_tobit_fb:
+  |//  beqz TMP1, ->fff_fallback		//TODO doesnot process the following mips slot ins
+  |.if FPU
+  |  fld.d FARG1, 0(BASE)
+  |  beqz TMP1, ->fff_fallback
+  |  fadd.d FARG1, FARG1, TOBIT
+  |  movfr2gr.s CRET1, FARG1
+  |  bstrpick.d CRET1, CRET1, 31, 0                // zextw -> bstrpick.d
+  |  jirl r0, ra, 0
+  |.else
+  |  beqz TMP1, ->fff_fallback
+  |// FP number to bit conversion for soft-float.
+  |->vm_tobit:
+  |  slli.d TMP0, CARG1, 1
+  |  .LI CARG3, 1076
+  |  srli.d AT, TMP0, 53
+  |  sub.d CARG3, CARG3, AT
+  |  sltui AT, CARG3, 54
+  |  bstrpick.d TMP0, TMP0, 52, 0
+  |  beqz AT, >1
+  |  bstrins.d TMP0, AT, 21, 21
+  |  slt AT, CARG1, r0
+  |  srl.d CRET1, TMP0, CARG3
+  |  sub.d TMP0, r0, CRET1
+  |  maskeqz TMP0, TMP0, AT
+  |  masknez CRET1, CRET1, AT
+  |  or CRET1, CRET1, TMP0
+  |  bstrpick.d CRET1, CRET1, 31, 0	// zextw -> bstrpick.d
+  |  jirl r0, ra, 0
+  |1:
+  |  or CRET1, r0, r0
+  |  jirl, r0, ra, 0
+  |
+  |// FP number to int conversion with a check for soft-float.
+  |// Modifies CARG1, CRET1, CRET2, TMP0, AT.
+  |->vm_tointg:
+  |.if JIT
+  |  slli.d CRET2, CARG1, 1
+  |  .LI TMP0, 1076
+  |  beqz CRET2, >2
+  |  srli.d AT, CRET2, 53
+  |  sub.d TMP0, TMP0, AT
+  |  sltui AT, TMP0, 54
+  |  bstrpick.d CRET2, CRET2, 52, 0
+  |  beqz AT, >1
+  |  bstrins.d CRET2, AT, 21, 21
+  |  slt AT, CARG1, r0
+  |  srl.d CRET1, CRET2, TMP0
+  |  sub.d CARG1, r0, CRET1
+  |  masknez CRET1, CRET1, AT
+  |  maskeqz CARG1, CARG1, AT
+  |  or CRET1, CRET1, CARG1
+  |  .LI CARG1, 64
+  |  sub.w TMP0, CARG1, TMP0
+  |  sll.d CRET2, CRET2, TMP0	// Integer check.
+  |  slli.w AT, CRET1, 0	// sextw -> slli.w
+  |  xor AT, CRET1, AT		// Range check.
+  |  masknez AT, AT, CRET2
+  |  maskeqz CRET2, CRET2, CRET2
+  |  or CRET2, AT, CRET2
+  |  jirl r0, ra, 0
+  |1:
+  |  .LI CRET2, 1
+  |  jirl r0, ra, 0
+  |2:
+  |  or CRET1, r0, r0
+  |  jirl r0, ra, 0
+  |.endif
+  |.endif
+  |
+  |.macro .ffunc_bit, name
+  |  .ffunc_1 bit_..name
+  |  gettp TMP0, CARG1
+  |  bstrpick.d CRET1, CARG1, 31, 0	// zextw -> bstrpick.d
+  |  beq TMP0, TISNUM, >6
+  |  sltui TMP1, TMP0, LJ_TISNUM
+  |  bl ->vm_tobit_fb
+  |6:
+  |.endmacro
+  |
+  |.macro .ffunc_bit_op, name, bins
+  |  .ffunc_bit name
+  |  addi.d TMP2, BASE, 8
+  |  add.d TMP3, BASE, NARGS8:RC
+  |1:
+  |  ld.d r17, 0(TMP2)
+  |  beq TMP2, TMP3, ->fff_resi
+  |  gettp TMP0, r17
+  |.if FPU
+  |  addi.d TMP2, TMP2, 8
+  |  bne TMP0, TISNUM, >2
+  |  bstrpick.d r17, r17, 31, 0		// zextw -> bstrpick.d
+  |  bins CRET1, CRET1, r17
+  |  beq r0, r0, <1
+  |2:
+  |   fld.d FARG1, -8(TMP2)
+  |  sltui AT, TMP0, LJ_TISNUM
+  |  fadd.d FARG1, FARG1, TOBIT
+  |  beqz AT, ->fff_fallback
+  |  movfr2gr.s r17, FARG1
+  |  bstrpick.d r17, r17, 31, 0		// zextw -> bstrpick.d
+  |  bins CRET1, CRET1, r17
+  |  beq r0, r0, <1
+  |.else
+  |  or CRET2, CRET1, r0
+  |  beq TMP0, TISNUM, >2
+  |  sltui TMP1, TMP0, LJ_TISNUM
+  |  bl ->vm_tobit_fb
+  |  or CARG1, CRET2, r0
+  |2:
+  |  bstrpick.d r17, r17, 31, 0		// zextw -> bstrpick.d
+  |  bins CRET1, CRET1, r17
+  |  addi.d TMP2, TMP2, 8
+  |  beq r0, r0, <1
+  |.endif
+  |.endmacro
+  |
+  |.ffunc_bit_op band, and
+  |.ffunc_bit_op bor, or
+  |.ffunc_bit_op bxor, xor
+  |
+  |.ffunc_bit bswap
+  |  srli.d TMP0, CRET1, 8
+  |   srli.d TMP1, CRET1, 24
+  |//  andi TMP2, TMP0, 0xff00
+  |  srli.d TMP3,TMP0, 8
+  |  andi TMP2, TMP3, 0xff
+  |  slli.d TMP2, TMP2, 8
+  |   bstrins.d TMP1, CRET1, 31, 24
+  |  bstrins.d TMP2, TMP0, 23, 16
+  |  or CRET1, TMP1, TMP2
+  |  beq r0, r0, ->fff_resi
+  |
+  |.ffunc_bit bnot
+  |  nor CRET1, CRET1, r0
+  |  bstrpick.d CRET1, CRET1, 31, 0	// zextw -> bstrpick.d
+  |  beq r0, r0, ->fff_resi
+  |
+  |.macro .ffunc_bit_sh, name, shins, shmod
+  |  .ffunc_2 bit_..name
+  |  gettp TMP0, CARG1
+  |  beq TMP0, TISNUM, >1
+  |  sltui TMP1, TMP0, LJ_TISNUM
+  |  bl ->vm_tobit_fb
+  |  or CARG1, CRET1, r0
+  |1:
+  |  gettp TMP0, CARG2
+  |  bstrpick.d CARG2, CARG2, 31, 0	// zextw -> bstrpick.d
+  |  bne TMP0, TISNUM, ->fff_fallback
+  |  slli.w CARG1, CARG1, 0		// sextw -> slli.w
+  |.if shmod == 1
+  |  sub.w CARG2, r0, CARG2
+  |.endif
+  |  shins CRET1, CARG1, CARG2
+  |  bstrpick.d CRET1, CRET1, 31, 0	// zextw -> bstrpick.d
+  |  beq r0, r0, ->fff_resi
+  |.endmacro
+  |
+  |.ffunc_bit_sh lshift, sll.w, 0
+  |.ffunc_bit_sh rshift, srl.w, 0
+  |.ffunc_bit_sh arshift, sra.w, 0
+  |.ffunc_bit_sh rol, rotr.w, 1
+  |.ffunc_bit_sh ror, rotr.w, 0
+  |
+  |.ffunc_bit tobit
+  |->fff_resi:
+  |  ld.d PC, FRAME_PC(BASE)
+  |  addi.d RA, BASE, -16
+  |  settp CRET1, TISNUM
+  |  st.d CRET1, -16(BASE)
+  |  beq r0, r0, ->fff_res1
+  |
+  |//-----------------------------------------------------------------------
+  |->fff_fallback:			// Call fast function fallback handler.
+  |  // BASE = new base, RB = CFUNC, RC = nargs*8
+  |  ld.d TMP3, CFUNC:RB->f
+  |    add.d TMP1, BASE, NARGS8:RC
+  |   ld.d PC, FRAME_PC(BASE)		// Fallback may overwrite PC.
+  |    addi.d TMP0, TMP1, 8*LUA_MINSTACK
+  |     ld.d TMP2, L->maxstack
+  |   st.d PC, SAVE_PC(sp)			// Redundant (but a defined value).
+  |  sltu AT, TMP2, TMP0
+  |     st.d BASE, L->base
+  |    st.d TMP1, L->top
+  |  or CFUNCADDR, TMP3, r0
+  |  bnez AT, >5			// Need to grow stack.
+  |  or CARG1, L, r0
+  |  jirl r1, TMP3, 0				// (lua_State *L)
+  |  // Either throws an error, or recovers and returns -1, 0 or nresults+1.
+  |  ld.d BASE, L->base
+  |   slli.w RD, CRET1, 3
+  |  addi.d RA, BASE, -16
+  |  blt r0, CRET1, ->fff_res		// Returned nresults+1?
+  |1:  // Returned 0 or -1: retry fast path.
+  |   ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |  ld.d TMP0, L->top
+  |   cleartp LFUNC:RB
+  |  sub.d NARGS8:RC, TMP0, BASE
+  |  bnez CRET1, ->vm_call_tail		// Returned -1?
+  |  ins_callt				// Returned 0: retry fast path.
+  |
+  |// Reconstruct previous base for vmeta_call during tailcall.
+  |->vm_call_tail:
+  |  andi TMP0, PC, FRAME_TYPE
+  |   .LI AT, -4
+  |  and TMP1, PC, AT
+  |  bnez TMP0, >3
+  |  ld.bu TMP1, OFS_RA(PC)
+  |  slli.w TMP1, TMP1, 3
+  |  addi.w TMP1, TMP1, 16
+  |3:
+  |  sub.d TMP2, BASE, TMP1
+  |  beq r0, r0, ->vm_call_dispatch		// Resolve again for tailcall.
+  |
+  |5:  // Grow stack for fallback handler.
+  |  .LI CARG2, LUA_MINSTACK
+  |  or CARG1, L, r0
+  |  bl extern lj_state_growstack	// (lua_State *L, int n)
+  |  ld.d BASE, L->base
+  |  .LI CRET1, 0                       // Force retry.
+  |  beq r0, r0, <1
+  |
+  |->fff_gcstep:			// Call GC step function.
+  |  // BASE = new base, RC = nargs*8
+  |  or MULTRES, ra, r0
+  |   st.d BASE, L->base
+  |  add.d TMP0, BASE, NARGS8:RC
+  |   st.d PC, SAVE_PC(sp)			// Redundant (but a defined value).
+  |  st.d TMP0, L->top
+  |  or CARG1, L, r0
+  |  bl extern lj_gc_step		// (lua_State *L)
+  |   ld.d BASE, L->base
+  |  or ra, MULTRES, r0
+  |    ld.d TMP0, L->top
+  |  ld.d CFUNC:RB, FRAME_FUNC(BASE)
+  |  cleartp CFUNC:RB
+  |  sub.d NARGS8:RC, TMP0, BASE
+  |  jirl r0, ra, 0
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Special dispatch targets -------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |->vm_record:				// Dispatch target for recording phase.
+  |.if JIT
+  |  .LDXBU TMP3, DISPATCH, DISPATCH_GL(hookmask)
+  |  andi AT, TMP3, HOOK_VMEVENT	// No recording while in vmevent.
+  |  .LDXW TMP2, DISPATCH, DISPATCH_GL(hookcount)
+  |  bnez AT, >5
+  |  // Decrement the hookcount for consistency, but always do the call.
+  |  andi AT, TMP3, HOOK_ACTIVE
+  |  addi.w TMP2, TMP2, -1
+  |  bnez AT, >1
+  |  andi AT, TMP3, LUA_MASKLINE|LUA_MASKCOUNT
+  |  beqz AT, >1
+  |  .STXW TMP2, DISPATCH, DISPATCH_GL(hookcount)
+  |  beq r0, r0, >1
+  |.endif
+  |
+  |->vm_rethook:			// Dispatch target for return hooks.
+  |  .LDXBU TMP3, DISPATCH, DISPATCH_GL(hookmask)
+  |  andi AT, TMP3, HOOK_ACTIVE		// Hook already active?
+  |//  beqz AT, >1			//TODO dose not process the following mips slot ins
+  |5:  // Re-dispatch to static ins.
+  |  ld.d AT, GG_DISP2STATIC(TMP0)	// Assumes TMP0 holds DISPATCH+OP*4.
+  |  beqz AT, >1
+  |  jirl r0, AT, 0
+  |
+  |->vm_inshook:			// Dispatch target for instr/line hooks.
+  |  .LDXBU TMP3, DISPATCH, DISPATCH_GL(hookmask)
+  |  .LDXW TMP2, DISPATCH, DISPATCH_GL(hookcount)
+  |  andi AT, TMP3, HOOK_ACTIVE		// Hook already active?
+  |  or r17, AT, r0
+  |  andi AT, TMP3, LUA_MASKLINE|LUA_MASKCOUNT
+  |  bnez r17, <5
+  |  addi.w TMP2, TMP2, -1
+  |  beqz AT, <5
+  |  .STXW TMP2, DISPATCH, DISPATCH_GL(hookcount)
+  |  beqz TMP2, >1
+  |  andi AT, TMP3, LUA_MASKLINE
+  |  beqz AT, <5			//TODO dose not process the following mips slot ins
+  |1:
+  |//.  load_got lj_dispatch_ins
+  |// st.w MULTRES, SAVE_MULTRES
+  |   st.w MULTRES, TMPD(sp)
+  |  or CARG2, PC, r0
+  |   st.d BASE, L->base
+  |  // SAVE_PC must hold the _previous_ PC. The callee updates it with PC.
+  |  or CARG1, L, r0
+  |  bl extern lj_dispatch_ins	// (lua_State *L, const BCIns *pc)
+  |3:
+  |  ld.d BASE, L->base
+  |4:  // Re-dispatch to static ins.
+  |  ld.w INS, -4(PC)
+  |  decode_OP8a TMP1, INS
+  |  decode_OP8b TMP1
+  |  add.d TMP0, DISPATCH, TMP1
+  |   decode_RD8a RD, INS
+  |  ld.d AT, GG_DISP2STATIC(TMP0)
+  |   decode_RA8a RA, INS
+  |   decode_RD8b RD
+  |   decode_RA8b RA
+  |  jirl r0, AT, 0
+  |
+  |->cont_hook:				// Continue from hook yield.
+  |  addi.d PC, PC, 4
+  |  ld.w MULTRES, -24+LO(RB)            // Restore MULTRES for *M ins.
+  |  beq r0, r0, <4
+  |
+  |->vm_hotloop:			// Hot loop counter underflow.
+  |.if JIT
+  |  ld.d LFUNC:TMP1, FRAME_FUNC(BASE)
+  |   .DADDIU CARG1, DISPATCH, GG_DISP2J
+  |  cleartp LFUNC:TMP1
+  |   st.d PC, SAVE_PC(sp)
+  |  ld.d TMP1, LFUNC:TMP1->pc
+  |   or CARG2, PC, r0
+  |   .STXD L, DISPATCH, DISPATCH_J(L)
+  |  ld.bu TMP1, PC2PROTO(framesize)(TMP1)
+  |   st.d BASE, L->base
+  |  slli.d TMP1, TMP1, 3
+  |  add.d TMP1, BASE, TMP1
+  |  st.d TMP1, L->top
+  |  bl extern lj_trace_hot		// (jit_State *J, const BCIns *pc)
+  |  beq r0, r0, <3
+  |.endif
+  |
+  |
+  |->vm_callhook:			// Dispatch target for call hooks.
+  |  or CARG2, PC, r0
+  |.if JIT
+  |  beq r0, r0, >1				//TODO which is the mips slot ins
+  |.endif
+  |//  or CARG2, PC, r0
+  |
+  |->vm_hotcall:			// Hot call counter underflow.
+  |.if JIT
+  |  ori CARG2, PC, 1
+  |1:
+  |.endif
+  |  add.d TMP0, BASE, RC
+  |   st.d PC, SAVE_PC(sp)
+  |   st.d BASE, L->base
+  |  sub.d RA, RA, BASE
+  |   st.d TMP0, L->top
+  |  or CARG1, L, r0
+  |  bl extern lj_dispatch_call	// (lua_State *L, const BCIns *pc)
+  |  // Returns ASMFunction.
+  |  ld.d BASE, L->base
+  |   ld.d TMP0, L->top
+  |   st.d r0, SAVE_PC(sp)			// Invalidate for subsequent line hook.
+  |  sub.d NARGS8:RC, TMP0, BASE
+  |  add.d RA, BASE, RA
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |  cleartp LFUNC:RB
+  |  ld.w INS, -4(PC)
+  |  jirl r0, CRET1, 0
+  |
+  |->cont_stitch:			// Trace stitching.
+  |.if JIT
+  |  // RA = resultptr, RB = meta base
+  |  ld.w INS, -4(PC)
+  |    ld.d TRACE:TMP2, -40(RB)		// Save previous trace.
+  |  decode_RA8a RC, INS
+  |   addi.d AT, MULTRES, -8
+  |    cleartp TRACE:TMP2
+  |  decode_RA8b RC
+  | add.d RC, BASE, RC                 // Call base.
+  |   beqz AT, >2
+  |1:  // Move results down.
+  |  ld.d CARG1, 0(RA)
+  |   addi.d AT, AT, -8
+  |    addi.d RA, RA, 8
+  |  st.d CARG1, 0(RC)
+  |   addi.d RC, RC, 8
+  |   bnez AT, <1
+  |2:
+  |   decode_RA8a RA, INS
+  |    decode_RB8a RB, INS
+  |   decode_RA8b RA
+  |    decode_RB8b RB
+  |   add.d RA, RA, RB
+  |   add.d RA, BASE, RA
+  |3:
+  |   sltu AT, RC, RA
+  |   bnez AT, >9			// More results wanted?
+  |
+  |  ld.hu TMP3, TRACE:TMP2->traceno
+  |  ld.hu RD, TRACE:TMP2->link
+  |  beq RD, TMP3, ->cont_nop		// Blacklisted.
+  |  slli.w RD, RD, 3
+  |  bnez RD, =>BC_JLOOP		// Jump to stitched trace.
+  |
+  |  // Stitch a new trace to the previous trace.
+  |  st.w TMP3, DISPATCH_J(exitno)(DISPATCH)
+  |  .STXD L, DISPATCH, DISPATCH_J(L)
+  |  st.d BASE, L->base
+  |  .DADDIU CARG1, DISPATCH, GG_DISP2J
+  |  or CARG2, PC, r0
+  |  bl extern lj_dispatch_stitch	// (jit_State *J, const BCIns *pc)
+  |  ld.d BASE, L->base
+  |  beq r0, r0, ->cont_nop
+  |
+  |9:
+  |  st.d TISNIL, 0(RC)
+  |  addi.d RC, RC, 8
+  |  beq r0, r0, <3
+  |.endif
+  |
+  |->vm_profhook:			// Dispatch target for profiler hook.
+#if LJ_HASPROFILE
+  |// st.w MULTRES, SAVE_MULTRES
+  |   st.w MULTRES, TMPD(sp)
+  |  or CARG2, PC, r0
+  |   st.d BASE, L->base
+  |  or CARG1, L, r0
+  |  bl extern lj_dispatch_profile	// (lua_State *L, const BCIns *pc)
+  |  // HOOK_PROFILE is off again, so re-dispatch to dynamic instruction.
+  |  addi.d PC, PC, -4
+  |  ld.d BASE, L->base
+  |  beq r0, r0, ->cont_nop
+#endif
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Trace exit handler -------------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |.macro savex_, a, b
+  |.if FPU
+  |  fst.d f..a, a*8(sp)
+  |  fst.d f..b, b*8(sp)
+  |  st.d r..a, 32*8+a*8(sp)
+  |  st.d r..b, 32*8+b*8(sp)
+  |.else
+  |  st.d r..a, a*8(sp)
+  |  st.d r..b, b*8(sp)
+  |.endif
+  |.endmacro
+  |
+  |->vm_exit_handler:
+  |.if JIT
+  |.if FPU
+  |  addi.d sp, sp, -(32*8+32*8)
+  |.else
+  |  addi.d sp, sp, -(32*8)
+  |.endif
+  |  savex_ 0, 2
+  |  savex_ 4, 5
+  |  savex_ 6, 7
+  |  savex_ 8, 9
+  |  savex_ 10, 11
+  |  savex_ 12, 13
+  |  savex_ 14, 15
+  |  savex_ 16, 17
+  |  savex_ 18, 19
+  |  savex_ 20, 21
+  |  savex_ 22, 23
+  |  savex_ 24, 25
+  |  savex_ 26, 27
+  |  savex_ 28, 29
+  |  savex_ 30, 31
+  |.if FPU
+  |  fst.d f1, 1*8(sp)
+  |  fst.d f3, 3*8(sp)
+  |  st.d r0, 32*8+1*8(sp)		// Clear RID_TMP.
+  |  addi.d TMP2, sp, 32*8+32*8		// Recompute original value of sp.
+  |  st.d TMP2, 32*8+3*8(sp)		// Store sp in RID_SP
+  |.else
+  |  st.d r0, 31*8(sp)			// Clear RID_TMP.
+  |  addi.d TMP2, sp, 32*8		// Recompute original value of sp.
+  |  st.d TMP2, 3*8(sp)			// Store sp in RID_SP
+  |.endif
+  |  li_vmstate EXIT
+  |  .DADDIU DISPATCH, JGL, -GG_DISP2G-32768
+  |  ld.w TMP1, 0(TMP2)			// Load exit number.
+  |  st_vmstate
+  |  .LDXD L, DISPATCH, DISPATCH_GL(cur_L)
+  |   .LDXD BASE, DISPATCH, DISPATCH_GL(jit_base)
+  |  .STXD L, DISPATCH, DISPATCH_J(L)
+  |  st.w ra, DISPATCH_J(parent)(DISPATCH)  // Store trace number.
+  |   st.d BASE, L->base
+  |  st.w TMP1, DISPATCH_J(exitno)(DISPATCH)  // Store exit number.
+  |  .DADDIU CARG1, DISPATCH, GG_DISP2J
+  |   .STXD r0, DISPATCH, DISPATCH_GL(jit_base)
+  |  or CARG2, sp, r0
+  |  bl extern lj_trace_exit		// (jit_State *J, ExitState *ex)
+  |  // Returns MULTRES (unscaled) or negated error code.
+  |  ld.d TMP1, L->cframe
+  |  .LI AT, -4
+  |   ld.d BASE, L->base
+  |  and sp, TMP1, AT
+  |   ld.d PC, SAVE_PC(sp)			// Get SAVE_PC.
+  |  st.d L, SAVE_L(sp)                      // Set SAVE_L (on-trace resume/yield).
+  |  beq r0, r0, >1
+  |.endif
+  |->vm_exit_interp:
+  |.if JIT
+  |  // CRET1 = MULTRES or negated error code, BASE, PC and JGL set.
+  |  ld.d L, SAVE_L(sp)
+  |   .DADDIU DISPATCH, JGL, -GG_DISP2G-32768
+  |  st.d BASE, L->base
+  |1:
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |  blt CRET1, r0, >9			// Check for error from exit.
+  |    .FPU addu16i.d TMP3, r0, 0x59c0		// TOBIT = 2^52 + 2^51 (float).
+  |  slli.d MULTRES, CRET1, 3
+  |  cleartp LFUNC:RB
+  |//st.w MULTRES, SAVE_MULTRES
+  |  st.w MULTRES, TMPD(sp)
+  |    .LI TISNIL, LJ_TNIL
+  |     .LI TISNUM, LJ_TISNUM		// Setup type comparison constants.
+  |    .FPU2 movgr2fr.w TOBIT, TMP3
+  |  ld.d TMP1, LFUNC:RB->pc
+  |   .STXD r0, DISPATCH, DISPATCH_GL(jit_base)
+  |  ld.d KBASE, PC2PROTO(k)(TMP1)
+  |    .FPU2 fcvt.d.s TOBIT, TOBIT
+  |  // Modified copy of ins_next which handles function header dispatch, too.
+  |  ld.w INS, 0(PC)
+  |   addi.d PC, PC, 4
+  |    // Assumes TISNIL == ~LJ_VMST_INTERP == -1
+  |    .STXW TISNIL, DISPATCH, DISPATCH_GL(vmstate)
+  |  decode_OP8a TMP1, INS
+  |  decode_OP8b TMP1
+  |    sltui TMP2, TMP1, BC_FUNCF*8
+  |  add.d TMP0, DISPATCH, TMP1
+  |   decode_RD8a RD, INS
+  |  ld.d AT, 0(TMP0)
+  |   decode_RA8a RA, INS
+  |   decode_RA8b RA
+  |    beqz TMP2, >2
+  |   decode_RD8b RD
+  |  jirl r0, AT, 0
+  |2:
+  |  sltui TMP2, TMP1, (BC_FUNCC+2)*8	// Fast function?
+  |  ld.d TMP1, FRAME_PC(BASE)
+  |  bnez TMP2, >3
+  |  // Check frame below fast function.
+  |  andi TMP0, TMP1, FRAME_TYPE
+  |  bnez TMP0, >3			// Trace stitching continuation?
+  |  // Otherwise set KBASE for Lua function below fast function.
+  |  ld.w TMP2, -4(TMP1)
+  |  decode_RA8a TMP0, TMP2
+  |  decode_RA8b TMP0
+  |  sub.d TMP1, BASE, TMP0
+  |  ld.d LFUNC:TMP2, -32(TMP1)
+  |  cleartp LFUNC:TMP2
+  |  ld.d TMP1, LFUNC:TMP2->pc
+  |  ld.d KBASE, PC2PROTO(k)(TMP1)
+  |3:
+  |  addi.d RC, MULTRES, -8
+  |  add.d RA, RA, BASE
+  |  jirl r0, AT, 0
+  |
+  |9:  // Rethrow error from the right C frame.
+  |  sub.w CARG2, r0, CRET1		//TODO LA: sub.w  no trap
+  |  or CARG1, L, r0
+  |  bl extern lj_err_throw 		// (lua_State *L, int errcode)
+  |.endif
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Math helper functions ----------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |// Hard-float round to integer.
+  |.macro vm_round_hf, func
+  |  addu16i.d TMP0, r0, 0x4330			// Hiword of 2^52 (double).
+  |  slli.d TMP0, TMP0, 32
+  |  movgr2fr.d f4, TMP0
+  |  fabs.d FRET2, FARG1			// |x|
+  |    movfr2gr.d AT, FARG1
+  |  fcmp.clt.d FCC0, FRET2, f4
+  |   fadd.d FRET1, FRET2, f4		// (|x| + 2^52) - 2^52
+  |  fsub.d FRET1, FRET1, f4
+  |  bceqz FCC0, >1			// Truncate only if |x| < 2^52.
+  |    slt AT, AT, r0
+  |.if "func" == "ceil"
+  |//   addu16i.d TMP0, r0, 0xbff0			// Hiword of -1 (double). Preserves -0.
+  |  .LUI TMP0, 0xbff0
+  |.else
+  |   addu16i.d TMP0, r0, 0x3ff0			// Hiword of +1 (double).
+  |.endif
+  |.if "func" == "trunc"
+  |   slli.d TMP0, TMP0, 32
+  |   movgr2fr.d f4, TMP0
+  |  fcmp.clt.d FCC0, FRET2, FRET1	// |x| < result?
+  |   fsub.d FRET2, FRET1, f4
+  |//  sel.d  FTMP1, FRET1, FRET2		// If yes, subtract +1.
+  |  fsel FTMP1, FRET1, FRET2, FCC0
+  |  movgr2fr.d FRET1, AT
+  |  fneg.d FRET2, FTMP1
+  |//.  sel.d FRET1, FTMP1, FRET2
+  |  movfr2cf FCC0, FRET1
+  |  fsel FRET1, FTMP1, FRET2, FCC0
+  |  jirl r0, ra, 0
+  |.else
+  |  fneg.d FRET2, FRET1
+  |   slli.d TMP0, TMP0, 32
+  |   movgr2fr.d f4, TMP0
+  |  movgr2fr.d FTMP1, AT
+  |  movfr2cf FCC0, FTMP1
+  |  fsel FTMP1, FRET1, FRET2, FCC0
+  |.if "func" == "ceil"
+  |  fcmp.clt.d FCC0, FTMP1, FARG1	// x > result?
+  |.else
+  |  fcmp.clt.d FCC0, FARG1, FTMP1	// x < result?
+  |.endif
+  |   fsub.d FRET2, FTMP1, f4		// If yes, subtract +-1.
+  |  fsel FRET1, FTMP1, FRET2, FCC0
+  |  fmov.d FARG1, FRET1
+  |  jirl r0, ra, 0
+  |.endif
+  |1:
+  |  fmov.d FRET1, FARG1
+  |  jirl r0, ra, 0
+  |.endmacro
+  |
+  |.macro vm_round, func
+  |.if FPU
+  |  vm_round_hf, func
+  |.endif
+  |.endmacro
+  |
+  |->vm_floor:
+  |  vm_round floor
+  |->vm_ceil:
+  |  vm_round ceil
+  |->vm_trunc:
+  |.if JIT
+  |  vm_round trunc
+  |.endif
+  |
+  |// Soft-float integer to number conversion.
+  |.macro sfi2d, ARG
+  |.if not FPU
+  |  srai.w TMP0, ARG, 31
+  |  beqz ARG, >9			// Handle zero first.
+  |  xor TMP1, ARG, TMP0
+  |  sub.d TMP1, TMP1, TMP0		// Absolute value in TMP1.
+  |  clz.d ARG, TMP1
+  |  addi.w ARG, ARG, -11
+  |  .LI AT, 0x3ff+63-11-1
+  |   sll.d TMP1, TMP1, ARG		// Align mantissa left with leading 1.
+  |  sub.w ARG, AT, ARG			// Exponent - 1.
+  |  bstrins.w ARG, TMP0, 11, 11		// Sign | Exponent.
+  |  slli.d ARG, ARG, 52			// Align left.
+  |  add.d ARG, ARG, TMP1              // Add mantissa, increment exponent.
+  |  jirl r0, ra, 0
+  |9:
+  |  jirl r0, ra, 0
+  |.endif
+  |.endmacro
+  |
+  |// Input CARG1. Output: CARG1. Temporaries: AT, TMP0, TMP1.
+  |->vm_sfi2d_1:
+  |  sfi2d CARG1
+  |
+  |// Input CARG2. Output: CARG2. Temporaries: AT, TMP0, TMP1.
+  |->vm_sfi2d_2:
+  |  sfi2d CARG2
+  |
+  |// Soft-float comparison. Equivalent to c.eq.d.
+  |// Input: CARG*. Output: CRET1. Temporaries: AT, TMP0, TMP1.
+  |->vm_sfcmpeq:
+  |.if not FPU
+  |  slli.d AT, CARG1, 1
+  |  slli.d TMP0, CARG2, 1
+  |  or TMP1, AT, TMP0
+  |  addu16i.d TMP1, r0, 0xffe0
+  |  beqz TMP1, >8			// Both args +-0: return 1.
+  |  slli.d TMP1, TMP1, 32
+  |   sltu AT, TMP1, AT
+  |   sltu TMP0, TMP1, TMP0
+  |  or TMP1, AT, TMP0
+  |  xor AT, CARG1, CARG2
+  |  bnez TMP1, >9			// Either arg is NaN: return 0;
+  |  sltui CRET1, AT, 1                // Same values: return 1.
+  |  jirl r0, ra, 0
+  |8:
+  |  .LI CRET1, 1
+  |  jirl r0, ra, 0
+  |9:
+  |  .LI CRET1, 0
+  |  jirl r0, ra, 0
+  |.endif
+  |
+  |// Soft-float comparison. Equivalent to c.ult.d and c.olt.d.
+  |// Input: CARG1, CARG2. Output: CRET1. Temporaries: AT, TMP0, TMP1, CRET2.
+  |->vm_sfcmpult:
+  |.if not FPU
+  |  .LI CRET2, 1
+  |  beq r0, r0, >1
+  |.endif
+  |
+  |->vm_sfcmpolt:
+  |.if not FPU
+  |  .LI CRET2, 0
+  |1:
+  |  slli.d AT, CARG1, 1
+  |  slli.d TMP0, CARG2, 1
+  |  or TMP1, AT, TMP0
+  |  addu16i.d TMP1, r0, 0xffe0
+  |  beqz TMP1, >8			// Both args +-0: return 0.
+  |  slli.d TMP1, TMP1, 32
+  |   sltu AT, TMP1, AT
+  |   sltu TMP0, TMP1, TMP0
+  |  or TMP1, AT, TMP0
+  |  and AT, CARG1, CARG2
+  |  bnez TMP1, >9			// Either arg is NaN: return 0 or 1;
+  |  blt AT, r0, >5			// Both args negative?
+  |  slt CRET1, CARG1, CARG2
+  |  jirl r0, ra, 0
+  |5:  // Swap conditions if both operands are negative.
+  |  slt CRET1, CARG2, CARG1
+  |  jirl r0, ra, 0
+  |8:
+  |  .LI CRET1, 0
+  |  jirl r0, ra, 0
+  |9:
+  |  or CRET1, CRET2, r0
+  |  jirl r0, ra, 0
+  |.endif
+  |
+  |->vm_sfcmpogt:
+  |.if not FPU
+  |  slli.d AT, CARG2, 1
+  |  slli.d TMP0, CARG1, 1
+  |  or TMP1, AT, TMP0
+  |  addu16i.d TMP1, r0, 0xffe0
+  |  beqz TMP1, >8			// Both args +-0: return 0.
+  |  slli.d TMP1, TMP1, 32
+  |   sltu AT, TMP1, AT
+  |   sltu TMP0, TMP1, TMP0
+  |  or TMP1, AT, TMP0
+  |  and AT, CARG2, CARG1
+  |  bnez TMP1, >9			// Either arg is NaN: return 0 or 1;
+  |  blt AT, r0, >5			// Both args negative?
+  |  slt CRET1, CARG2, CARG1
+  |  jirl r0, ra, 0
+  |5:  // Swap conditions if both operands are negative.
+  |  slt CRET1, CARG1, CARG2
+  |  jirl r0, ra, 0
+  |8:
+  |  .LI CRET1, 0
+  |  jirl r0, ra, 0
+  |9:
+  |  .LI CRET1, 0
+  |  jirl r0, ra, 0
+  |.endif
+  |
+  |// Soft-float comparison. Equivalent to c.ole.d a, b or c.ole.d b, a.
+  |// Input: CARG1, CARG2, TMP3. Output: CRET1. Temporaries: AT, TMP0, TMP1.
+  |->vm_sfcmpolex:
+  |.if not FPU
+  |  slli.d AT, CARG1, 1
+  |  slli.d TMP0, CARG2, 1
+  |  or TMP1, AT, TMP0
+  |  addu16i.d TMP1, r0, 0xffe0
+  |  beqz TMP1, >8			// Both args +-0: return 1.
+  |  slli.d TMP1, TMP1, 32
+  |   sltu AT, TMP1, AT
+  |   sltu TMP0, TMP1, TMP0
+  |  or TMP1, AT, TMP0
+  |  and AT, CARG1, CARG2
+  |  bnez TMP1, >9			// Either arg is NaN: return 0;
+  |  xor AT, AT, TMP3
+  |  bltz AT, r0, >5			// Both args negative?
+  |  slt CRET1, CARG2, CARG1
+  |  jirl r0, ra, 0
+  |5:  // Swap conditions if both operands are negative.
+  |  slt CRET1, CARG1, CARG2
+  |  jirl r0, ra, 0
+  |8:
+  |  .LI CRET1, 1
+  |  jirl r0, ra, 0
+  |9:
+  |  .LI CRET1, 0
+  |  jirl r0, ra, 0
+  |.endif
+  |
+  |.macro sfmin_max, name, fpcall
+  |->vm_sf .. name:
+  |.if JIT and not FPU
+  |  or TMP2, ra, r0
+  |  bl ->fpcall
+  |  or ra, TMP2, r0
+  |  or TMP0, CRET1, r0
+  |  or CRET1, CARG1, r0
+  |  maskeqz CRET1, CRET1, TMP0
+  |  masknez TMP0, CARG2, TMP0
+  |  or CRET1, CRET1, TMP0
+  |  jirl r0, ra, 0
+  |.endif
+  |.endmacro
+  |
+  |  sfmin_max min, vm_sfcmpolt
+  |  sfmin_max max, vm_sfcmpogt
+  |
+  |//-----------------------------------------------------------------------
+  |//-- Miscellaneous functions --------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |.define NEXT_TAB,		TAB:CARG1
+  |.define NEXT_IDX,		CARG2
+  |.define NEXT_ASIZE,		CARG3
+  |.define NEXT_NIL,		CARG4
+  |.define NEXT_TMP0,		r12
+  |.define NEXT_TMP1,		r13
+  |.define NEXT_TMP2,		r14
+  |.define NEXT_RES_VK,		CRET1
+  |.define NEXT_RES_IDX,	CRET2
+  |.define NEXT_RES_PTR,	sp
+  |.define NEXT_RES_VAL,	0(sp)
+  |.define NEXT_RES_KEY,	8(sp)
+  |
+  |// TValue *lj_vm_next(GCtab *t, uint32_t idx)
+  |// Next idx returned in CRET2.
+  |->vm_next:
+  |.if JIT and ENDIAN_LE
+  |   ld.d NEXT_ASIZE, NEXT_TAB->asize
+  |  ld.d NEXT_TMP0, NEXT_TAB->array
+  |    .LI NEXT_NIL, LJ_TNIL
+  |1:  // Traverse array part.
+  |   sltu AT, NEXT_IDX, NEXT_ASIZE
+  |    slli.w NEXT_TMP1, NEXT_IDX, 3
+  |   add.d NEXT_TMP1, NEXT_TMP0, NEXT_TMP1
+  |   beqz AT, >5
+  |   .LI AT, LJ_TISNUM
+  |  ld.d NEXT_TMP2, 4(NEXT_TMP1)
+  |   slli.d AT, AT, 47
+  |   or NEXT_TMP1, NEXT_IDX, AT
+  |  addi.d NEXT_IDX, NEXT_IDX, 1
+  |  beq NEXT_TMP2, NEXT_NIL, <1
+  |  st.d NEXT_TMP2, NEXT_RES_VAL
+  |   st.d NEXT_TMP1, NEXT_RES_KEY
+  |  addi.d NEXT_RES_VK, NEXT_RES_PTR, 0
+  |  addi.d NEXT_RES_IDX, NEXT_IDX, 0
+  |  jirl r0, ra, 0
+  |
+  |5:  // Traverse hash part.
+  |  sub.d NEXT_RES_IDX, NEXT_IDX, NEXT_ASIZE
+  |   ld.d NODE:NEXT_RES_VK, NEXT_TAB->node
+  |    slli.w NEXT_TMP2, NEXT_RES_IDX, 5
+  |  ld.d NEXT_TMP0, NEXT_TAB->hmask
+  |    slli.w AT, NEXT_RES_IDX, 3
+  |    sub.d AT, NEXT_TMP2, AT
+  |   add.d NODE:NEXT_RES_VK, NODE:NEXT_RES_VK, AT
+  |6:
+  |  sltu AT, NEXT_TMP0, NEXT_RES_IDX
+  |  bnez AT, >8
+  |  ld.d NEXT_TMP2, NODE:NEXT_RES_VK->val
+  |  addi.d NEXT_RES_IDX, NEXT_RES_IDX, 1
+  |  bne NEXT_TMP2, NEXT_NIL, >9
+  |  // Skip holes in hash part.
+  |  addi.d NODE:NEXT_RES_VK, NODE:NEXT_RES_VK, sizeof(Node)
+  |  b <6
+  |
+  |8:  // End of iteration. Set the key to nil (not the value).
+  |  st.d NEXT_NIL, NEXT_RES_KEY
+  |  addi.d NEXT_RES_VK, NEXT_RES_PTR, 0
+  |9:
+  |  add.d NEXT_RES_IDX, NEXT_RES_IDX, NEXT_ASIZE
+  |  jirl r0, ra, 0
+  |.endif
+  |
+  |//-----------------------------------------------------------------------
+  |//-- FFI helper functions -----------------------------------------------
+  |//-----------------------------------------------------------------------
+  |
+  |// Handler for callback functions. Callback slot number in r19, g in r17.
+  |->vm_ffi_callback:
+  |.if FFI
+  |.type CTSTATE, CTState, PC
+  |  saveregs
+  |  ld.d CTSTATE, GL:r17->ctype_state
+  |   .DADDIU DISPATCH, r17, GG_G2DISP
+  |  st.w r19, CTSTATE->cb.slot
+  |  st.d CARG1, CTSTATE->cb.gpr[0]
+  |  .FPU2 fst.d FARG1, CTSTATE->cb.fpr[0]
+  |  st.d CARG2, CTSTATE->cb.gpr[1]
+  |  .FPU2 fst.d FARG2, CTSTATE->cb.fpr[1]
+  |  st.d CARG3, CTSTATE->cb.gpr[2]
+  |  .FPU2 fst.d FARG3, CTSTATE->cb.fpr[2]
+  |  st.d CARG4, CTSTATE->cb.gpr[3]
+  |  .FPU2 fst.d FARG4, CTSTATE->cb.fpr[3]
+  |  st.d CARG5, CTSTATE->cb.gpr[4]
+  |  .FPU2 fst.d FARG5, CTSTATE->cb.fpr[4]
+  |  st.d CARG6, CTSTATE->cb.gpr[5]
+  |  .FPU2 fst.d FARG6, CTSTATE->cb.fpr[5]
+  |  st.d CARG7, CTSTATE->cb.gpr[6]
+  |  .FPU2 fst.d FARG7, CTSTATE->cb.fpr[6]
+  |  st.d CARG8, CTSTATE->cb.gpr[7]
+  |  .FPU2 fst.d FARG8, CTSTATE->cb.fpr[7]
+  |  addi.d TMP0, sp, CFRAME_SPACE
+  |  st.d TMP0, CTSTATE->cb.stack
+  |  st.d r0, SAVE_PC(sp)			// Any value outside of bytecode is ok.
+  |   or CARG2, sp, r0
+  |  or CARG1, CTSTATE, r0
+  |  bl extern lj_ccallback_enter	// (CTState *cts, void *cf)
+  |  // Returns lua_State *.
+  |  ld.d BASE, L:CRET1->base
+  |  ld.d RC, L:CRET1->top
+  |   or L, CRET1, r0
+  |     .FPU addu16i.d TMP3, r0, 0x59c0		// TOBIT = 2^52 + 2^51 (float).
+  |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+  |     .FPU2 movgr2fr.w TOBIT, TMP3
+  |      .LI TISNIL, LJ_TNIL
+  |       .LI TISNUM, LJ_TISNUM
+  |    li_vmstate INTERP
+  |  sub.w RC, RC, BASE
+  |   cleartp LFUNC:RB
+  |    st_vmstate
+  |     .FPU2 fcvt.d.s TOBIT, TOBIT
+  |  ins_callt
+  |.endif
+  |
+  |->cont_ffi_callback:			// Return from FFI callback.
+  |.if FFI
+  |  .LDXD CTSTATE, DISPATCH, DISPATCH_GL(ctype_state)
+  |   st.d BASE, L->base
+  |   st.d RB, L->top
+  |  st.d L, CTSTATE->L
+  |  or CARG2, RA, r0
+  |  or CARG1, CTSTATE, r0
+  |  bl extern lj_ccallback_leave	// (CTState *cts, TValue *o)
+  |  .FPU2 fld.d FRET1, CTSTATE->cb.fpr[0]
+  |  ld.d CRET1, CTSTATE->cb.gpr[0]
+  |  .FPU2 fld.d FRET2, CTSTATE->cb.fpr[1]
+  |  ld.d CRET2, CTSTATE->cb.gpr[1]
+  |  beq r0, r0, ->vm_leave_unw
+  |.endif
+  |
+  |->vm_ffi_call:			// Call C function via FFI.
+  |  // Caveat: needs special frame unwinding, see below.
+  |.if FFI
+  |  .type CCSTATE, CCallState, CARG1
+  |  ld.w TMP1, CCSTATE->spadj
+  |   ld.bu CARG2, CCSTATE->nsp
+  |   ld.bu CARG3, CCSTATE->nfpr
+  |  or TMP2, sp, r0
+  |  sub.d sp, sp, TMP1
+  |  st.d ra, -8(TMP2)
+  |   slli.w CARG2, CARG2, 3
+  |  st.d r23, -16(TMP2)
+  |  st.d CCSTATE, -24(TMP2)
+  |  or r23, TMP2, r0
+  |  addi.d TMP1, CCSTATE, offsetof(CCallState, stack)
+  |  or TMP2, sp, r0
+  |  add.d TMP3, TMP1, CARG2
+  |  beqz CARG2, >2
+  |1:
+  |   ld.d TMP0, 0(TMP1)
+  |  addi.d TMP1, TMP1, 8
+  |  sltu AT, TMP1, TMP3
+  |   st.d TMP0, 0(TMP2)
+  |  addi.d TMP2, TMP2, 8
+  |  bnez AT, <1
+  |2:
+  |  beqz CARG3, >3
+  |  .FPU2 fld.d FARG1, CCSTATE->fpr[0]
+  |  .FPU2 fld.d FARG2, CCSTATE->fpr[1]
+  |  .FPU2 fld.d FARG3, CCSTATE->fpr[2]
+  |  .FPU2 fld.d FARG4, CCSTATE->fpr[3]
+  |  .FPU2 fld.d FARG5, CCSTATE->fpr[4]
+  |  .FPU2 fld.d FARG6, CCSTATE->fpr[5]
+  |  .FPU2 fld.d FARG7, CCSTATE->fpr[6]
+  |  .FPU2 fld.d FARG8, CCSTATE->fpr[7]
+  |3:
+  |  ld.d CFUNCADDR, CCSTATE->func
+  |  ld.d CARG2, CCSTATE->gpr[1]
+  |  ld.d CARG3, CCSTATE->gpr[2]
+  |  ld.d CARG4, CCSTATE->gpr[3]
+  |  ld.d CARG5, CCSTATE->gpr[4]
+  |  ld.d CARG6, CCSTATE->gpr[5]
+  |  ld.d CARG7, CCSTATE->gpr[6]
+  |  ld.d CARG8, CCSTATE->gpr[7]
+  |  ld.d CARG1, CCSTATE->gpr[0]         // Do this last, since CCSTATE is CARG1.
+  |  jirl r1, CFUNCADDR, 0
+  |  ld.d CCSTATE:TMP1, -24(r23)
+  |  ld.d TMP2, -16(r23)
+  |  ld.d ra, -8(r23)
+  |  st.d CRET1, CCSTATE:TMP1->gpr[0]
+  |  st.d CRET2, CCSTATE:TMP1->gpr[1]
+  |.if FPU
+  |  fmov.d FRET1, FARG1
+  |  fmov.d FRET2, FARG2
+  |  fst.d FRET1, CCSTATE:TMP1->fpr[0]
+  |  fst.d FRET2, CCSTATE:TMP1->fpr[1]
+  |.else
+  |  st.d CARG1, CCSTATE:TMP1->gpr[2]	// 2nd FP struct field for soft-float.
+  |.endif
+  |  or sp, r23, r0
+  |  or r23, TMP2, r0
+  |  jirl r0, ra, 0
+  |.endif
+  |// Note: vm_ffi_call must be the last function in this object file!
+  |
+  |//-----------------------------------------------------------------------
+}
+
+/* Generate the code for a single instruction. */
+static void build_ins(BuildCtx *ctx, BCOp op, int defop)
+{
+  int vk = 0;
+  |=>defop:
+
+  switch (op) {
+
+  /* -- Comparison ops ---------------------------------------------------- */
+
+  /* Remember: all ops branch for a true comparison, fall through otherwise. */
+
+  case BC_ISLT: case BC_ISGE: case BC_ISLE: case BC_ISGT:
+    |  // RA = src1*8, RD = src2*8, JMP with RD = target
+    |.macro bc_comp, FRA, FRD, ARGRA, ARGRD, movop, fmovop, fcomp, sfcomp
+    |  add.d RA, BASE, RA
+    |   add.d RD, BASE, RD
+    |  ld.d ARGRA, 0(RA)
+    |   ld.d ARGRD, 0(RD)
+    |    ld.hu TMP2, OFS_RD(PC)
+    |  gettp CARG3, ARGRA
+    |   gettp CARG4, ARGRD
+    |   addi.d PC, PC, 4
+    |  bne CARG3, TISNUM, >2
+    |   decode_RD4b TMP2
+    |  bne CARG4, TISNUM, >5
+    |  slli.w ARGRA, ARGRA, 0	// sextw -> slli.w
+    |   slli.w ARGRD, ARGRD, 0	// sextw -> slli.w
+    |    .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  slt AT, CARG1, CARG2
+    |    add.w TMP2, TMP2, TMP3
+    |  movop TMP2, TMP2, AT
+    |1:
+    |  add.d PC, PC, TMP2
+    |  ins_next
+    |
+    |2:  // RA is not an integer.
+    |  sltui AT, CARG3, LJ_TISNUM
+    |   .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  beqz AT, ->vmeta_comp
+    |  sltui AT, CARG4, LJ_TISNUM
+    |   decode_RD4b TMP2       //TODO
+    |  beqz AT, >4
+    |.if FPU
+    |  fld.d FRA, 0(RA)
+    |   fld.d FRD, 0(RD)
+    |.endif
+    |3:  // RA and RD are both numbers.
+    |.if FPU
+    |  fcomp FCC0, FTMP0, FTMP2
+    |   add.w TMP2, TMP2, TMP3
+    |  movcf2gr TMP3, FCC0
+    |  fmovop TMP2, TMP2, TMP3
+    |  beq r0, r0, <1
+    |.else
+    |   add.w TMP2, TMP2, TMP
+    |  bl sfcomp
+    |  movop TMP2, TMP2, CRET1
+    |  beq r0, r0, <1
+    |.endif
+    |
+    |4:  // RA is a number, RD is not a number.
+    |//  bne CARG4, TISNUM, ->vmeta_comp
+    |  // RA is a number, RD is an integer. Convert RD to a number.
+    |.if FPU
+    |  fld.s FRD, LO(RD)
+    |  bne CARG4, TISNUM, ->vmeta_comp
+    |  fld.d FRA, 0(RA)
+    |  ffint.d.w FRD, FRD
+    |  beq r0, r0, <3
+    |.else
+    |.if "ARGRD" == "CARG1"
+    |  slli.w CARG1, CARG1, 0		// sextw -> slli.w
+    |  bne CARG4, TISNUM, ->vmeta_comp
+    |  bl ->vm_sfi2d_1
+    |.else
+    |  slli.w CARG2, CARG2, 0		// sextw -> slli.w
+    |  bne CARG4, TISNUM, ->vmeta_comp
+    |  bl ->vm_sfi2d_2
+    |.endif
+    |  beq r0, r0, <3
+    |.endif
+    |
+    |5:  // RA is an integer, RD is not an integer
+    |  sltui AT, CARG4, LJ_TISNUM
+    |  .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  beqz AT, ->vmeta_comp
+    |  // RA is an integer, RD is a number. Convert RA to a number.
+    |.if FPU
+    |   fld.s FRA, LO(RA)
+    |   fld.d FRD, 0(RD)
+    |   ffint.d.w FRA, FRA
+    |  beq r0, r0, <3
+    |.else
+    |.if "ARGRA" == "CARG1"
+    |  slli.w CARG1, CARG1, 0		// sextw -> slli.w
+    |  bl ->vm_sfi2d_1
+    |.else
+    |  slli.w CARG2, CARG2, 0		// sextw -> slli.w
+    |  bl ->vm_sfi2d_2
+    |.endif
+    |  beq r0, r0, <3
+    |.endif
+    |.endmacro
+    |
+    if (op == BC_ISLT) {
+      |  bc_comp FTMP0, FTMP2, CARG1, CARG2, maskeqz, maskeqz, fcmp.clt.d, ->vm_sfcmpolt
+    } else if (op == BC_ISGE) {
+      |  bc_comp FTMP0, FTMP2, CARG1, CARG2, masknez, masknez, fcmp.clt.d, ->vm_sfcmpolt
+    } else if (op == BC_ISLE) {
+      |  bc_comp FTMP2, FTMP0, CARG2, CARG1, masknez, masknez, fcmp.cult.d, ->vm_sfcmpult
+    } else {
+      |  bc_comp FTMP2, FTMP0, CARG2, CARG1, maskeqz, maskeqz, fcmp.cult.d, ->vm_sfcmpult
+    }
+    break;
+
+  case BC_ISEQV: case BC_ISNEV:
+    vk = op == BC_ISEQV;
+    |  // RA = src1*8, RD = src2*8, JMP with RD = target
+    |  add.d RA, BASE, RA
+    |    addi.d PC, PC, 4
+    |   add.d RD, BASE, RD
+    |  ld.d CARG1, 0(RA)
+    |    ld.hu TMP2, -4+OFS_RD(PC)
+    |   ld.d CARG2, 0(RD)
+    |  gettp CARG3, CARG1
+    |   gettp CARG4, CARG2
+    |  sltu AT, TISNUM, CARG3
+    |   sltu TMP1, TISNUM, CARG4
+    |  or AT, AT, TMP1
+    |  .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    if (vk) {
+      |  beqz AT, ->BC_ISEQN_Z		//TODO which is the following slot ins
+    } else {
+      |  beqz AT, ->BC_ISNEN_Z
+    }
+    |  // Either or both types are not numbers.
+    |.if FFI
+    |  .LI AT, LJ_TCDATA
+    |  beq CARG3, AT, ->vmeta_equal_cd
+    |.endif
+    |   decode_RD4b TMP2
+    |.if FFI
+    |  beq CARG4, AT, ->vmeta_equal_cd
+    |.endif
+    |  add.w TMP2, TMP2, TMP3
+    |  bne CARG1, CARG2, >2
+    |  // Tag and value are equal.
+    if (vk) {
+      |->BC_ISEQV_Z:
+      |  add.d PC, PC, TMP2
+    }
+    |1:
+    |  ins_next
+    |
+    |2:  // Check if the tags are the same and it's a table or userdata.
+    |  xor AT, CARG3, CARG4			// Same type?
+    |  sltui TMP0, CARG3, LJ_TISTABUD+1		// Table or userdata?
+    |  masknez TMP0, TMP0, AT
+    |  cleartp TAB:TMP1, CARG1
+    if (vk) {
+      |  beqz TMP0, <1
+    } else {
+      |  beqz TMP0, ->BC_ISEQV_Z  // Reuse code from opposite instruction.
+    }
+    |  // Different tables or userdatas. Need to check __eq metamethod.
+    |  // Field metatable must be at same offset for GCtab and GCudata!
+    |  ld.d TAB:TMP3, TAB:TMP1->metatable
+    if (vk) {
+      |  beqz TAB:TMP3, <1		// No metatable?
+      |  ld.bu TMP3, TAB:TMP3->nomm
+      |  andi TMP3, TMP3, 1<<MM_eq
+      |  bnez TMP3, >1			// Or 'no __eq' flag set?
+    } else {
+      |  beqz TAB:TMP3,->BC_ISEQV_Z	// No metatable?
+      |  ld.bu TMP3, TAB:TMP3->nomm
+      |  andi TMP3, TMP3, 1<<MM_eq
+      |  bnez TMP3, ->BC_ISEQV_Z	// Or 'no __eq' flag set?
+    }
+    |  .LI TMP0, 1-vk                   // ne = 0 or 1.
+    |  beq r0, r0, ->vmeta_equal			// Handle __eq metamethod.
+    break;
+
+  case BC_ISEQS: case BC_ISNES:
+    vk = op == BC_ISEQS;
+    |  // RA = src*8, RD = str_const*8 (~), JMP with RD = target
+    |  add.d RA, BASE, RA
+    |   addi.d PC, PC, 4
+    |  ld.d CARG1, 0(RA)
+    |   sub.d RD, KBASE, RD
+    |    ld.hu TMP2, -4+OFS_RD(PC)
+    |   ld.d CARG2, -8(RD)		// KBASE-8-str_const*8
+    |.if FFI
+    |  gettp TMP0, CARG1
+    |  .LI AT, LJ_TCDATA
+    |.endif
+    |  .LI TMP1, LJ_TSTR
+    |   decode_RD4b TMP2
+    |  settp CARG2, TMP1
+    |.if FFI
+    |  beq TMP0, AT, ->vmeta_equal_cd
+    |.endif
+    |   .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  xor TMP1, CARG1, CARG2
+    |   add.w TMP2, TMP2, TMP3
+    if (vk) {
+      |  masknez TMP2, TMP2, TMP1
+    } else {
+      |  maskeqz TMP2, TMP2, TMP1
+    }
+    |  add.d PC, PC, TMP2
+    |  ins_next
+    break;
+
+  case BC_ISEQN: case BC_ISNEN:
+    vk = op == BC_ISEQN;
+    |  // RA = src*8, RD = num_const*8, JMP with RD = target
+    |  add.d RA, BASE, RA
+    |   add.d RD, KBASE, RD
+    |  ld.d CARG1, 0(RA)
+    |   ld.d CARG2, 0(RD)
+    |    ld.hu TMP2, OFS_RD(PC)
+    |  gettp CARG3, CARG1
+    |   gettp CARG4, CARG2
+    |    addi.d PC, PC, 4
+    |    .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    if (vk) {
+      |->BC_ISEQN_Z:
+    } else {
+      |->BC_ISNEN_Z:
+    }
+    |   decode_RD4b TMP2
+    |  bne CARG3, TISNUM, >3
+    |   add.w TMP2, TMP2, TMP3
+    |  bne CARG4, TISNUM, >6
+    |  xor AT, CARG1, CARG2
+    if (vk) {
+      | masknez TMP2, TMP2, AT
+      |1:
+      |  add.d PC, PC, TMP2
+      |2:
+    } else {
+      |  maskeqz TMP2, TMP2, AT
+      |1:
+      |2:
+      |  add.d PC, PC, TMP2
+    }
+    |  ins_next
+    |
+    |3:  // RA is not an integer.
+    |  sltu AT, CARG3, TISNUM
+    |   add.w TMP2, TMP2, TMP3
+    |.if FFI
+    |  beqz AT, >8
+    |.else
+    |  beqz AT, <2
+    |.endif
+    |  sltu AT, CARG4, TISNUM
+    |.if FPU
+    |  fld.d FTMP0, 0(RA)
+    |   fld.d FTMP2, 0(RD)
+    |.endif
+    |  beqz AT, >5
+    |4:  // RA and RD are both numbers.
+    |.if FPU
+    |  fcmp.ceq.d FCC0, FTMP0, FTMP2		//TODO fcmp.cond.d cc, fj, fk
+    |  movcf2gr TMP1, FCC0
+    if (vk) {
+      |  maskeqz TMP2, TMP2, TMP1
+    } else {
+      |  masknez TMP2, TMP2, TMP1
+    }
+    |  beq r0, r0, <1
+    |.else
+    |  bl ->vm_sfcmpeq
+    if (vk) {
+      |  maskeqz TMP2, TMP2, CRET1
+    } else {
+      |  masknez TMP2, TMP2, CRET1
+    }
+    |  beq r0, r0, <1
+    |.endif
+    |
+    |5:  // RA is a number, RD is not a number.
+    |//.if FFI
+    |//  bne CARG4, TISNUM, >9		//TODO does not process the following flot ins
+    |//.else
+    |//  bne CARG4, TISNUM, <2
+    |//.endif
+    |  // RA is a number, RD is an integer. Convert RD to a number.
+    |.if FPU
+    |  fld.s FTMP2, LO(RD)
+    |.if FFI
+    |  bne CARG4, TISNUM, >9
+    |.else
+    |  bne CARG4, TISNUM, <2
+    |.endif
+    |  ffint.d.w FTMP2, FTMP2
+    |  beq r0, r0, <4
+    |.else
+    |  slli.w CARG2, CARG2, 0           // sextw -> slli.w
+    |.if FFI
+    |  bne CARG4, TISNUM, >9
+    |.else
+    |  bne CARG4, TISNUM, <2
+    |.endif
+    |  bl ->vm_sfi2d_2
+    |  beq r0, r0, <4
+    |.endif
+    |
+    |6:  // RA is an integer, RD is not an integer
+    |  sltu AT, CARG4, TISNUM
+    |//.if FFI
+    |//  beqz AT, >9			//TODO does not process the following flot ins
+    |//.else
+    |//  beqz AT, <2
+    |//.endif
+    |  // RA is an integer, RD is a number. Convert RA to a number.
+    |.if FPU
+    |  fld.s FTMP0, LO(RA)
+    |.if FFI
+    |  beqz AT, >9
+    |.else
+    |  beqz AT, <2
+    |.endif
+    |   fld.d FTMP2, 0(RD)
+    |   ffint.d.w FTMP0, FTMP0
+    |  b <4
+    |.else
+    |  slli.w CARG1, CARG1, 0		// sextw -> slli.w
+    |.if FFI
+    |  beqz AT, >9
+    |.else
+    |  beqz AT, <2
+    |.endif
+    |  bl ->vm_sfi2d_1
+    |  beq r0, r0, <4
+    |.endif
+    |
+    |.if FFI
+    |8:
+    |  .LI AT, LJ_TCDATA
+    |  bne CARG3, AT, <2
+    |  beq r0, r0, ->vmeta_equal_cd
+    |9:
+    |  .LI AT, LJ_TCDATA
+    |  bne CARG4, AT, <2
+    |  beq r0, r0, ->vmeta_equal_cd
+    |.endif
+    break;
+
+  case BC_ISEQP: case BC_ISNEP:
+    vk = op == BC_ISEQP;
+    |  // RA = src*8, RD = primitive_type*8 (~), JMP with RD = target
+    |  add.d RA, BASE, RA
+    |   srli.w TMP1, RD, 3
+    |  ld.d TMP0, 0(RA)
+    |    ld.hu TMP2, OFS_RD(PC)
+    |   nor TMP1, TMP1, r0
+    |  gettp TMP0, TMP0
+    |    addi.d PC, PC, 4
+    |  or r17, TMP0, r0
+    |  xor TMP0, TMP0, TMP1
+    |.if FFI
+    |  .LI AT, LJ_TCDATA
+    |  beq r17, AT, ->vmeta_equal_cd
+    |.endif
+    |  decode_RD4b TMP2
+    |  .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  add.w TMP2, TMP2, TMP3
+    if (vk) {
+      |  masknez TMP2, TMP2, TMP0
+    } else {
+      |  maskeqz TMP2, TMP2, TMP0
+    }
+    |  add.d PC, PC, TMP2
+    |  ins_next
+    break;
+
+  /* -- Unary test and copy ops ------------------------------------------- */
+
+  case BC_ISTC: case BC_ISFC: case BC_IST: case BC_ISF:
+    |  // RA = dst*8 or unused, RD = src*8, JMP with RD = target
+    |  add.d RD, BASE, RD
+    |   ld.hu TMP2, OFS_RD(PC)
+    |  ld.d TMP0, 0(RD)
+    |   addi.d PC, PC, 4
+    |  gettp TMP0, TMP0
+    |  sltui TMP0, TMP0, LJ_TISTRUECOND
+    if (op == BC_IST || op == BC_ISF) {
+      |   decode_RD4b TMP2
+      |   .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+      |   add.w TMP2, TMP2, TMP3
+      if (op == BC_IST) {
+	|  maskeqz TMP2, TMP2, TMP0;
+      } else {
+	|  masknez TMP2, TMP2, TMP0;
+      }
+      |  add.d PC, PC, TMP2
+    } else {
+      |  ld.d CRET1, 0(RD)
+      |  add.d RA, BASE, RA
+      if (op == BC_ISTC) {
+	|  beqz TMP0, >1
+      } else {
+	|  bnez TMP0, >1
+      }
+      |   decode_RD4b TMP2
+      |   .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+      |   add.w TMP2, TMP2, TMP3
+      |  st.d CRET1, 0(RA)
+      |   add.d PC, PC, TMP2
+      |1:
+    }
+    |  ins_next
+    break;
+
+  case BC_ISTYPE:
+    |  // RA = src*8, RD = -type*8
+    |  add.d TMP2, BASE, RA
+    |  srli.w TMP1, RD, 3
+    |  ld.d TMP0, 0(TMP2)
+    |  ins_next1
+    |  gettp TMP0, TMP0
+    |  add.d AT, TMP0, TMP1
+    |  bnez AT, ->vmeta_istype
+    |  ins_next2
+    break;
+  case BC_ISNUM:
+    |  // RA = src*8, RD = -(TISNUM-1)*8
+    |  add.d TMP2, BASE, RA
+    |  ld.d TMP0, 0(TMP2)
+    |  ins_next1
+    |  ins_next2
+    |  checknum TMP0, ->vmeta_istype
+    |//  ins_next2
+    break;
+
+  /* -- Unary ops --------------------------------------------------------- */
+
+  case BC_MOV:
+    |  // RA = dst*8, RD = src*8
+    |  add.d RD, BASE, RD
+    |   add.d RA, BASE, RA
+    |  ld.d CRET1, 0(RD)
+    |  ins_next1
+    |  st.d CRET1, 0(RA)
+    |  ins_next2
+    break;
+  case BC_NOT:
+    |  // RA = dst*8, RD = src*8
+    |  add.d RD, BASE, RD
+    |   add.d RA, BASE, RA
+    |  ld.d TMP0, 0(RD)
+    |   .LI AT, LJ_TTRUE
+    |  gettp TMP0, TMP0
+    |  sltu TMP0, AT, TMP0
+    |  addi.w TMP0, TMP0, 1
+    |  slli.d TMP0, TMP0, 47
+    |  nor TMP0, TMP0, r0
+    |  ins_next1
+    |   st.d TMP0, 0(RA)
+    |  ins_next2
+    break;
+  case BC_UNM:
+    |  // RA = dst*8, RD = src*8
+    |  add.d RB, BASE, RD
+    |  ld.d CARG1, 0(RB)
+    |    add.d RA, BASE, RA
+    |  gettp CARG3, CARG1
+    |// addu16i.d TMP1, r0, 0x8000
+    |  .LUI TMP1, 0x8000
+    |  bne CARG3, TISNUM, >2
+    |  slli.w CARG1, CARG1, 0		// sextw -> slli.w
+    |  sub.w CARG1, r0, CARG1
+    |  beq CARG1, TMP1, ->vmeta_unm	// Meta handler deals with -2^31.
+    |  bstrpick.d CARG1, CARG1, 31, 0		// zextw -> bstrpick.d
+    |  settp CARG1, TISNUM
+    |1:
+    |  ins_next1
+    |   st.d CARG1, 0(RA)
+    |  ins_next2
+    |2:
+    |  sltui AT, CARG3, LJ_TISNUM
+    |  slli.d TMP1, TMP1, 32
+    |  beqz AT, ->vmeta_unm
+    |  xor CARG1, CARG1, TMP1
+    |  beq r0, r0, <1
+    break;
+  case BC_LEN:
+    |  // RA = dst*8, RD = src*8
+    |  add.d CARG2, BASE, RD
+    |   add.d RA, BASE, RA
+    |  ld.d TMP0, 0(CARG2)
+    |  gettp TMP1, TMP0
+    |  addi.d AT, TMP1, -LJ_TSTR
+    |  cleartp STR:CARG1, TMP0
+    |  bnez AT, >2
+    |   ld.w CRET1, STR:CARG1->len
+    |1:
+    |  settp CRET1, TISNUM
+    |  ins_next1
+    |  st.d CRET1, 0(RA)
+    |  ins_next2
+    |2:
+    |  addi.d AT, TMP1, -LJ_TTAB
+    |  bnez AT, ->vmeta_len
+#if LJ_52
+    |  ld.d TAB:TMP2, TAB:CARG1->metatable
+    |  bnez TAB:TMP2, >9
+    |3:
+#endif
+    |->BC_LEN_Z:
+    |  bl extern lj_tab_len		// (GCtab *t)
+    |  // Returns uint32_t (but less than 2^31).
+    |  beq r0, r0, <1
+#if LJ_52
+    |9:
+    |  ld.bu TMP0, TAB:TMP2->nomm
+    |  andi TMP0, TMP0, 1<<MM_len
+    |  bnez TMP0, <3			// 'no __len' flag set: done.
+    |  beq r0, r0, ->vmeta_len
+#endif
+    break;
+
+  /* -- Binary ops -------------------------------------------------------- */
+
+    |.macro fpmod, a, b, c
+    |  fdiv.d FARG1, b, c
+    |  bl ->vm_floor		// floor(b/c)
+    |  fmul.d a, FRET1, c
+    |  fsub.d a, b, a		// b - floor(b/c)*c
+    |.endmacro
+
+    |.macro sfpmod
+    |  addi.d sp, sp, -16
+    |
+    |  st.d CARG1, 0(sp)
+    |  st.d CARG2, 8(sp)
+    |  bl extern __divdf3
+    |
+    |  or CARG1, CRET1, r0
+    |  bl extern floor
+    |
+    |  or CARG1, CRET1, r0
+    |  ld.d CARG2, 8(sp)
+    |  bl extern __muldf3
+    |
+    |  ld.d CARG1, 0(sp)
+    |  or CARG2, CRET1, r0
+    |  bl extern __subdf3
+    |
+    |  addi.d sp, sp, 16
+    |.endmacro
+
+    |.macro ins_arithpre, label
+    ||vk = ((int)op - BC_ADDVN) / (BC_ADDNV-BC_ADDVN);
+    |  // RA = dst*8, RB = src1*8, RC = src2*8 | num_const*8
+    ||switch (vk) {
+    ||case 0:
+    |   decode_RB8a RB, INS
+    |   decode_RB8b RB
+    |    decode_RDtoRC8 RC, RD
+    |   // RA = dst*8, RB = src1*8, RC = num_const*8
+    |   add.d RB, BASE, RB
+    |   add.d RC, KBASE, RC
+    |.if "label" ~= "none"
+    |   beq r0, r0, label
+    |.endif
+    ||  break;
+    ||case 1:
+    |   decode_RB8a RC, INS
+    |   decode_RB8b RC
+    |    decode_RDtoRC8 RB, RD
+    |   // RA = dst*8, RB = num_const*8, RC = src1*8
+    |   add.d RC, BASE, RC
+    |   add.d RB, KBASE, RB
+    |.if "label" ~= "none"
+    |   beq r0, r0, label
+    |.endif
+    ||  break;
+    ||default:
+    |   decode_RB8a RB, INS
+    |   decode_RB8b RB
+    |    decode_RDtoRC8 RC, RD
+    |   // RA = dst*8, RB = src1*8, RC = src2*8
+    |   add.d RB, BASE, RB
+    |   add.d RC, BASE, RC
+    |.if "label" ~= "none"
+    |   beq r0, r0, label
+    |.endif
+    ||  break;
+    ||}
+    |.endmacro
+    |
+    |.macro ins_arith, intins, fpins, fpcall, label
+    |  ins_arithpre none
+    |
+    |.if "label" ~= "none"
+    |label:
+    |.endif
+    |
+    |// Used in 5.
+    |  ld.d CARG1, 0(RB)
+    |   ld.d CARG2, 0(RC)
+    |  gettp TMP0, CARG1
+    |   gettp TMP1, CARG2
+    |
+    |.if "intins" ~= "div.w"
+    |
+    |  // Check for two integers.
+    |  slli.w CARG3, CARG1, 0		// sextw -> slli.w
+    |  slli.w CARG4, CARG2, 0		// sextw -> slli.w
+    |  bne TMP0, TISNUM, >5
+    |//  bne TMP1, TISNUM, >5		//TODO not process the following slot ins
+    |
+    |.if "intins" == "add.w"
+    |  intins CRET1, CARG3, CARG4
+    |  bne TMP1, TISNUM, >5
+    |  xor TMP1, CRET1, CARG3		// ((y^a) & (y^b)) < 0: overflow.
+    |  xor TMP2, CRET1, CARG4
+    |  and TMP1, TMP1, TMP2
+    |  add.d RA, BASE, RA
+    |  blt TMP1, r0, ->vmeta_arith
+    |.elif "intins" == "sub.w"
+    |  intins CRET1, CARG3, CARG4
+    |  bne TMP1, TISNUM, >5
+    |  xor TMP1, CRET1, CARG3		// ((y^a) & (a^b)) < 0: overflow.
+    |  xor TMP2, CARG3, CARG4
+    |  and TMP1, TMP1, TMP2
+    |  add.d RA, BASE, RA
+    |  blt TMP1, r0, ->vmeta_arith
+    |.elif "intins" == "mulw.d.w"		//TODO mips: mult -> la: mulw.d.w
+    |//.  nop
+    |  bne TMP1, TISNUM, >5
+    |  mul.w CRET1, CARG3, CARG4
+    |  mulh.w TMP2, CARG3, CARG4
+    |  srai.w TMP1, CRET1, 31
+    |  add.d RA, BASE, RA
+    |  bne TMP1, TMP2, ->vmeta_arith
+    |.else
+    |//.  load_got lj_vm_modi
+    |  bne TMP1, TISNUM, >5
+    |  add.d RA, BASE, RA
+    |  beqz CARG4, ->vmeta_arith
+    |  or CARG1, CARG3, r0
+    |  or CARG2, CARG4, r0
+    |  bl extern lj_vm_modi			//TODO implement func lj_vm_modi/vm_modi
+    |.endif
+    |
+    |  bstrpick.d CRET1, CRET1, 31, 0		// zextw -> bstrpick.d
+    |  settp CRET1, TISNUM
+    |  ins_next1
+    |  st.d CRET1, 0(RA)
+    |3:
+    |  ins_next2
+    |
+    |.endif
+    |
+    |5:  // Check for two numbers.
+    |  .FPU2 fld.d FTMP0, 0(RB)
+    |  sltu AT, TMP0, TISNUM
+    |   sltu TMP0, TMP1, TISNUM
+    |  .FPU2 fld.d FTMP2, 0(RC)
+    |   and AT, AT, TMP0
+    |   add.d RA, BASE, RA
+    |   beqz AT, ->vmeta_arith
+    |
+    |.if FPU
+    |  fpins FRET1, FTMP0, FTMP2
+    |.elif "fpcall" == "sfpmod"
+    |  sfpmod
+    |.else
+    |  bl fpcall
+    |.endif
+    |
+    |  ins_next1
+    |.if FPU
+    |  fst.d FRET1, 0(RA)
+    |.else
+    |  st.d CRET1, 0(RA)
+    |.endif
+    |.if "intins" ~= "div.w"
+    |  beq r0, r0, <3
+    |.endif
+    |.if "intins" == "div.w"
+    |  ins_next2
+    |.endif
+    |
+    |.endmacro
+
+  case BC_ADDVN: case BC_ADDNV: case BC_ADDVV:
+    |  ins_arith add.w, fadd.d, __adddf3, none
+    break;
+  case BC_SUBVN: case BC_SUBNV: case BC_SUBVV:
+    |  ins_arith sub.w, fsub.d, __subdf3, none
+    break;
+  case BC_MULVN: case BC_MULNV: case BC_MULVV:
+    |  ins_arith mulw.d.w, fmul.d, __muldf3, none
+    break;
+  case BC_DIVVN:
+    |  ins_arith div.w, fdiv.d, __divdf3, ->BC_DIVVN_Z
+    break;
+  case BC_DIVNV: case BC_DIVVV:
+    |  ins_arithpre ->BC_DIVVN_Z
+    break;
+  case BC_MODVN:
+    |  ins_arith modi, fpmod, sfpmod, ->BC_MODVN_Z	//TODO modi -> ?
+    break;
+  case BC_MODNV: case BC_MODVV:
+    |  ins_arithpre ->BC_MODVN_Z
+    break;
+  case BC_POW:
+    |  ins_arithpre none
+    |  ld.d CARG1, 0(RB)
+    |   ld.d CARG2, 0(RC)
+    |  gettp TMP0, CARG1
+    |   gettp TMP1, CARG2
+    |  sltui TMP0, TMP0, LJ_TISNUM
+    |   sltui TMP1, TMP1, LJ_TISNUM
+    |  and AT, TMP0, TMP1
+    |  add.d RA, BASE, RA
+    |  beqz AT, ->vmeta_arith
+    |.if FPU
+    |  fld.d FARG1, 0(RB)
+    |  fld.d FARG2, 0(RC)
+    |.endif
+    |  bl extern pow
+    |  ins_next1
+    |.if FPU
+    |  fst.d FRET1, 0(RA)
+    |.else
+    |  st.d CRET1, 0(RA)
+    |.endif
+    |  ins_next2
+    break;
+
+  case BC_CAT:
+    |  // RA = dst*8, RB = src_start*8, RC = src_end*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RDtoRC8 RC, RD
+    |  sub.d CARG3, RC, RB
+    |   st.d BASE, L->base
+    |  add.d CARG2, BASE, RC
+    |  or MULTRES, RB, r0
+    |->BC_CAT_Z:
+    |  srli.w CARG3, CARG3, 3
+    |   st.d PC, SAVE_PC(sp)
+    |  or CARG1, L, r0
+    |  bl extern lj_meta_cat		// (lua_State *L, TValue *top, int left)
+    |  // Returns NULL (finished) or TValue * (metamethod).
+    |  ld.d BASE, L->base
+    |  bnez CRET1, ->vmeta_binop
+    |  add.d RB, BASE, MULTRES
+    |  ld.d r17, 0(RB)
+    |   add.d RA, BASE, RA
+    |  ins_next1
+    |  st.d r17, 0(RA)
+    |  ins_next2
+    break;
+
+  /* -- Constant ops ------------------------------------------------------ */
+
+  case BC_KSTR:
+    |  // RA = dst*8, RD = str_const*8 (~)
+    |  sub.d TMP1, KBASE, RD
+    |  ins_next1
+    |   .LI TMP2, LJ_TSTR
+    |  ld.d TMP0, -8(TMP1)		// KBASE-8-str_const*8
+    |  add.d RA, BASE, RA
+    |   settp TMP0, TMP2
+    |  st.d TMP0, 0(RA)
+    |  ins_next2
+    break;
+  case BC_KCDATA:
+    |.if FFI
+    |  // RA = dst*8, RD = cdata_const*8 (~)
+    |  sub.d TMP1, KBASE, RD
+    |  ins_next1
+    |  ld.d TMP0, -8(TMP1)		// KBASE-8-cdata_const*8
+    |   .LI TMP2, LJ_TCDATA
+    |  add.d RA, BASE, RA
+    |   settp TMP0, TMP2
+    |  st.d TMP0, 0(RA)
+    |  ins_next2
+    |.endif
+    break;
+  case BC_KSHORT:
+    |  // RA = dst*8, RD = int16_literal*8
+    |   srai.w RD, INS, 16
+    |  add.d RA, BASE, RA
+    |   bstrpick.d RD, RD, 31, 0	// zextw -> bstrpick.d
+    |  ins_next1
+    |   settp RD, TISNUM
+    |   st.d RD, 0(RA)
+    |  ins_next2
+    break;
+  case BC_KNUM:
+    |  // RA = dst*8, RD = num_const*8
+    |  add.d RD, KBASE, RD
+    |   add.d RA, BASE, RA
+    |  ld.d CRET1, 0(RD)
+    |  ins_next1
+    |  st.d CRET1, 0(RA)
+    |  ins_next2
+    break;
+  case BC_KPRI:
+    |  // RA = dst*8, RD = primitive_type*8 (~)
+    |   add.d RA, BASE, RA
+    |  slli.d TMP0, RD, 44
+    |  nor TMP0, TMP0, r0
+    |  ins_next1
+    |   st.d TMP0, 0(RA)
+    |  ins_next2
+    break;
+  case BC_KNIL:
+    |  // RA = base*8, RD = end*8
+    |  add.d RA, BASE, RA
+    |  st.d TISNIL, 0(RA)
+    |   addi.d RA, RA, 8
+    |  add.d RD, BASE, RD
+    |1:
+    |  st.d TISNIL, 0(RA)
+    |  slt AT, RA, RD
+    |  addi.d RA, RA, 8
+    |  bnez AT, <1
+    |  ins_next_
+    break;
+
+  /* -- Upvalue and function ops ------------------------------------------ */
+
+  case BC_UGET:
+    |  // RA = dst*8, RD = uvnum*8
+    |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+    |   add.d RA, BASE, RA
+    |  cleartp LFUNC:RB
+    |  add.d RD, RD, LFUNC:RB
+    |  ld.d UPVAL:RB, LFUNC:RD->uvptr
+    |  ins_next1
+    |  ld.d TMP1, UPVAL:RB->v
+    |  ld.d CRET1, 0(TMP1)
+    |   st.d CRET1, 0(RA)
+    |  ins_next2
+    break;
+  case BC_USETV:
+    |  // RA = uvnum*8, RD = src*8
+    |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+    |   add.d RD, BASE, RD
+    |  cleartp LFUNC:RB
+    |  add.d RA, RA, LFUNC:RB
+    |  ld.d UPVAL:RB, LFUNC:RA->uvptr
+    |   ld.d CRET1, 0(RD)
+    |  ld.bu TMP3, UPVAL:RB->marked
+    |   ld.d CARG2, UPVAL:RB->v
+    |  andi TMP3, TMP3, LJ_GC_BLACK	// isblack(uv)
+    |  ld.bu TMP0, UPVAL:RB->closed
+    |   gettp TMP2, CRET1
+    |   st.d CRET1, 0(CARG2)
+    |  .LI AT, LJ_GC_BLACK|1
+    |  or TMP3, TMP3, TMP0
+    |  addi.d TMP2, TMP2, -(LJ_TNUMX+1)
+    |  beq TMP3, AT, >2			// Upvalue is closed and black?
+    |1:
+    |  ins_next
+    |
+    |2:  // Check if new value is collectable.
+    |  sltui AT, TMP2, LJ_TISGCV - (LJ_TNUMX+1)
+    |  cleartp GCOBJ:CRET1, CRET1
+    |  beqz AT, <1			// tvisgcv(v)
+    |  ld.bu TMP3, GCOBJ:CRET1->gch.marked
+    |  andi TMP3, TMP3, LJ_GC_WHITES	// iswhite(v)
+    |  beqz TMP3, <1
+    |  // Crossed a write barrier. Move the barrier forward.
+    |  .DADDIU CARG1, DISPATCH, GG_DISP2G
+    |  bl extern lj_gc_barrieruv	// (global_State *g, TValue *tv)
+    |  beq r0, r0, <1
+    break;
+  case BC_USETS:
+    |  // RA = uvnum*8, RD = str_const*8 (~)
+    |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+    |   sub.d TMP1, KBASE, RD
+    |  cleartp LFUNC:RB
+    |  add.d RA, RA, LFUNC:RB
+    |  ld.d UPVAL:RB, LFUNC:RA->uvptr
+    |   ld.d STR:TMP1, -8(TMP1)		// KBASE-8-str_const*8
+    |  ld.bu TMP2, UPVAL:RB->marked
+    |   ld.d CARG2, UPVAL:RB->v
+    |   ld.bu TMP3, STR:TMP1->marked
+    |  andi AT, TMP2, LJ_GC_BLACK	// isblack(uv)
+    |   ld.bu TMP2, UPVAL:RB->closed
+    |   .LI TMP0, LJ_TSTR
+    |   settp TMP1, TMP0
+    |  st.d TMP1, 0(CARG2)
+    |  bnez AT, >2
+    |1:
+    |  ins_next
+    |
+    |2:  // Check if string is white and ensure upvalue is closed.
+    |  andi AT, TMP3, LJ_GC_WHITES     // iswhite(str)
+    |  beqz TMP2, <1
+    |  beqz AT, <1
+    |  // Crossed a write barrier. Move the barrier forward.
+    |  .DADDIU CARG1, DISPATCH, GG_DISP2G
+    |  bl extern lj_gc_barrieruv	// (global_State *g, TValue *tv)
+    |  beq r0, r0, <1
+    break;
+  case BC_USETN:
+    |  // RA = uvnum*8, RD = num_const*8
+    |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+    |   add.d RD, KBASE, RD
+    |  cleartp LFUNC:RB
+    |  add.d RA, RA, LFUNC:RB
+    |  ld.d UPVAL:RB, LFUNC:RA->uvptr
+    |   ld.d CRET1, 0(RD)
+    |  ld.d TMP1, UPVAL:RB->v
+    |  ins_next1
+    |   st.d CRET1, 0(TMP1)
+    |  ins_next2
+    break;
+  case BC_USETP:
+    |  // RA = uvnum*8, RD = primitive_type*8 (~)
+    |  ld.d LFUNC:RB, FRAME_FUNC(BASE)
+    |   slli.d TMP0, RD, 44
+    |  cleartp LFUNC:RB
+    |  add.d RA, RA, LFUNC:RB
+    |   nor TMP0, TMP0, r0
+    |  ld.d UPVAL:RB, LFUNC:RA->uvptr
+    |  ins_next1
+    |  ld.d TMP1, UPVAL:RB->v
+    |   st.d TMP0, 0(TMP1)
+    |  ins_next2
+    break;
+
+  case BC_UCLO:
+    |  // RA = level*8, RD = target
+    |  ld.d TMP2, L->openupval
+    |  branch_RD			// Do this first since RD is not saved.
+    |   st.d BASE, L->base
+    |  or CARG1, L, r0
+    |  beqz TMP2, >1
+    |  add.d CARG2, BASE, RA
+    |  bl extern lj_func_closeuv	// (lua_State *L, TValue *level)
+    |  ld.d BASE, L->base
+    |1:
+    |  ins_next
+    break;
+
+  case BC_FNEW:
+    |  // RA = dst*8, RD = proto_const*8 (~) (holding function prototype)
+    |  sub.d TMP1, KBASE, RD
+    |  ld.d CARG3, FRAME_FUNC(BASE)
+    |   ld.d CARG2, -8(TMP1)		// KBASE-8-tab_const*8
+    |    st.d BASE, L->base
+    |    st.d PC, SAVE_PC(sp)
+    |  cleartp CARG3
+    |  // (lua_State *L, GCproto *pt, GCfuncL *parent)
+    |  or CARG1, L, r0
+    |  bl extern lj_func_newL_gc
+    |  // Returns GCfuncL *.
+    |   .LI TMP0, LJ_TFUNC
+    |  ld.d BASE, L->base
+    |  ins_next1
+    |   settp CRET1, TMP0
+    |  add.d RA, BASE, RA
+    |   st.d CRET1, 0(RA)
+    |  ins_next2
+    break;
+
+  /* -- Table ops --------------------------------------------------------- */
+
+  case BC_TNEW:
+  case BC_TDUP:
+    |  // RA = dst*8, RD = (hbits|asize)*8 | tab_const*8 (~)
+    |  .LDXD TMP0, DISPATCH, DISPATCH_GL(gc.total)
+    |  .LDXD TMP1, DISPATCH, DISPATCH_GL(gc.threshold)
+    |   st.d BASE, L->base
+    |   st.d PC, SAVE_PC(sp)
+    |  sltu AT, TMP0, TMP1
+    |  beqz AT, >5		//TODO why no slot ins ?
+    |1:
+    if (op == BC_TNEW) {
+      |  srli.w CARG2, RD, 3
+      |  andi CARG2, CARG2, 0x7ff
+      |  .LI TMP0, 0x801
+      |  addi.w AT, CARG2, -0x7ff
+      |   srli.w CARG3, RD, 14
+      |  masknez TMP0, TMP0, AT
+      |  maskeqz CARG2, CARG2, AT
+      |  or CARG2, CARG2, TMP0
+      |  // (lua_State *L, int32_t asize, uint32_t hbits)
+      |  or CARG1, L, r0
+      |  bl extern lj_tab_new
+      |  // Returns Table *.
+    } else {
+      |  sub.d TMP1, KBASE, RD
+      |  or CARG1, L, r0
+      |  ld.d CARG2, -8(TMP1)            // KBASE-8-str_const*8
+      |  bl extern lj_tab_dup		// (lua_State *L, Table *kt)
+      |  // Returns Table *.
+    }
+    |   .LI TMP0, LJ_TTAB
+    |  ld.d BASE, L->base
+    |  ins_next1
+    |  add.d RA, BASE, RA
+    |   settp CRET1, TMP0
+    |   st.d CRET1, 0(RA)
+    |  ins_next2
+    |5:
+    |  or MULTRES, RD, r0
+    |  or CARG1, L, r0
+    |  bl extern lj_gc_step_fixtop	// (lua_State *L)
+    |  or RD, MULTRES, r0
+    |  beq r0, r0, <1
+    break;
+
+  case BC_GGET:
+    |  // RA = dst*8, RD = str_const*8 (~)
+  case BC_GSET:
+    |  // RA = src*8, RD = str_const*8 (~)
+    |  ld.d LFUNC:TMP2, FRAME_FUNC(BASE)
+    |   sub.d TMP1, KBASE, RD
+    |   ld.d STR:RC, -8(TMP1)	// KBASE-8-str_const*8
+    |  cleartp LFUNC:TMP2
+    |  ld.d TAB:RB, LFUNC:TMP2->env
+    |  add.d RA, BASE, RA
+    if (op == BC_GGET) {
+      |  beq r0, r0, ->BC_TGETS_Z
+    } else {
+      |  beq r0, r0, ->BC_TSETS_Z
+    }
+    break;
+
+  case BC_TGETV:
+    |  // RA = dst*8, RB = table*8, RC = key*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RDtoRC8 RC, RD
+    |  add.d CARG2, BASE, RB
+    |   add.d CARG3, BASE, RC
+    |  ld.d TAB:RB, 0(CARG2)
+    |   ld.d TMP2, 0(CARG3)
+    |   add.d RA, BASE, RA
+    |  checktab TAB:RB, ->vmeta_tgetv
+    |   gettp TMP3, TMP2
+    |  ld.w TMP0, TAB:RB->asize
+    |  bne TMP3, TISNUM, >5		// Integer key?
+    |  slli.w TMP2, TMP2, 0		// sextw -> slli.w
+    |   ld.d TMP1, TAB:RB->array
+    |  sltu AT, TMP2, TMP0
+    |   slli.w TMP2, TMP2, 3
+    |  add.d TMP2, TMP1, TMP2
+    |  beqz AT, ->vmeta_tgetv		// Integer key and in array part?
+    |  ld.d AT, 0(TMP2)
+    |   ld.d CRET1, 0(TMP2)
+    |  beq AT, TISNIL, >2
+    |1:
+    |  ins_next1
+    |   st.d CRET1, 0(RA)
+    |  ins_next2
+    |
+    |2:  // Check for __index if table value is nil.
+    |  ld.d TAB:TMP2, TAB:RB->metatable
+    |  beqz TAB:TMP2, <1		// No metatable: done.
+    |  ld.bu TMP0, TAB:TMP2->nomm
+    |  andi TMP0, TMP0, 1<<MM_index
+    |  bnez TMP0, <1			// 'no __index' flag set: done.
+    |  beq r0, r0, ->vmeta_tgetv
+    |
+    |5:
+    |  .LI AT, LJ_TSTR
+    |  cleartp RC, TMP2
+    |  bne TMP3, AT, ->vmeta_tgetv
+    |  beq r0, r0, ->BC_TGETS_Z			// String key?
+    break;
+  case BC_TGETS:
+    |  // RA = dst*8, RB = table*8, RC = str_const*8 (~)
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RC8a RC, INS
+    |  add.d CARG2, BASE, RB
+    |   decode_RC8b RC
+    |  ld.d TAB:RB, 0(CARG2)
+    |   sub.d CARG3, KBASE, RC
+    |  add.d RA, BASE, RA
+    |   ld.d STR:RC, -8(CARG3)		// KBASE-8-str_const*8
+    |  checktab TAB:RB, ->vmeta_tgets1
+    |->BC_TGETS_Z:
+    |  // TAB:RB = GCtab *, STR:RC = GCstr *, RA = dst*8
+    |  ld.w TMP0, TAB:RB->hmask
+    |   ld.w TMP1, STR:RC->hash
+    |    ld.d NODE:TMP2, TAB:RB->node
+    |  and TMP1, TMP1, TMP0		// idx = str->hash & tab->hmask
+    |  slli.w TMP0, TMP1, 5
+    |  slli.w TMP1, TMP1, 3
+    |  sub.w TMP1, TMP0, TMP1
+    |   .LI TMP3, LJ_TSTR
+    |  add.d NODE:TMP2, NODE:TMP2, TMP1	// node = tab->node + (idx*32-idx*8)
+    |   settp STR:RC, TMP3		// Tagged key to look for.
+    |1:
+    |  ld.d CARG1, NODE:TMP2->key
+    |   ld.d r17, NODE:TMP2->val
+    |    ld.d NODE:TMP1, NODE:TMP2->next
+    |  ld.d TAB:TMP3, TAB:RB->metatable
+    |  bne CARG1, RC, >4
+    |  beq r17, TISNIL, >5		// Key found, but nil value?
+    |3:
+    |  ins_next1
+    |   st.d r17, 0(RA)
+    |  ins_next2
+    |
+    |4:  // Follow hash chain.
+    |  or NODE:TMP2, NODE:TMP1, r0
+    |  bnez NODE:TMP1, <1
+    |  // End of hash chain: key not found, nil result.
+    |
+    |5:  // Check for __index if table value is nil.
+    |  or r17, TISNIL, r0
+    |  beqz TAB:TMP3, <3		// No metatable: done.
+    |  ld.bu TMP0, TAB:TMP3->nomm
+    |  andi TMP0, TMP0, 1<<MM_index
+    |  bnez TMP0, <3			// 'no __index' flag set: done.
+    |  beq r0, r0, ->vmeta_tgets
+    break;
+  case BC_TGETB:
+    |  // RA = dst*8, RB = table*8, RC = index*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |  add.d CARG2, BASE, RB
+    |   decode_RDtoRC8 RC, RD
+    |  ld.d TAB:RB, 0(CARG2)
+    |   add.d RA, BASE, RA
+    |  srli.w TMP0, RC, 3
+    |  checktab TAB:RB, ->vmeta_tgetb
+    |  ld.w TMP1, TAB:RB->asize
+    |   ld.d TMP2, TAB:RB->array
+    |  sltu AT, TMP0, TMP1
+    |  add.d RC, TMP2, RC
+    |  beqz AT, ->vmeta_tgetb
+    |  ld.d AT, 0(RC)
+    |  ld.d CRET1, 0(RC)
+    |  beq AT, TISNIL, >5
+    |1:
+    |  ins_next1
+    |   st.d CRET1, 0(RA)
+    |  ins_next2
+    |
+    |5:  // Check for __index if table value is nil.
+    |  ld.d TAB:TMP2, TAB:RB->metatable
+    |  beqz TAB:TMP2, <1		// No metatable: done.
+    |  ld.bu TMP1, TAB:TMP2->nomm
+    |  andi TMP1, TMP1, 1<<MM_index
+    |  bnez TMP1, <1			// 'no __index' flag set: done.
+    |  beq r0, r0, ->vmeta_tgetb			// Caveat: preserve TMP0 and CARG2!
+    break;
+  case BC_TGETR:
+    |  // RA = dst*8, RB = table*8, RC = key*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RDtoRC8 RC, RD
+    |  add.d RB, BASE, RB
+    |   add.d RC, BASE, RC
+    |  ld.d TAB:CARG1, 0(RB)
+    |   ld.w CARG2, LO(RC)
+    |    add.d RA, BASE, RA
+    |  cleartp TAB:CARG1
+    |  ld.w TMP0, TAB:CARG1->asize
+    |   ld.d TMP1, TAB:CARG1->array
+    |  sltu AT, CARG2, TMP0
+    |   slli.w TMP2, CARG2, 3
+    |  add.d r17, TMP1, TMP2
+    |  beqz AT, ->vmeta_tgetr		// In array part?
+    |   ld.d CARG2, 0(r17)
+    |->BC_TGETR_Z:
+    |  ins_next1
+    |   st.d CARG2, 0(RA)
+    |  ins_next2
+    break;
+
+  case BC_TSETV:
+    |  // RA = src*8, RB = table*8, RC = key*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RDtoRC8 RC, RD
+    |  add.d CARG2, BASE, RB
+    |   add.d CARG3, BASE, RC
+    |  ld.d RB, 0(CARG2)
+    |   ld.d TMP2, 0(CARG3)
+    |  add.d RA, BASE, RA
+    |  checktab RB, ->vmeta_tsetv
+    |  slli.w RC, TMP2, 0			// sextw -> slli.w
+    |  checkint TMP2, >5
+    |  ld.w TMP0, TAB:RB->asize
+    |   ld.d TMP1, TAB:RB->array
+    |  sltu AT, RC, TMP0
+    |   slli.w TMP2, RC, 3
+    |  add.d TMP1, TMP1, TMP2
+    |  beqz AT, ->vmeta_tsetv		// Integer key and in array part?
+    |  ld.d TMP0, 0(TMP1)
+    |   ld.bu TMP3, TAB:RB->marked
+    |  ld.d CRET1, 0(RA)
+    |  beq TMP0, TISNIL, >3
+    |1:
+    |   andi AT, TMP3, LJ_GC_BLACK	// isblack(table)
+    |  st.d CRET1, 0(TMP1)
+    |  bnez AT, >7
+    |2:
+    |  ins_next
+    |
+    |3:  // Check for __newindex if previous value is nil.
+    |  ld.d TAB:TMP2, TAB:RB->metatable
+    |  beqz TAB:TMP2, <1		// No metatable: done.
+    |  ld.bu TMP2, TAB:TMP2->nomm
+    |  andi TMP2, TMP2, 1<<MM_newindex
+    |  bnez TMP2, <1			// 'no __newindex' flag set: done.
+    |  beq r0, r0, ->vmeta_tsetv
+    |
+    |5:
+    |  gettp AT, TMP2
+    |  addi.d AT, AT, -LJ_TSTR
+    |  bnez AT, ->vmeta_tsetv
+    |  cleartp STR:RC, TMP2
+    |  beq r0, r0, ->BC_TSETS_Z			// String key?
+    |
+    |7:  // Possible table write barrier for the value. Skip valiswhite check.
+    |  barrierback TAB:RB, TMP3, TMP0, <2
+    break;
+  case BC_TSETS:
+    |  // RA = src*8, RB = table*8, RC = str_const*8 (~)
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |  add.d CARG2, BASE, RB
+    |   decode_RC8a RC, INS
+    |    ld.d TAB:RB, 0(CARG2)
+    |   decode_RC8b RC
+    |   sub.d CARG3, KBASE, RC
+    |   ld.d RC, -8(CARG3)		// KBASE-8-str_const*8
+    |  add.d RA, BASE, RA
+    |   cleartp STR:RC
+    |  checktab TAB:RB, ->vmeta_tsets1
+    |->BC_TSETS_Z:
+    |  // TAB:RB = GCtab *, STR:RC = GCstr *, RA = BASE+src*8
+    |  ld.w TMP0, TAB:RB->hmask
+    |   ld.w TMP1, STR:RC->hash
+    |    ld.d NODE:TMP2, TAB:RB->node
+    |   st.b r0, TAB:RB->nomm		// Clear metamethod cache.
+    |  and TMP1, TMP1, TMP0		// idx = str->hash & tab->hmask
+    |  slli.w TMP0, TMP1, 5
+    |  slli.w TMP1, TMP1, 3
+    |  sub.w TMP1, TMP0, TMP1
+    |   .LI TMP3, LJ_TSTR
+    |  add.d NODE:TMP2, NODE:TMP2, TMP1	// node = tab->node + (idx*32-idx*8)
+    |   settp STR:RC, TMP3		// Tagged key to look for.
+    |.if FPU
+    |   fld.d FTMP0, 0(RA)
+    |.else
+    |   ld.d CRET1, 0(RA)
+    |.endif
+    |1:
+    |  ld.d TMP0, NODE:TMP2->key
+    |   ld.d CARG2, NODE:TMP2->val
+    |    ld.d NODE:TMP1, NODE:TMP2->next
+    |    ld.bu TMP3, TAB:RB->marked
+    |  bne TMP0, RC, >5
+    |   ld.d TAB:TMP0, TAB:RB->metatable
+    |   beq CARG2, TISNIL, >4		// Key found, but nil value?
+    |2:
+    |  andi AT, TMP3, LJ_GC_BLACK	// isblack(table)
+    |.if FPU
+    |  fst.d FTMP0, NODE:TMP2->val
+    |.else
+    |  st.d CRET1, NODE:TMP2->val
+    |.endif
+    |  bnez AT, >7
+    |3:
+    |  ins_next
+    |
+    |4:  // Check for __newindex if previous value is nil.
+    |  beqz TAB:TMP0, <2		// No metatable: done.
+    |  ld.bu TMP0, TAB:TMP0->nomm
+    |  andi TMP0, TMP0, 1<<MM_newindex
+    |  bnez TMP0, <2			// 'no __newindex' flag set: done.
+    |  beq r0, r0, ->vmeta_tsets
+    |
+    |5:  // Follow hash chain.
+    |  or NODE:TMP2, NODE:TMP1, r0
+    |  bnez NODE:TMP1, <1
+    |  // End of hash chain: key not found, add a new one
+    |
+    |  // But check for __newindex first.
+    |  ld.d TAB:TMP2, TAB:RB->metatable
+    |  .DADDIU CARG3, DISPATCH, DISPATCH_GL(tmptv)
+    |  beqz TAB:TMP2, >6		// No metatable: continue.
+    |  ld.bu TMP0, TAB:TMP2->nomm
+    |  andi TMP0, TMP0, 1<<MM_newindex
+    |  beqz TMP0, ->vmeta_tsets		// 'no __newindex' flag NOT set: check. TODO why no slot ins ?
+    |6:
+    |  st.d RC, 0(CARG3)
+    |   st.d BASE, L->base
+    |  or CARG2, TAB:RB, r0
+    |   st.d PC, SAVE_PC(sp)
+    |  or CARG1, L, r0
+    |  bl extern lj_tab_newkey	// (lua_State *L, GCtab *t, TValue *k
+    |  // Returns TValue *.
+    |  ld.d BASE, L->base
+    |.if FPU
+    |  fst.d FTMP0, 0(CRET1)
+    |  beq r0, r0, <3				// No 2nd write barrier needed.
+    |.else
+    |  ld.d r17, 0(RA)
+    |  st.d r17, 0(CRET1)
+    |  beq r0, r0, <3				// No 2nd write barrier needed.
+    |.endif
+    |
+    |7:  // Possible table write barrier for the value. Skip valiswhite check.
+    |  barrierback TAB:RB, TMP3, TMP0, <3
+    break;
+  case BC_TSETB:
+    |  // RA = src*8, RB = table*8, RC = index*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |  add.d CARG2, BASE, RB
+    |   decode_RDtoRC8 RC, RD
+    |  ld.d TAB:RB, 0(CARG2)
+    |   add.d RA, BASE, RA
+    |  srli.w TMP0, RC, 3
+    |  checktab RB, ->vmeta_tsetb
+    |  ld.w TMP1, TAB:RB->asize
+    |   ld.d TMP2, TAB:RB->array
+    |  sltu AT, TMP0, TMP1
+    |  add.d RC, TMP2, RC
+    |  beqz AT, ->vmeta_tsetb
+    |  ld.d TMP1, 0(RC)
+    |   ld.bu TMP3, TAB:RB->marked
+    |  beq TMP1, TISNIL, >5		//TODO not process the following slot ins
+    |1:
+    |  ld.d CRET1, 0(RA)
+    |//  beq TMP1, TISNIL, >5
+    |  andi AT, TMP3, LJ_GC_BLACK	// isblack(table)
+    |   st.d CRET1, 0(RC)
+    |  bnez AT, >7
+    |2:
+    |  ins_next
+    |
+    |5:  // Check for __newindex if previous value is nil.
+    |  ld.d TAB:TMP2, TAB:RB->metatable
+    |  beqz TAB:TMP2, <1		// No metatable: done.
+    |  ld.bu TMP1, TAB:TMP2->nomm
+    |  andi TMP1, TMP1, 1<<MM_newindex
+    |  bnez TMP1, <1			// 'no __newindex' flag set: done.
+    |  beq r0, r0, ->vmeta_tsetb			// Caveat: preserve TMP0 and CARG2!
+    |
+    |7:  // Possible table write barrier for the value. Skip valiswhite check.
+    |  barrierback TAB:RB, TMP3, TMP0, <2
+    break;
+  case BC_TSETR:
+    |  // RA = dst*8, RB = table*8, RC = key*8
+    |  decode_RB8a RB, INS
+    |  decode_RB8b RB
+    |   decode_RDtoRC8 RC, RD
+    |  add.d CARG1, BASE, RB
+    |   add.d CARG3, BASE, RC
+    |  ld.d TAB:CARG2, 0(CARG1)
+    |   ld.w CARG3, LO(CARG3)
+    |  cleartp TAB:CARG2
+    |  ld.bu TMP3, TAB:CARG2->marked
+    |   ld.w TMP0, TAB:CARG2->asize
+    |    ld.d TMP1, TAB:CARG2->array
+    |  andi AT, TMP3, LJ_GC_BLACK	// isblack(table)
+    |  add.d RA, BASE, RA
+    |  bnez AT, >7
+    |2:
+    |  sltu AT, CARG3, TMP0
+    |   slli.w TMP2, CARG3, 3
+    |  add.d r17, TMP1, TMP2
+    |  beqz AT, ->vmeta_tsetr		// In array part?
+    |->BC_TSETR_Z:
+    |  bnez AT, >3
+    |  add.d r17, CRET1, r0
+    |3:
+    |  ld.d CARG1, 0(RA)
+    |  ins_next1
+    |  st.d CARG1, 0(r17)
+    |  ins_next2
+    |
+    |7:  // Possible table write barrier for the value. Skip valiswhite check.
+    |  barrierback TAB:CARG2, TMP3, CRET1, <2
+    break;
+
+  case BC_TSETM:
+    |  // RA = base*8 (table at base-1), RD = num_const*8 (start index)
+    |  add.d RA, BASE, RA
+    |1:
+    |   add.d TMP3, KBASE, RD
+    |  ld.d TAB:CARG2, -8(RA)		// Guaranteed to be a table.
+    |    addi.w TMP0, MULTRES, -8
+    |   ld.w TMP3, LO(TMP3)		// Integer constant is in lo-word.
+    |    srli.w CARG3, TMP0, 3
+    |    beqz TMP0, >4			// Nothing to copy?
+    |  cleartp CARG2
+    |  add.w CARG3, CARG3, TMP3
+    |  ld.w TMP2, TAB:CARG2->asize
+    |   slli.w TMP1, TMP3, 3
+    |    ld.bu TMP3, TAB:CARG2->marked
+    |   ld.d CARG1, TAB:CARG2->array
+    |  sltu AT, TMP2, CARG3
+    |  add.d TMP2, RA, TMP0
+    |  bnez AT, >5
+    |   add.d TMP1, TMP1, CARG1
+    |  andi TMP0, TMP3, LJ_GC_BLACK	// isblack(table)
+    |3:  // Copy result slots to table.
+    |   ld.d CRET1, 0(RA)
+    |    addi.d RA, RA, 8
+    |  sltu AT, RA, TMP2
+    |   st.d CRET1, 0(TMP1)
+    |   addi.d TMP1, TMP1, 8
+    |  bnez AT, <3
+    |  bnez TMP0, >7
+    |4:
+    |  ins_next
+    |
+    |5:  // Need to resize array part.
+    |   st.d BASE, L->base
+    |   st.d PC, SAVE_PC(sp)
+    |  or BASE, RD, r0
+    |  or CARG1, L, r0
+    |  bl extern lj_tab_reasize	// (lua_State *L, GCtab *t, int nasize)
+    |  // Must not reallocate the stack.
+    |  or RD, BASE, r0
+    |  ld.d BASE, L->base        // Reload BASE for lack of a saved register.
+    |  beq r0, r0, <1
+    |
+    |7:  // Possible table write barrier for any value. Skip valiswhite check.
+    |  barrierback TAB:CARG2, TMP3, TMP0, <4
+    break;
+
+  /* -- Calls and vararg handling ----------------------------------------- */
+
+  case BC_CALLM:
+    |  // RA = base*8, (RB = (nresults+1)*8,) RC = extra_nargs*8
+    |  decode_RDtoRC8 NARGS8:RC, RD
+    |  add.w NARGS8:RC, NARGS8:RC, MULTRES
+    |  beq r0, r0, ->BC_CALL_Z
+    break;
+  case BC_CALL:
+    |  // RA = base*8, (RB = (nresults+1)*8,) RC = (nargs+1)*8
+    |  decode_RDtoRC8 NARGS8:RC, RD
+    |->BC_CALL_Z:
+    |  or TMP2, BASE, r0
+    |  add.d BASE, BASE, RA
+    |   ld.d LFUNC:RB, 0(BASE)
+    |   addi.d BASE, BASE, 16
+    |  addi.w NARGS8:RC, NARGS8:RC, -8
+    |  checkfunc RB, ->vmeta_call
+    |  ins_call
+    break;
+
+  case BC_CALLMT:
+    |  // RA = base*8, (RB = 0,) RC = extra_nargs*8
+    |  add.w NARGS8:RD, NARGS8:RD, MULTRES	// BC_CALLT gets RC from RD.
+    |  // Fall through. Assumes BC_CALLT follows.
+    break;
+  case BC_CALLT:
+    |  // RA = base*8, (RB = 0,) RC = (nargs+1)*8
+    |  add.d RA, BASE, RA
+    |  ld.d RB, 0(RA)
+    |   or NARGS8:RC, RD, r0
+    |    ld.d TMP1, FRAME_PC(BASE)
+    |   addi.d RA, RA, 16
+    |  addi.w NARGS8:RC, NARGS8:RC, -8
+    |  checktp CARG3, RB, -LJ_TFUNC, ->vmeta_callt
+    |->BC_CALLT_Z:
+    |  andi TMP0, TMP1, FRAME_TYPE	// Caveat: preserve TMP0 until the 'or'.
+    |   ld.bu TMP3, LFUNC:CARG3->ffid
+    |  xori TMP2, TMP1, FRAME_VARG
+    |  bnez TMP0, >7
+    |1:
+    |  st.d RB, FRAME_FUNC(BASE)		// Copy function down, but keep PC.
+    |  sltui AT, TMP3, 2		// (> FF_C) Calling a fast function?
+    |  or TMP2, BASE, r0
+    |  or RB, CARG3, r0
+    |  or TMP3, NARGS8:RC, r0
+    |  beqz NARGS8:RC, >3
+    |2:
+    |   ld.d CRET1, 0(RA)
+    |    addi.d RA, RA, 8
+    |  addi.w TMP3, TMP3, -8
+    |   st.d CRET1, 0(TMP2)
+    |   addi.d TMP2, TMP2, 8
+    |  bnez TMP3, <2
+    |3:
+    |  or TMP0, TMP0, AT
+    |  beqz TMP0, >5
+    |4:
+    |  ins_callt
+    |
+    |5:  // Tailcall to a fast function with a Lua frame below.
+    |  ld.w INS, -4(TMP1)
+    |  decode_RA8a RA, INS
+    |  decode_RA8b RA
+    |  sub.d TMP1, BASE, RA
+    |  ld.d TMP1, -32(TMP1)
+    |  cleartp LFUNC:TMP1
+    |  ld.d TMP1, LFUNC:TMP1->pc
+    |  ld.d KBASE, PC2PROTO(k)(TMP1)     // Need to prepare KBASE.
+    |  beq r0, r0, <4
+    |
+    |7:  // Tailcall from a vararg function.
+    |  andi AT, TMP2, FRAME_TYPEP
+    |  sub.d TMP2, BASE, TMP2          // Relocate BASE down.
+    |  bnez AT, <1			// Vararg frame below?
+    |  or BASE, TMP2, r0
+    |  ld.d TMP1, FRAME_PC(TMP2)
+    |  andi TMP0, TMP1, FRAME_TYPE
+    |  beq r0, r0, <1
+    break;
+
+  case BC_ITERC:
+    |  // RA = base*8, (RB = (nresults+1)*8, RC = (nargs+1)*8 ((2+1)*8))
+    |  or TMP2, BASE, r0			// Save old BASE fir vmeta_call.
+    |  add.d BASE, BASE, RA
+    |  ld.d RB, -24(BASE)
+    |   ld.d CARG1, -16(BASE)
+    |    ld.d CARG2, -8(BASE)
+    |  .LI NARGS8:RC, 16			// Iterators get 2 arguments.
+    |  st.d RB, 0(BASE)			// Copy callable.
+    |   st.d CARG1, 16(BASE)		// Copy state.
+    |    st.d CARG2, 24(BASE)		// Copy control var.
+    |   addi.d BASE, BASE, 16
+    |  checkfunc RB, ->vmeta_call
+    |  ins_call
+    break;
+
+  case BC_ITERN:
+    |  // RA = base*8, (RB = (nresults+1)*8, RC = (nargs+1)*8 (2+1)*8)
+    |.if JIT
+    |  // NYI: add hotloop, record BC_ITERN.
+    |.endif
+    |->vm_IITERN:
+    |  add.d RA, BASE, RA
+    |  ld.d TAB:RB, -16(RA)
+    |   ld.w RC, -8+LO(RA)		// Get index from control var.
+    |  cleartp TAB:RB
+    |   addi.d PC, PC, 4
+    |  ld.w TMP0, TAB:RB->asize
+    |   ld.d TMP1, TAB:RB->array
+    |  slli.d CARG3, TISNUM, 47
+    |1:  // Traverse array part.
+    |  sltu AT, RC, TMP0
+    |  slli.w TMP3, RC, 3
+    |  beqz AT, >5			// Index points after array part?
+    |  add.d TMP3, TMP1, TMP3
+    |  ld.d CARG1, 0(TMP3)
+    |     ld.hu RD, -4+OFS_RD(PC)
+    |   or TMP2, RC, CARG3
+    |  addi.w RC, RC, 1
+    |  beq CARG1, TISNIL, <1		// Skip holes in array part.
+    |   st.d TMP2, 0(RA)
+    |  st.d CARG1, 8(RA)
+    |   or TMP0, RC, CARG3
+    |     .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |     decode_RD4b RD
+    |     add.d RD, RD, TMP3
+    |   st.w TMP0, -8+LO(RA)		// Update control var.
+    |     add.d PC, PC, RD
+    |3:
+    |  ins_next
+    |
+    |5:  // Traverse hash part.
+    |  ld.w TMP1, TAB:RB->hmask
+    |  sub.w RC, RC, TMP0
+    |   ld.d TMP2, TAB:RB->node
+    |6:
+    |  sltu AT, TMP1, RC		// End of iteration? Branch to ITERL+1.
+    |  slli.w TMP3, RC, 5
+    |  bnez AT, <3
+    |   slli.w RB, RC, 3
+    |   sub.w TMP3, TMP3, RB
+    |  add.d NODE:TMP3, TMP3, TMP2
+    |  ld.d CARG1, 0(NODE:TMP3)
+    |     ld.hu RD, -4+OFS_RD(PC)
+    |  addi.w RC, RC, 1
+    |  beq CARG1, TISNIL, <6		// Skip holes in hash part.
+    |  ld.d CARG2, NODE:TMP3->key
+    |     .LUI TMP3, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  st.d CARG1, 8(RA)
+    |    add.w RC, RC, TMP0
+    |     decode_RD4b RD
+    |     add.w RD, RD, TMP3
+    |  st.d CARG2, 0(RA)
+    |     add.d PC, PC, RD
+    |  st.w RC, -8+LO(RA)                // Update control var.
+    |  beq r0, r0, <3
+    break;
+
+  case BC_ISNEXT:
+    |  // RA = base*8, RD = target (points to ITERN)
+    |  add.d RA, BASE, RA
+    |    srli.w TMP0, RD, 1
+    |  ld.d CFUNC:CARG1, -24(RA)
+    |    add.d TMP0, PC, TMP0
+    |   ld.d CARG2, -16(RA)
+    |   ld.d CARG3, -8(RA)
+    |    .LUI TMP2, (-(BCBIAS_J*4 >> 16) & 65535)
+    |  checkfunc CFUNC:CARG1, >5
+    |  gettp CARG2, CARG2
+    |  addi.d CARG2, CARG2, -LJ_TTAB
+    |  ld.bu TMP1, CFUNC:CARG1->ffid
+    |  addi.d CARG3, CARG3, -LJ_TNIL
+    |  or AT, CARG2, CARG3
+    |  addi.d TMP1, TMP1, -FF_next_N
+    |  or AT, AT, TMP1
+    |//  addu16i.d TMP1, r0, 0xfffe
+    |  .LUI TMP1, 0xfffe
+    |  bnez AT, >5
+    |  add.d PC, TMP0, TMP2
+    |//  ori TMP1, TMP1, 0x7fff
+    |  srli.d TMP1, TMP1, 12
+    |  ori TMP1, TMP1, 0x7
+    |  slli.d TMP1, TMP1, 12
+    |  ori TMP1, TMP1, 0xfff
+    |  slli.d TMP1, TMP1, 32
+    |  st.d TMP1, -8(RA)
+    |1:
+    |  ins_next
+    |5:  // Despecialize bytecode if any of the checks fail.
+    |  .LI TMP3, BC_JMP
+    |   .LI TMP1, BC_ITERC
+    |  st.b TMP3, -4+OFS_OP(PC)
+    |   add.d PC, TMP0, TMP2
+    |  st.b TMP1, OFS_OP(PC)
+    |  beq r0, r0, <1
+    break;
+
+  case BC_VARG:
+    |  // RA = base*8, RB = (nresults+1)*8, RC = numparams*8
+    |  ld.d TMP0, FRAME_PC(BASE)
+    |  decode_RDtoRC8 RC, RD
+    |   decode_RB8a RB, INS
+    |  add.d RC, BASE, RC
+    |   decode_RB8b RB
+    |   add.d RA, BASE, RA
+    |  addi.d RC, RC, FRAME_VARG
+    |   add.d TMP2, RA, RB
+    |  addi.d TMP3, BASE, -16		// TMP3 = vtop
+    |  sub.d RC, RC, TMP0		// RC = vbase
+    |  // Note: RC may now be even _above_ BASE if nargs was < numparams.
+    |  sub.d TMP1, TMP3, RC
+    |  beqz RB, >5			// Copy all varargs?
+    |  addi.d TMP2, TMP2, -16
+    |1:  // Copy vararg slots to destination slots.
+    |  ld.d CARG1, 0(RC)
+    |  sltu AT, RC, TMP3
+    |    addi.d RC, RC, 8
+    |  maskeqz CARG1, CARG1, AT
+    |  masknez AT, TISNIL, AT
+    |  or CARG1, CARG1, AT
+    |  st.d CARG1, 0(RA)
+    |  sltu AT, RA, TMP2
+    |   addi.d RA, RA, 8
+    |  bnez AT, <1
+    |3:
+    |  ins_next
+    |
+    |5:  // Copy all varargs.
+    |  ld.d TMP0, L->maxstack
+    |  .LI MULTRES, 8                   // MULTRES = (0+1)*8
+    |  bge r0, TMP1, <3			// No vararg slots?
+    |  add.d TMP2, RA, TMP1
+    |  sltu AT, TMP0, TMP2
+    |  addi.d MULTRES, TMP1, 8
+    |  bnez AT, >7
+    |6:
+    |  ld.d CRET1, 0(RC)
+    |   addi.d RC, RC, 8
+    |  st.d CRET1, 0(RA)
+    |  sltu AT, RC, TMP3
+    |  addi.d RA, RA, 8
+    |  bnez AT, <6			// More vararg slots?
+    |  beq r0, r0, <3
+    |
+    |7:  // Grow stack for varargs.
+    |   st.d RA, L->top
+    |  sub.d RA, RA, BASE
+    |   st.d BASE, L->base
+    |  sub.d BASE, RC, BASE		// Need delta, because BASE may change.
+    |   st.d PC, SAVE_PC(sp)
+    |  srli.w CARG2, TMP1, 3
+    |  or CARG1, L, r0
+    |  bl extern lj_state_growstack	// (lua_State *L, int n)
+    |  or RC, BASE, r0
+    |  ld.d BASE, L->base
+    |  add.d RA, BASE, RA
+    |  add.d RC, BASE, RC
+    |  addi.d TMP3, BASE, -16
+    |  beq r0, r0, <6
+    break;
+
+  /* -- Returns ----------------------------------------------------------- */
+
+  case BC_RETM:
+    |  // RA = results*8, RD = extra_nresults*8
+    |  add.w RD, RD, MULTRES		// MULTRES >= 8, so RD >= 8.
+    |  // Fall through. Assumes BC_RET follows.
+    break;
+
+  case BC_RET:
+    |  // RA = results*8, RD = (nresults+1)*8
+    |  ld.d PC, FRAME_PC(BASE)
+    |   add.d RA, BASE, RA
+    |    or MULTRES, RD, r0
+    |1:
+    |  andi TMP0, PC, FRAME_TYPE
+    |  xori TMP1, PC, FRAME_VARG
+    |  bnez TMP0, ->BC_RETV_Z
+    |
+    |->BC_RET_Z:
+    |  // BASE = base, RA = resultptr, RD = (nresults+1)*8, PC = return
+    |   ld.w INS, -4(PC)
+    |    addi.d TMP2, BASE, -16
+    |    addi.d RC, RD, -8
+    |  decode_RA8a TMP0, INS
+    |   decode_RB8a RB, INS
+    |  decode_RA8b TMP0
+    |   decode_RB8b RB
+    |   add.d TMP3, TMP2, RB
+    |  sub.d BASE, TMP2, TMP0
+    |  beqz RC, >3
+    |2:
+    |   ld.d CRET1, 0(RA)
+    |    addi.d RA, RA, 8
+    |  addi.d RC, RC, -8
+    |   st.d CRET1, 0(TMP2)
+    |   addi.d TMP2, TMP2, 8
+    |  bnez RC, <2
+    |3:
+    |  addi.d TMP3, TMP3, -8
+    |5:
+    |  sltu AT, TMP2, TMP3
+    |  ld.d LFUNC:TMP1, FRAME_FUNC(BASE)
+    |  bnez AT, >6
+    |  ins_next1
+    |  cleartp LFUNC:TMP1
+    |  ld.d TMP1, LFUNC:TMP1->pc
+    |  ld.d KBASE, PC2PROTO(k)(TMP1)
+    |  ins_next2
+    |
+    |6:  // Fill up results with nil.
+    |  st.d TISNIL, 0(TMP2)
+    |  addi.d TMP2, TMP2, 8
+    |  beq r0, r0, <5
+    |
+    |->BC_RETV_Z:  // Non-standard return case.
+    |  andi TMP2, TMP1, FRAME_TYPEP
+    |  bnez TMP2, ->vm_return
+    |  // Return from vararg function: relocate BASE down.
+    |  sub.d BASE, BASE, TMP1
+    |  ld.d PC, FRAME_PC(BASE)
+    |  beq r0, r0, <1
+    break;
+
+  case BC_RET0: case BC_RET1:
+    |  // RA = results*8, RD = (nresults+1)*8
+    |  ld.d PC, FRAME_PC(BASE)
+    |   add.d RA, BASE, RA
+    |    or MULTRES, RD, r0
+    |  andi TMP0, PC, FRAME_TYPE
+    |  xori TMP1, PC, FRAME_VARG
+    |  bnez TMP0, ->BC_RETV_Z
+    |  ld.w INS, -4(PC)
+    |   addi.d TMP2, BASE, -16
+    if (op == BC_RET1) {
+      |  ld.d CRET1, 0(RA)
+    }
+    |  decode_RB8a RB, INS
+    |   decode_RA8a RA, INS
+    |  decode_RB8b RB
+    |   decode_RA8b RA
+    |   sub.d BASE, TMP2, RA
+    if (op == BC_RET1) {
+      |  st.d CRET1, 0(TMP2)
+    }
+    |5:
+    |  sltu AT, RD, RB
+    |  ld.d TMP1, FRAME_FUNC(BASE)
+    |  bnez AT, >6
+    |  ins_next1
+    |  cleartp LFUNC:TMP1
+    |  ld.d TMP1, LFUNC:TMP1->pc
+    |  ld.d KBASE, PC2PROTO(k)(TMP1)
+    |  ins_next2
+    |
+    |6:  // Fill up results with nil.
+    |  addi.d TMP2, TMP2, 8
+    |  addi.d RD, RD, 8
+    if (op == BC_RET1) {
+      |  st.d TISNIL, 0(TMP2)
+    } else {
+      |  st.d TISNIL, -8(TMP2)
+    }
+    |  beq r0, r0, <5
+    break;
+
+  /* -- Loops and branches ------------------------------------------------ */
+
+  case BC_FORL:
+    |.if JIT
+    |  hotloop
+    |.endif
+    |  // Fall through. Assumes BC_IFORL follows.
+    break;
+
+  case BC_JFORI:
+  case BC_JFORL:
+#if !LJ_HASJIT
+    break;
+#endif
+  case BC_FORI:
+  case BC_IFORL:
+    |  // RA = base*8, RD = target (after end of loop or start of loop)
+    vk = (op == BC_IFORL || op == BC_JFORL);
+    |  add.d RA, BASE, RA
+    |  ld.d r17, FORL_IDX*8(RA)		// IDX CARG1 - CARG3 type
+    |  gettp CARG3, r17
+    if (op != BC_JFORL) {
+      |  srli.w RD, RD, 1
+      |  .LUI TMP2, (-(BCBIAS_J*4 >> 16) & 65535)
+      |  add.d TMP2, RD, TMP2
+    }
+    if (!vk) {
+      |  ld.d r18, FORL_STOP*8(RA)	// STOP CARG2 - CARG4 type
+      |  ld.d CRET1, FORL_STEP*8(RA)	// STEP CRET1 - CRET2 type
+      |  gettp CARG4, r18
+      |  gettp CRET2, CRET1
+      |  bne CARG3, TISNUM, >5
+      |  slli.w CARG3, r17, 0	// sextw -> slli.w
+      |  bne CARG4, TISNUM, ->vmeta_for
+      |  slli.w r18, r18, 0	// sextw -> slli.w
+      |  bne CRET2, TISNUM, ->vmeta_for
+      |  bstrpick.d AT, CRET1, 31, 31
+      |  slt CRET1, r18, CARG3
+      |  slt TMP1, CARG3, r18
+      |  maskeqz TMP1, TMP1, AT
+      |  masknez CRET1, CRET1, AT
+      |  or CRET1, CRET1, TMP1
+    } else {
+      |  ld.d CARG2, FORL_STEP*8(RA)     // STEP CARG2 - CARG4 type
+      |  bne CARG3, TISNUM, >5
+      |    ld.d CRET1, FORL_STOP*8(RA)	// STOP CRET1 - CRET2 type
+      |  slli.w TMP3, r17, 0		// sextw -> slli.w
+      |   slli.w CARG2, CARG2, 0	// sextw -> slli.w
+      |    slli.w CRET1, CRET1, 0	// sextw -> slli.w
+      |  add.w r17, TMP3, CARG2
+      |  xor TMP0, r17, TMP3
+      |  xor TMP1, r17, CARG2
+      |  and TMP0, TMP0, TMP1
+      |  slt TMP1, r17, CRET1
+      |  slt CRET1, CRET1, r17
+      |  slt AT, CARG2, r0
+      |   slt TMP0, TMP0, r0		// ((y^a) & (y^b)) < 0: overflow.
+      |  maskeqz TMP1, TMP1, AT
+      |  masknez CRET1, CRET1, AT
+      |  or CRET1, CRET1, TMP1
+      |   or CRET1, CRET1, TMP0
+      |  bstrpick.d r17, r17, 31, 0		// zextw -> bstrpick.d
+      |  settp r17, TISNUM
+    }
+    |1:
+    if (op == BC_FORI) {
+      |  maskeqz TMP2, TMP2, CRET1
+      |  add.d PC, PC, TMP2
+    } else if (op == BC_JFORI) {
+      |  add.d PC, PC, TMP2
+      |  ld.hu RD, -4+OFS_RD(PC)
+    } else if (op == BC_IFORL) {
+      |  masknez TMP2, TMP2, CRET1
+      |  add.d PC, PC, TMP2
+    }
+    if (vk) {
+      |  st.d r17, FORL_IDX*8(RA)
+    }
+    |  ins_next1
+    |  st.d r17, FORL_EXT*8(RA)
+    |2:
+    if (op == BC_JFORI) {
+      |  decode_RD8b RD
+      |  beqz CRET1, =>BC_JLOOP
+    } else if (op == BC_JFORL) {
+      |  beqz CRET1, =>BC_JLOOP		//TODO no slot ins ?
+    }
+    |  ins_next2
+    |
+    |5:  // FP loop.
+    |.if FPU
+    if (!vk) {
+      |  fld.d f22, FORL_IDX*8(RA)
+      |   fld.d f23, FORL_STOP*8(RA)
+      |  sltui TMP0, CARG3, LJ_TISNUM
+      |  sltui TMP1, CARG4, LJ_TISNUM
+      |  sltui AT, CRET2, LJ_TISNUM
+      |   ld.d TMP3, FORL_STEP*8(RA)
+      |  and TMP0, TMP0, TMP1
+      |  and AT, AT, TMP0
+      |  slt TMP3, TMP3, r0
+      |  beqz AT, ->vmeta_for
+      |   movgr2fr.d FTMP2, TMP3
+      |  fcmp.clt.d FCC0, f22, f23
+      |  fcmp.clt.d FCC1, f23, f22
+      |  movcf2fr FTMP0, FCC0
+      |  movcf2fr FTMP1, FCC1
+      |  movfr2cf FCC0, FTMP2
+      |  fsel FTMP2, FTMP1, FTMP0, FCC0
+      |  movfr2gr.d CRET1, FTMP2
+      |  beq r0, r0, <1
+    } else {
+      |  fld.d f22, FORL_IDX*8(RA)
+      |   fld.d f10, FORL_STEP*8(RA)
+      |    fld.d f23, FORL_STOP*8(RA)
+      |   ld.d TMP3, FORL_STEP*8(RA)
+      |  fadd.d f22, f22, f10
+      |   slt TMP3, TMP3, r0
+      |   movgr2fr.d FTMP2, TMP3
+      |  fcmp.clt.d FCC0, f22, f23
+      |  fcmp.clt.d FCC1, f23, f22
+      |  movcf2fr FTMP0, FCC0
+      |  movcf2fr FTMP1, FCC1
+      |  movfr2cf FCC0, FTMP2
+      |  fsel FTMP2, FTMP1, FTMP0, FCC0
+      |  movfr2gr.d CRET1, FTMP2
+      if (op == BC_IFORL) {
+	|  masknez TMP2, TMP2, CRET1
+	|  add.d PC, PC, TMP2
+      }
+      |  fst.d f22, FORL_IDX*8(RA)
+      |  ins_next1
+      |  fst.d f22, FORL_EXT*8(RA)
+      |  beq r0, r0, <2
+    }
+    |.else
+    if (!vk) {
+      |  sltui TMP0, CARG3, LJ_TISNUM
+      |  sltui TMP1, CARG4, LJ_TISNUM
+      |  sltui AT, CRET2, LJ_TISNUM
+      |  and TMP0, TMP0, TMP1
+      |  and AT, AT, TMP0
+      |  beqz AT, ->vmeta_for
+      |  ld.w TMP3, FORL_STEP*8+HI(RA)
+      |  bl ->vm_sfcmpolex
+      |  beq r0, r0, <1
+    } else {
+      |  st.w TMP2, TMPD(sp)
+      |  bl extern __adddf3
+      |  ld.d CARG2, FORL_STOP*8(RA)
+      |  or r17, CRET1, r0
+      if ( op == BC_JFORL ) {
+	|  ld.hu RD, -4+OFS_RD(PC)
+	|  decode_RD8b RD
+      }
+      |  ld.w TMP3, FORL_STEP*8+HI(RA)
+      |  bl ->vm_sfcmpolex
+      |  ld.w TMP2, TMPD(sp)
+      |  beq r0, r0, <1
+    }
+    |.endif
+    break;
+
+  case BC_ITERL:
+    |.if JIT
+    |  hotloop
+    |.endif
+    |  // Fall through. Assumes BC_IITERL follows.
+    break;
+
+  case BC_JITERL:
+#if !LJ_HASJIT
+    break;
+#endif
+  case BC_IITERL:
+    |  // RA = base*8, RD = target
+    |  add.d RA, BASE, RA
+    |  ld.d TMP1, 0(RA)
+    |  beq TMP1, TISNIL, >1		// Stop if iterator returned nil.
+    if (op == BC_JITERL) {
+      |  st.d TMP1,-8(RA)
+      |  beq r0, r0, =>BC_JLOOP
+    } else {
+      |  branch_RD			// Otherwise save control var + branch.
+      |  st.d TMP1, -8(RA)
+    }
+    |1:
+    |  ins_next
+    break;
+
+  case BC_LOOP:
+    |  // RA = base*8, RD = target (loop extent)
+    |  // Note: RA/RD is only used by trace recorder to determine scope/extent
+    |  // This opcode does NOT jump, it's only purpose is to detect a hot loop.
+    |.if JIT
+    |  hotloop
+    |.endif
+    |  // Fall through. Assumes BC_ILOOP follows.
+    break;
+
+  case BC_ILOOP:
+    |  // RA = base*8, RD = target (loop extent)
+    |  ins_next
+    break;
+
+  case BC_JLOOP:
+    |.if JIT
+    |  // RA = base*8 (ignored), RD = traceno*8
+    |  .LDXD TMP1, DISPATCH, DISPATCH_J(trace)
+    |   .LI AT, 0
+    |  add.d TMP1, TMP1, RD
+    |  // Traces on MIPS don't store the trace number, so use 0.
+    |   .STXD AT, DISPATCH, DISPATCH_GL(vmstate)
+    |  ld.d TRACE:TMP2, 0(TMP1)
+    |   .STXD BASE, DISPATCH, DISPATCH_GL(jit_base)
+    |  ld.d TMP2, TRACE:TMP2->mcode
+    |   .STXD L, DISPATCH, DISPATCH_GL(tmpbuf.L)
+    |  .DADDIU JGL, DISPATCH, GG_DISP2G+32768
+    |  jirl r0, TMP2, 0
+    |.endif
+    break;
+
+  case BC_JMP:
+    |  // RA = base*8 (only used by trace recorder), RD = target
+    |  branch_RD
+    |  ins_next
+    break;
+
+  /* -- Function headers -------------------------------------------------- */
+
+  case BC_FUNCF:
+    |.if JIT
+    |  hotcall
+    |.endif
+  case BC_FUNCV:  /* NYI: compiled vararg functions. */
+    |  // Fall through. Assumes BC_IFUNCF/BC_IFUNCV follow.
+    break;
+
+  case BC_JFUNCF:
+#if !LJ_HASJIT
+    break;
+#endif
+  case BC_IFUNCF:
+    |  // BASE = new base, RA = BASE+framesize*8, RB = LFUNC, RC = nargs*8
+    |  ld.d TMP2, L->maxstack
+    |   ld.bu TMP1, -4+PC2PROTO(numparams)(PC)
+    |    ld.d KBASE, -4+PC2PROTO(k)(PC)
+    |  sltu AT, TMP2, RA
+    |  slli.w TMP1, TMP1, 3
+    |  bnez AT, ->vm_growstack_l
+    if (op != BC_JFUNCF) {
+      |  ins_next1
+    }
+    |2:
+    |  sltu AT, NARGS8:RC, TMP1		// Check for missing parameters.
+    |  or r17, AT, r0
+    |  add.d AT, BASE, NARGS8:RC
+    |  bnez r17, >3
+    if (op == BC_JFUNCF) {
+      |  decode_RD8a RD, INS
+      |  decode_RD8b RD
+      |  beq r0, r0, =>BC_JLOOP
+    } else {
+      |  ins_next2
+    }
+    |
+    |3:  // Clear missing parameters.
+    |  st.d TISNIL, 0(AT)
+    |  addi.w NARGS8:RC, NARGS8:RC, 8
+    |  beq r0, r0, <2
+    break;
+
+  case BC_JFUNCV:
+#if !LJ_HASJIT
+    break;
+#endif
+    |  NYI  // NYI: compiled vararg functions
+    break;  /* NYI: compiled vararg functions. */
+
+  case BC_IFUNCV:
+    |  // BASE = new base, RA = BASE+framesize*8, RB = LFUNC, RC = nargs*8
+    |   .LI TMP0, LJ_TFUNC
+    |   add.d TMP1, BASE, RC
+    |  ld.d TMP2, L->maxstack
+    |   settp LFUNC:RB, TMP0
+    |  add.d TMP0, RA, RC
+    |   st.d LFUNC:RB, 0(TMP1)		// Store (tagged) copy of LFUNC.
+    |   addi.d TMP3, RC, 16+FRAME_VARG
+    |  sltu AT, TMP0, TMP2
+    |    ld.d KBASE, -4+PC2PROTO(k)(PC)
+    |  st.d TMP3, 8(TMP1)                // Store delta + FRAME_VARG.
+    |  beqz AT, ->vm_growstack_l
+    |  ld.bu TMP2, -4+PC2PROTO(numparams)(PC)
+    |   or RA, BASE, r0
+    |   or RC, TMP1, r0
+    |  ins_next1
+    |  addi.d BASE, TMP1, 16
+    |  beqz TMP2, >3
+    |1:
+    |  ld.d TMP0, 0(RA)
+    |  sltu AT, RA, RC			// Less args than parameters?
+    |  or CARG1, TMP0, r0
+    |  maskeqz TMP0, TMP0, AT
+    |  masknez TMP3, TISNIL, AT
+    |  or TMP0, TMP0, TMP3
+    |  masknez TMP3, CARG1, AT
+    |  maskeqz CARG1, TISNIL, AT
+    |  or CARG1, CARG1, TMP3
+    |    addi.w TMP2, TMP2, -1
+    |  st.d TMP0, 16(TMP1)
+    |    addi.d TMP1, TMP1, 8
+    |  st.d CARG1, 0(RA)
+    |   addi.d RA, RA, 8
+    |  bnez TMP2, <1
+    |3:
+    |  ins_next2
+    break;
+
+  case BC_FUNCC:
+  case BC_FUNCCW:
+    |  // BASE = new base, RA = BASE+framesize*8, RB = CFUNC, RC = nargs*8
+    if (op == BC_FUNCC) {
+      |  ld.d CFUNCADDR, CFUNC:RB->f
+    } else {
+      |  .LDXD CFUNCADDR, DISPATCH, DISPATCH_GL(wrapf)
+    }
+    |  add.d TMP1, RA, NARGS8:RC
+    |  ld.d TMP2, L->maxstack
+    |   add.d RC, BASE, NARGS8:RC
+    |  st.d BASE, L->base
+    |  sltu AT, TMP2, TMP1
+    |   st.d RC, L->top
+    |    li_vmstate C
+    if (op == BC_FUNCCW) {
+      |  ld.d CARG2, CFUNC:RB->f
+    }
+    |  or CARG1, L, r0
+    |  bnez AT, ->vm_growstack_c	// Need to grow stack.
+    |   st_vmstate
+    |  jirl r1, CFUNCADDR, 0		// (lua_State *L [, lua_CFunction f])
+    |  // Returns nresults.
+    |  ld.d BASE, L->base
+    |   slli.w RD, CRET1, 3
+    |  ld.d TMP1, L->top
+    |    li_vmstate INTERP
+    |  ld.d PC, FRAME_PC(BASE)		// Fetch PC of caller.
+    |   sub.d RA, TMP1, RD		// RA = L->top - nresults*8
+    |    .STXD L, DISPATCH, DISPATCH_GL(cur_L)
+    |   st_vmstate
+    |  beq r0, r0, ->vm_returnc
+    break;
+
+  /* ---------------------------------------------------------------------- */
+
+  default:
+    fprintf(stderr, "Error: undefined opcode BC_%s\n", bc_names[op]);
+    exit(2);
+    break;
+  }
+}
+
+static int build_backend(BuildCtx *ctx)
+{
+  int op;
+
+  dasm_growpc(Dst, BC__MAX);
+
+  build_subroutines(ctx);
+
+  |.code_op
+  for (op = 0; op < BC__MAX; op++)
+    build_ins(ctx, (BCOp)op, op);
+
+  return BC__MAX;
+}
+
+/* Emit pseudo frame-info for all assembler functions. */
+static void emit_asm_debug(BuildCtx *ctx)
+{
+  int fcofs = (int)((uint8_t *)ctx->glob[GLOB_vm_ffi_call] - ctx->code);
+  int i;
+  switch (ctx->mode) {
+  case BUILD_elfasm:
+    fprintf(ctx->fp, "\t.section .debug_frame,\"\",@progbits\n");
+    fprintf(ctx->fp,
+	".Lframe0:\n"
+	"\t.4byte .LECIE0-.LSCIE0\n"
+	".LSCIE0:\n"
+	"\t.4byte 0xffffffff\n"
+	"\t.byte 0x1\n"
+	"\t.string \"\"\n"
+	"\t.uleb128 0x1\n"
+	"\t.sleb128 -4\n"
+	"\t.byte 31\n"
+	"\t.byte 0xc\n\t.uleb128 29\n\t.uleb128 0\n"
+	"\t.align 2\n"
+	".LECIE0:\n\n");
+    fprintf(ctx->fp,
+	".LSFDE0:\n"
+	"\t.4byte .LEFDE0-.LASFDE0\n"
+	".LASFDE0:\n"
+	"\t.4byte .Lframe0\n"
+	"\t.8byte .Lbegin\n"
+	"\t.8byte %d\n"
+	"\t.byte 0xe\n\t.uleb128 %d\n"
+	"\t.byte 0x9f\n\t.sleb128 2*5\n"
+	"\t.byte 0x9e\n\t.sleb128 2*6\n",
+	fcofs, CFRAME_SIZE);
+    for (i = 23; i >= 16; i--)
+      fprintf(ctx->fp, "\t.byte %d\n\t.uleb128 %d\n", 0x80+i, 2*(30-i));
+#if !LJ_SOFTFP
+    for (i = 31; i >= 24; i--)
+      fprintf(ctx->fp, "\t.byte %d\n\t.uleb128 %d\n", 0x80+32+i, 2*(46-i));
+#endif
+    fprintf(ctx->fp,
+	"\t.align 2\n"
+	".LEFDE0:\n\n");
+#if LJ_HASFFI
+    fprintf(ctx->fp,
+	".LSFDE1:\n"
+	"\t.4byte .LEFDE1-.LASFDE1\n"
+	".LASFDE1:\n"
+	"\t.4byte .Lframe0\n"
+	"\t.4byte lj_vm_ffi_call\n"
+	"\t.4byte %d\n"
+	"\t.byte 0x9f\n\t.uleb128 2*1\n"
+	"\t.byte 0x90\n\t.uleb128 2*2\n"
+	"\t.byte 0xd\n\t.uleb128 0x10\n"
+	"\t.align 2\n"
+	".LEFDE1:\n\n", (int)ctx->codesz - fcofs);
+#endif
+#if !LJ_NO_UNWIND
+    /* NYI */
+#endif
+    break;
+  default:
+    break;
+  }
+}
+
diff --git a/libs/luajit/configure b/libs/luajit/configure
index 7d798f8..ea7d3c1 100755
--- a/libs/luajit/configure
+++ b/libs/luajit/configure
@@ -15094,6 +15094,11 @@ then :
   echo '-D__AARCH64EB__=1' >>native_flags
 fi
 
+elif grep 'LJ_TARGET_LOONGARCH64 ' conftest.i >/dev/null 2>&1
+then :
+  LJARCH=loongarch64
+  echo '-D__loongarch__=1' >>native_flags
+
 elif grep 'LJ_TARGET_PPC ' conftest.i >/dev/null 2>&1
 then :
   LJARCH=ppc
diff --git a/libs/luajit/m4/lj-system.m4 b/libs/luajit/m4/lj-system.m4
index 73ba282..7005664 100644
--- a/libs/luajit/m4/lj-system.m4
+++ b/libs/luajit/m4/lj-system.m4
@@ -29,6 +29,9 @@ AS_IF([grep 'LJ_TARGET_X64 ' conftest.i >/dev/null 2>&1],
          AS_IF([grep '__AARCH64EB__' conftest.i >/dev/null 2>&1],
                  [echo '-D__AARCH64EB__=1' >>native_flags])
         ],
+      [grep 'LJ_TARGET_LOONGARCH64 ' conftest.i >/dev/null 2>&1],
+        [LJARCH=loongarch64
+        ],
       [grep 'LJ_TARGET_PPC ' conftest.i >/dev/null 2>&1],
         [LJARCH=ppc
          AS_IF([grep 'LJ_LE 1' conftest.i >/dev/null 2>&1],
